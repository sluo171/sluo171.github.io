
@article{akbari_towards_2019,
	title = {Towards reconstructing intelligible speech from the human auditory cortex},
	volume = {9},
	issn = {2045-2322},
	doi = {10.1038/s41598-018-37359-z},
	journaltitle = {Scientific Reports},
	author = {Akbari, H and Khalighinejad, B and Herrero, {JL} and Mehta, {AD} and Mesgarani, N},
	date = {2019},
	note = {Type: Journal Article},
}

@article{angrick_speech_2019,
	title = {Speech synthesis from {ECoG} using densely connected 3D convolutional neural networks},
	volume = {16},
	issn = {1741-2560},
	doi = {10.1088/1741-2552/ab0c59},
	number = {3},
	journaltitle = {Journal of Neural Engineering},
	author = {Angrick, M and Herff, C and Mugler, E and Tate, {MC} and Slutzky, {MW} and Krusienski, {DJ} and Schultz, T},
	date = {2019},
	note = {Type: Journal Article},
}

@article{bauer_varieties_1979,
	title = {Varieties of the locked-in syndrome},
	volume = {221},
	issn = {0340-5354},
	doi = {10.1007/BF00313105},
	pages = {77--91},
	number = {2},
	journaltitle = {Journal of Neurology},
	author = {Bauer, G and Gerstenbrand, F and Rumpl, E},
	date = {1979},
	note = {Type: Journal Article},
}

@article{beazley_automated_2003,
	title = {Automated scientific software scripting with {SWIG}},
	volume = {19},
	issn = {0167-739X},
	pages = {599--609},
	number = {5},
	journaltitle = {Future Generation Computer Systems},
	author = {Beazley, David M},
	date = {2003},
	note = {Type: Journal Article},
}

@article{broca_remarks_1861,
	title = {Remarks on the seat of the faculty of articulated language, following an observation of aphemia (loss of speech)},
	volume = {6},
	pages = {330--57},
	journaltitle = {Bulletin de la Société Anatomique},
	author = {Broca, Paul},
	date = {1861},
	note = {Type: Journal Article},
}

@article{brumberg_brain-computer_2010,
	title = {Brain-Computer Interfaces for Speech Communication},
	volume = {52},
	issn = {0167-6393},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/20204164},
	doi = {10.1016/j.specom.2010.01.001},
	pages = {367--379},
	number = {4},
	journaltitle = {Speech Commun},
	author = {Brumberg, J. S. and Nieto-Castanon, A. and Kennedy, P. R. and Guenther, F. H.},
	date = {2010},
	note = {Type: Journal Article},
}

@article{caldwell_direct_2019,
	title = {Direct Electrical Stimulation in Electrocorticographic Brain-Computer Interfaces: Enabling Technologies for Input to Cortex},
	volume = {13},
	issn = {1662-4548},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/31440127},
	doi = {10.3389/fnins.2019.00804},
	pages = {804},
	journaltitle = {Front Neurosci},
	author = {Caldwell, D. J. and Ojemann, J. G. and Rao, R. P. N.},
	date = {2019},
	note = {Type: Journal Article},
}

@article{cogan_sensory-motor_2014,
	title = {Sensory-motor transformations for speech occur bilaterally},
	volume = {507},
	issn = {0028-0836},
	doi = {10.1038/nature12935},
	pages = {94--+},
	number = {7490},
	journaltitle = {Nature},
	author = {Cogan, {GB} and Thesen, T and Carlson, C and Doyle, W and Devinsky, O and Pesaran, B},
	date = {2014},
	note = {Type: Journal Article},
}

@article{crone_functional_1999,
	title = {Functional mapping of word production in human sign language using electrocorticographic spectral analysis},
	volume = {52},
	issn = {0028-3878},
	pages = {A233--A233},
	number = {6},
	journaltitle = {Neurology},
	author = {Crone, {NE} and Hart, J and Hao, L and Miglioretti, {DL} and Lesser, {RP} and Gordon, B},
	date = {1999},
	note = {Type: Journal Article},
}

@article{crone_functional_1998,
	title = {Functional mapping of human sensorimotor cortex with electrocorticographic spectral analysis - {II}. Event-related synchronization in the gamma band},
	volume = {121},
	issn = {0006-8950},
	doi = {10.1093/brain/121.12.2301},
	pages = {2301--2315},
	journaltitle = {Brain},
	author = {Crone, {NE} and Miglioretti, {DL} and Gordon, B and Lesser, {RP}},
	date = {1998},
	note = {Type: Journal Article},
}

@article{crone_functional_1998-1,
	title = {Functional mapping of human sensorimotor cortex with electrocorticographic spectral analysis - I. Alpha and beta event-related desynchronization},
	volume = {121},
	issn = {0006-8950},
	doi = {10.1093/brain/121.12.2271},
	pages = {2271--2299},
	journaltitle = {Brain},
	author = {Crone, {NE} and Miglioretti, {DL} and Gordon, B and Sieracki, {JM} and Wilson, {MT} and Uematsu, S and Lesser, {RP}},
	date = {1998},
	note = {Type: Journal Article},
}

@article{dassios_non-uniqueness_2005,
	title = {On the non-uniqueness of the inverse {MEG} problem},
	volume = {21},
	issn = {0266-5611},
	doi = {10.1088/0266-5611/21/2/L01},
	pages = {L1--L5},
	number = {2},
	journaltitle = {Inverse Problems},
	author = {Dassios, G and Fokas, {AS} and Kariotou, F},
	date = {2005},
	note = {Type: Journal Article},
}

@book{de_zubicaray_oxford_2018,
	location = {New York, {NY}},
	title = {The Oxford handbook of neurolinguistics},
	isbn = {9780190672027 (cloth alk. paper)},
	pagetotal = {xix, 969 pages},
	publisher = {Oxford University Press},
	author = {De Zubicaray, Greig and Schiller, Niels Olaf},
	date = {2018},
	note = {Type: Book},
}

@article{degenhart_histological_2016,
	title = {Histological evaluation of a chronically-implanted electrocorticographic electrode grid in a non-human primate},
	volume = {13},
	issn = {1741-2560},
	doi = {10.1088/1741-2560/13/4/046019},
	number = {4},
	journaltitle = {Journal of Neural Engineering},
	author = {Degenhart, {AD} and Eles, J and Dum, R and Mischel, {JL} and Smalianchuk, I and Endler, B and Ashmore, {RC} and Tyler-Kabara, {EC} and Hatsopoulos, {NG} and Wang, W and Batista, {AP} and Cui, {XT}},
	date = {2016},
	note = {Type: Journal Article},
}

@article{duffau_intraoperative_2008,
	title = {Intraoperative subcortical stimulation mapping of language pathways in a consecutive series of 115 patients with Grade {II} glioma in the left dominant hemisphere},
	volume = {109},
	issn = {1933-0693},
	pages = {461--471},
	number = {3},
	journaltitle = {Journal of neurosurgery},
	author = {Duffau, Hugues and Gatignol, Peggy and Mandonnet, Emmanuel and Capelle, Laurent and Taillandier, Luc},
	date = {2008},
	note = {Type: Journal Article},
}

@book{duffy_motor_2019,
	location = {Maryland Heights},
	edition = {Fourth.},
	title = {Motor speech disorders: substrates, differential diagnosis, and management},
	isbn = {978-0-323-53054-5},
	pagetotal = {pages cm},
	publisher = {Elsevier},
	author = {Duffy, Joseph},
	date = {2019},
	note = {Type: Book},
}

@article{flinker_redefining_2015,
	title = {Redefining the role of Broca's area in speech},
	volume = {112},
	issn = {0027-8424},
	doi = {10.1073/pnas.1414491112},
	pages = {2871--2875},
	number = {9},
	journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Flinker, A and Korzeniewska, A and Shestyuk, {AY} and Franaszczuk, {PJ} and Dronkers, {NF} and Knight, {RT} and Crone, {NE}},
	date = {2015},
	note = {Type: Journal Article},
}

@article{fourment_comparison_2008,
	title = {A comparison of common programming languages used in bioinformatics},
	volume = {9},
	issn = {1471-2105},
	doi = {10.1186/1471-2105-9-82},
	journaltitle = {Bmc Bioinformatics},
	author = {Fourment, M and Gillings, {MR}},
	date = {2008},
	note = {Type: Journal Article},
}

@article{giraud_cortical_2012,
	title = {Cortical oscillations and speech processing: emerging computational principles and operations},
	volume = {15},
	issn = {1097-6256},
	doi = {10.1038/nn.3063},
	pages = {511--517},
	number = {4},
	journaltitle = {Nature Neuroscience},
	author = {Giraud, {AL} and Poeppel, D},
	date = {2012},
	note = {Type: Journal Article},
}

@article{gorno-tempini_classification_2011,
	title = {Classification of primary progressive aphasia and its variants},
	volume = {76},
	issn = {0028-3878},
	doi = {10.1212/WNL.0b013e31821103e6},
	pages = {1006--1014},
	number = {11},
	journaltitle = {Neurology},
	author = {Gorno-Tempini, {ML} and Hillis, {AE} and Weintraub, S and Kertesz, A and Mendez, M and Cappa, {SF} and Ogar, {JM} and Rohrer, {JD} and Black, S and Boeve, {BF} and Manes, F and Dronkers, {NF} and Vandenberghe, R and Rascovsky, K and Patterson, K and Miller, {BL} and Knopman, {DS} and Hodges, {JR} and Mesulam, {MM} and Grossman, M},
	date = {2011},
	note = {Type: Journal Article},
}

@article{guenther_wireless_2009,
	title = {A Wireless Brain-Machine Interface for Real-Time Speech Synthesis},
	volume = {4},
	issn = {1932-6203},
	doi = {10.1371/journal.pone.0008218},
	number = {12},
	journaltitle = {Plos One},
	author = {Guenther, {FH} and Brumberg, {JS} and Wright, {EJ} and Nieto-Castanon, A and Tourville, {JA} and Panko, M and Law, R and Siebert, {SA} and Bartels, {JL} and Andreasen, {DS} and Ehirim, P and Mao, H and Kennedy, {PR}},
	date = {2009},
	note = {Type: Journal Article},
}

@article{guenther_neural_2012,
	title = {A neural theory of speech acquisition and production},
	volume = {25},
	issn = {0911-6044},
	doi = {10.1016/j.jneuroling.2009.08.006},
	pages = {408--422},
	number = {5},
	journaltitle = {Journal of Neurolinguistics},
	author = {Guenther, {FH} and Vladusich, T},
	date = {2012},
	note = {Type: Journal Article},
}

@book{guenther_neural_2015,
	location = {Cambridge, {MA}},
	title = {Neural control of speech},
	isbn = {9780262034715 (hardcover alk. paper)},
	pagetotal = {xiv, 410 pages},
	publisher = {The {MIT} Press},
	author = {Guenther, Frank H.},
	date = {2015},
	note = {Type: Book},
}

@inproceedings{he_deep_nodate,
	title = {Deep residual learning for image recognition},
	pages = {770--778},
	booktitle = {Proceedings of the {IEEE} conference on computer vision and pattern recognition},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	note = {Type: Conference Proceedings},
}

@article{heywood_control_1996,
	title = {Control of breathing in man; Insights from the 'locked-in' syndrome},
	volume = {106},
	issn = {0034-5687},
	doi = {10.1016/0034-5687(96)00060-6},
	pages = {13--20},
	number = {1},
	journaltitle = {Respiration Physiology},
	author = {Heywood, P and Murphy, K and Corfield, {DR} and Morrell, {MJ} and Howard, {RS} and Guz, A},
	date = {1996},
	note = {Type: Journal Article},
}

@article{hickok_architecture_2014,
	title = {The architecture of speech production and the role of the phoneme in speech processing},
	volume = {29},
	issn = {0169-0965},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/24489420},
	doi = {10.1080/01690965.2013.834370},
	pages = {2--20},
	number = {1},
	journaltitle = {Lang Cogn Process},
	author = {Hickok, G.},
	date = {2014},
	note = {Type: Journal Article},
}

@book{hickok_neurobiology_2016,
	location = {Amsterdam ; Boston},
	title = {Neurobiology of language},
	isbn = {978-0-12-407794-2 0-12-407794-3},
	pagetotal = {xxvii, 1159 pages},
	publisher = {Elsevier/{AP}, Academic Press is an imprint of Elsevier},
	author = {Hickok, Gregory and Small, Steven Lawrence},
	date = {2016},
	note = {Type: Book},
}

@article{im_review_2016,
	title = {A review of electrodes for the electrical brain signal recording},
	volume = {6},
	issn = {2093-9868},
	pages = {104--112},
	number = {3},
	journaltitle = {Biomedical Engineering Letters},
	author = {Im, Changkyun and Seo, Jong-Mo},
	date = {2016},
	note = {Type: Journal Article},
	keywords = {{ECoG}, {LFP}, {EEG}, Multi-unit recording, Neural recording system, Recording electrode, Single-unit recording},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\8HH3KUEX\\Im and Seo - 2016 - A review of electrodes for the electrical brain si.pdf:application/pdf},
}

@article{indefrey_spatial_2004,
	title = {The spatial and temporal signatures of word production components},
	volume = {92},
	issn = {0010-0277},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/15037128},
	doi = {10.1016/j.cognition.2002.06.001},
	pages = {101--44},
	number = {1},
	journaltitle = {Cognition},
	author = {Indefrey, P. and Levelt, W. J.},
	date = {2004},
	note = {Type: Journal Article},
}

@article{indefrey_spatial_2011,
	title = {The Spatial and Temporal Signatures of Word Production Components: A Critical Update},
	volume = {2},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/article/10.3389/fpsyg.2011.00255},
	doi = {10.3389/fpsyg.2011.00255},
	number = {255},
	journaltitle = {Frontiers in Psychology},
	author = {Indefrey, Peter},
	date = {2011},
	note = {Type: Journal Article},
}

@book{kandel_principles_2013,
	location = {New York},
	edition = {5th},
	title = {Principles of neural science},
	isbn = {9780071390118 (hard cover alk. paper) 0071390111 (hard cover alk. paper)},
	pagetotal = {l, 1709 p.},
	publisher = {{McGraw}-Hill},
	author = {Kandel, Eric R.},
	date = {2013},
	note = {Type: Book},
}

@article{kent_research_2000,
	title = {Research on speech motor control and its disorders: A review and prospective},
	volume = {33},
	issn = {0021-9924},
	pages = {391--428},
	number = {5},
	journaltitle = {Journal of Communication disorders},
	author = {Kent, Ray D},
	date = {2000},
	note = {Type: Journal Article},
}

@inproceedings{kreps_kafka_nodate,
	title = {Kafka: A distributed messaging system for log processing},
	volume = {11},
	pages = {1--7},
	booktitle = {Proceedings of the {NetDB}},
	author = {Kreps, Jay and Narkhede, Neha and Rao, Jun},
	note = {Type: Conference Proceedings},
}

@article{leuthardt_temporal_2012,
	title = {Temporal evolution of gamma activity in human cortex during an overt and covert word repetition task},
	volume = {6},
	issn = {1662-5161},
	doi = {10.3389/fnhum.2012.00099},
	journaltitle = {Frontiers in Human Neuroscience},
	author = {Leuthardt, {EC} and Pei, {XM} and Breshears, J and Gaona, C and Sharma, M and Freudenberg, Z and Barbour, D and Schalk, G},
	date = {2012},
	note = {Type: Journal Article},
}

@article{leon-carrion_review_2002,
	title = {Review of subject: The locked-in syndrome: a syndrome looking for a therapy},
	volume = {16},
	issn = {0269-9052},
	pages = {555--569},
	number = {7},
	journaltitle = {Brain injury},
	author = {León-Carrión, José and Eeckhout, Philippe van and Domínguez-Morales, María del Rosario},
	date = {2002},
	note = {Type: Journal Article},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\MLUWI7R9\\León-Carrión et al. - 2002 - Review of subject The locked-in syndrome a syndr.pdf:application/pdf;León-Carrión et al. - 2002 - Review of subject The locked-in syndrome a syndr.pdf:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\ZSANQJC3\\León-Carrión et al. - 2002 - Review of subject The locked-in syndrome a syndr.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\26AIBD5Q\\02699050110119466.html:text/html},
}

@article{liberman_perception_1967,
	title = {Perception of the speech code},
	volume = {74},
	issn = {0033-295X},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/4170865},
	doi = {10.1037/h0020279},
	pages = {431--61},
	number = {6},
	journaltitle = {Psychol Rev},
	author = {Liberman, A. M. and Cooper, F. S. and Shankweiler, D. P. and Studdert-Kennedy, M.},
	date = {1967},
	note = {Type: Journal Article},
}

@article{lichtheim_aphasia_1885,
	title = {On aphasia},
	volume = {7},
	issn = {0006-8950},
	pages = {433--484},
	journaltitle = {Brain},
	author = {Lichtheim, Ludwig},
	date = {1885},
	note = {Type: Journal Article},
}

@article{liu_timing_2009,
	title = {Timing, Timing, Timing: Fast Decoding of Object Information from Intracranial Field Potentials in Human Visual Cortex},
	volume = {62},
	issn = {0896-6273},
	doi = {10.1016/j.neuron.2009.02.025},
	pages = {281--290},
	number = {2},
	journaltitle = {Neuron},
	author = {Liu, {HS} and Agam, Y and Madsen, {JR} and Kreiman, G},
	date = {2009},
	note = {Type: Journal Article},
}

@article{makin_machine_2020,
	title = {Machine translation of cortical activity to text with an encoder–decoder framework},
	volume = {23},
	issn = {1546-1726},
	url = {https://doi.org/10.1038/s41593-020-0608-8},
	doi = {10.1038/s41593-020-0608-8},
	pages = {575--582},
	number = {4},
	journaltitle = {Nature Neuroscience},
	author = {Makin, Joseph G. and Moses, David A. and Chang, Edward F.},
	date = {2020},
	note = {Type: Journal Article},
}

@article{manning_spontaneously_2012,
	title = {Spontaneously Reactivated Patterns in Frontal and Temporal Lobe Predict Semantic Clustering during Memory Search},
	volume = {32},
	issn = {0270-6474},
	doi = {10.1523/JNEUROSCI.5321-11.2012},
	pages = {8871--8878},
	number = {26},
	journaltitle = {Journal of Neuroscience},
	author = {Manning, {JR} and Sperling, {MR} and Sharan, A and Rosenberg, {EA} and Kahana, {MJ}},
	date = {2012},
	note = {Type: Journal Article},
}

@article{martin_decoding_2018,
	title = {Decoding Inner Speech Using Electrocorticography: Progress and Challenges Toward a Speech Prosthesis},
	volume = {12},
	issn = {1662-453X},
	doi = {10.3389/fnins.2018.00422},
	journaltitle = {Frontiers in Neuroscience},
	author = {Martin, S. and Iturrate, I and Millan, {JD} and Knight, {RT} and Pasley, {BN}},
	date = {2018},
	note = {Type: Journal Article},
	keywords = {Brain-computer interface, Decoding, electrocorticography, inner speech, neuroprosthetics},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\VRCEG7NG\\Martin et al. - 2018 - Decoding Inner Speech Using Electrocorticography .pdf:application/pdf},
}

@article{martin_decoding_2014,
	title = {Decoding spectrotemporal features of overt and covert speech from the human cortex},
	volume = {7},
	issn = {1662-6443},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/24904404},
	doi = {10.3389/fneng.2014.00014},
	pages = {14},
	journaltitle = {Front Neuroeng},
	author = {Martin, S. and Brunner, P. and Holdgraf, C. and Heinze, H. J. and Crone, N. E. and Rieger, J. and Schalk, G. and Knight, R. T. and Pasley, B. N.},
	date = {2014},
	note = {Type: Journal Article},
	keywords = {electrocorticography, covert speech, decoding model, pattern recognition, speech production},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\S88WQUZT\\Martin et al. - 2014 - Decoding spectrotemporal features of overt and cov.pdf:application/pdf},
}

@book{mckinney_python_2018,
	location = {Sebastopol, California},
	edition = {Second edition.},
	title = {Python for data analysis : data wrangling with pandas, {NumPy}, and {IPython}},
	isbn = {1-4919-5766-2 978-1-4919-5766-0},
	pagetotal = {xvi, 524 pages},
	publisher = {O'Reilly Media, Inc.},
	author = {{McKinney}, Wes},
	date = {2018},
	note = {Type: Book},
}

@article{mehri_samplernn_2016,
	title = {{SampleRNN}: An unconditional end-to-end neural audio generation model},
	journaltitle = {{arXiv} preprint {arXiv}:1612.07837},
	author = {Mehri, Soroush and Kumar, Kundan and Gulrajani, Ishaan and Kumar, Rithesh and Jain, Shubham and Sotelo, Jose and Courville, Aaron and Bengio, Yoshua},
	date = {2016},
	note = {Type: Journal Article},
}

@article{mesgarani_phonetic_2014,
	title = {Phonetic Feature Encoding in Human Superior Temporal Gyrus},
	volume = {343},
	issn = {0036-8075},
	doi = {10.1126/science.1245994},
	pages = {1006--1010},
	number = {6174},
	journaltitle = {Science},
	author = {Mesgarani, N and Cheung, C and Johnson, K and Chang, {EF}},
	date = {2014},
	note = {Type: Journal Article},
}

@article{milsap_keyword_2019,
	title = {Keyword Spotting Using Human Electrocorticographic Recordings},
	volume = {13},
	issn = {1662-453X},
	doi = {10.3389/fnins.2019.00060},
	pages = {60},
	journaltitle = {Frontiers in Neuroscience},
	author = {Milsap, G and Collard, M and Coogan, C and Rabbani, Q and Wang, {YJ} and Crone, {NE}},
	date = {2019},
	note = {Type: Journal Article},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\3CNDYYF7\\Milsap et al. - 2019 - Keyword Spotting Using Human Electrocorticographic.pdf:application/pdf},
}

@article{milsap_bci2000web_2018,
	title = {{BCI}2000Web and {WebFM}: Browser-Based Tools for Brain Computer Interfaces and Functional Brain Mapping},
	volume = {12},
	issn = {1662-4548},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/30814923},
	doi = {10.3389/fnins.2018.01030},
	pages = {1030},
	journaltitle = {Front Neurosci},
	author = {Milsap, G. and Collard, M. and Coogan, C. and Crone, N. E.},
	date = {2018},
	note = {Type: Journal Article},
}

@article{moses_real-time_2018,
	title = {Real-time classification of auditory sentences using evoked cortical activity in humans},
	volume = {15},
	issn = {1741-2560},
	doi = {10.1088/1741-2552/aaab6f},
	number = {3},
	journaltitle = {Journal of Neural Engineering},
	author = {Moses, {DA} and Leonard, {MK} and Chang, {EF}},
	date = {2018},
	note = {Type: Journal Article},
}

@article{moses_neural_2016,
	title = {Neural speech recognition: continuous phoneme decoding using spatiotemporal representations of human cortical activity},
	volume = {13},
	issn = {1741-2560},
	doi = {10.1088/1741-2560/13/5/056004},
	number = {5},
	journaltitle = {Journal of Neural Engineering},
	author = {Moses, {DA} and Mesgarani, N and Leonard, {MK} and Chang, {EF}},
	date = {2016},
	note = {Type: Journal Article},
}

@book{mtui_fitzgeralds_2017,
	location = {Philadelphia, {PA}},
	edition = {Edition 7.},
	title = {Fitzgerald's clinical neuroanatomy and neuroscience},
	isbn = {9780702058325 (pbk. alk. paper)},
	pagetotal = {xvii, 381 pages},
	publisher = {Elsevier},
	author = {Mtui, Estomih and Gruener, Gregory and Dockery, Peter and Fitzgerald, M. J. T.},
	date = {2017},
	note = {Type: Book},
}

@article{mugler_direct_2014,
	title = {Direct classification of all American English phonemes using signals from functional speech motor cortex},
	volume = {11},
	issn = {1741-2560},
	doi = {10.1088/1741-2560/11/3/035015},
	number = {3},
	journaltitle = {Journal of Neural Engineering},
	author = {Mugler, {EM} and Patton, {JL} and Flint, {RD} and Wright, {ZA} and Schuele, {SU} and Rosenow, J and Shih, {JJ} and Krusienski, {DJ} and Slutzky, {MW}},
	date = {2014},
	note = {Type: Journal Article},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\I7W9QRH6\\Mugler et al. - 2014 - Direct classification of all American English phon.pdf:application/pdf},
}

@article{ojemann_cortical_1989,
	title = {Cortical language localization in left, dominant hemisphere: an electrical stimulation mapping investigation in 117 patients},
	volume = {71},
	pages = {316--326},
	number = {3},
	journaltitle = {Journal of neurosurgery},
	author = {Ojemann, George and Ojemann, Jeff and Lettich, {EREEGT} and Berger, M},
	date = {1989},
	note = {Type: Journal Article},
}

@article{oord_wavenet_2016,
	title = {Wavenet: A generative model for raw audio},
	journaltitle = {{arXiv} preprint {arXiv}:1609.03499},
	author = {Oord, Aaron van den and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
	date = {2016},
	note = {Type: Journal Article},
}

@article{pesaran_investigating_2018,
	title = {Investigating large-scale brain dynamics using field potential recordings: analysis and interpretation},
	volume = {21},
	issn = {1097-6256},
	doi = {10.1038/s41593-018-0171-8},
	pages = {903--919},
	number = {7},
	journaltitle = {Nature Neuroscience},
	author = {Pesaran, B and Vinck, M and Einevoll, {GT} and Sirota, A and Fries, P and Siegel, M and Truccolo, W and Schroeder, {CE} and Srinivasan, R},
	date = {2018},
	note = {Type: Journal Article},
}

@article{rabbani_potential_2019,
	title = {The Potential for a Speech Brain-Computer Interface Using Chronic Electrocorticography},
	volume = {16},
	issn = {1878-7479},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/30617653},
	doi = {10.1007/s13311-018-00692-2},
	pages = {144--165},
	number = {1},
	journaltitle = {Neurotherapeutics},
	author = {Rabbani, Q. and Milsap, G. and Crone, N. E.},
	date = {2019},
	note = {Type: Journal Article},
}

@article{racine_cygwin_2000,
	title = {The Cygwin tools: a {GNU} toolkit for Windows},
	volume = {15},
	issn = {0883-7252},
	pages = {331--341},
	number = {3},
	journaltitle = {Journal of Applied Econometrics},
	author = {Racine, Jeffrey},
	date = {2000},
	note = {Type: Journal Article},
}

@book{redkar_pro_2004,
	location = {Berkeley, {CA} New York},
	title = {Pro {MSMQ} : Microsoft Message queue programming},
	isbn = {1-59059-346-4},
	pagetotal = {xxi, 423 p.},
	publisher = {Apress ; Distributed to the Book trade in the United States by Springer-Verlag},
	author = {Redkar, Arohi},
	date = {2004},
	note = {Type: Book},
}

@article{richard_persistence_1995,
	title = {Persistence of distal motor control in the locked in syndrome. Review of 11 patients},
	volume = {33},
	issn = {0031-1758},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/8584298},
	doi = {10.1038/sc.1995.135},
	pages = {640--6},
	number = {11},
	journaltitle = {Paraplegia},
	author = {Richard, I. and Péreon, Y. and Guiheneu, P. and Nogues, B. and Perrouin-Verbe, B. and Mathe, J. F.},
	date = {1995},
	note = {Type: Journal Article},
}

@article{rupp_semantic_2017,
	title = {Semantic attributes are encoded in human electrocorticographic signals during visual object recognition},
	volume = {148},
	issn = {1053-8119},
	doi = {10.1016/j.neuroimage.2016.12.074},
	pages = {318--329},
	journaltitle = {Neuroimage},
	author = {Rupp, K and Roos, M and Milsap, G and Caceres, C and Ratto, C and Chevillet, M and Crone, {NE} and Wolmetz, M},
	date = {2017},
	note = {Type: Journal Article},
}

@inproceedings{sainath_convolutional_nodate,
	title = {Convolutional neural networks for small-footprint keyword spotting},
	booktitle = {Sixteenth Annual Conference of the International Speech Communication Association},
	author = {Sainath, Tara N and Parada, Carolina},
	note = {Type: Conference Proceedings},
}

@article{schalk_bci2000_2004,
	title = {{BCI}2000: A general-purpose, brain-computer interface ({BCI}) system},
	volume = {51},
	issn = {0018-9294},
	doi = {10.1109/TBME.2004.827072},
	pages = {1034--1043},
	number = {6},
	journaltitle = {Ieee Transactions on Biomedical Engineering},
	author = {Schalk, G and {McFarland}, {DJ} and Hinterberger, T and Birbaumer, N and Wolpaw, {JR}},
	date = {2004},
	note = {Type: Journal Article},
}

@article{schalk_can_2010,
	title = {Can Electrocorticography ({ECoG}) Support Robust and Powerful Brain-Computer Interfaces?},
	volume = {3},
	issn = {1662-6443},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/20631853},
	doi = {10.3389/fneng.2010.00009},
	pages = {9},
	journaltitle = {Front Neuroeng},
	author = {Schalk, G.},
	date = {2010},
	note = {Type: Journal Article},
}

@book{schalk_practical_2010,
	location = {London ; New York},
	title = {A practical guide to brain-computer interfacing with {BCI}2000 : general-purpose software for brain-computer interface research, data acquisition, stimulus presentation, and brain monitoring},
	isbn = {9781849960915 (hardcover alk. paper)},
	pagetotal = {xxii, 260 p.},
	publisher = {Springer},
	author = {Schalk, Gerwin and Mellinger, Jürgen},
	date = {2010},
	note = {Type: Book},
}

@article{schreiber_pomegranate_2018,
	title = {pomegranate: Fast and Flexible Probabilistic Modeling in Python},
	volume = {18},
	issn = {1532-4435},
	journaltitle = {Journal of Machine Learning Research},
	author = {Schreiber, J},
	date = {2018},
	note = {Type: Journal Article},
}

@article{shokoueinejad_progress_2019,
	title = {Progress in the Field of Micro-Electrocorticography},
	volume = {10},
	issn = {2072-666X},
	doi = {10.3390/mi10010062},
	number = {1},
	journaltitle = {Micromachines},
	author = {Shokoueinejad, M and Park, {DW} and Jung, {YH} and Brodnick, {SK} and Novello, J and Dingle, A and Swanson, {KI} and Baek, {DH} and Suminski, {AJ} and Lake, {WB} and Ma, {ZQ} and Williams, J},
	date = {2019},
	note = {Type: Journal Article},
}

@book{shpigor_instant_2013,
	title = {Instant {MinGW} Starter},
	isbn = {1-84969-563-6},
	publisher = {Packt Publishing Ltd},
	author = {Shpigor, Ilya},
	date = {2013},
	note = {Type: Book},
}

@article{sinai_electrocorticographic_2005,
	title = {Electrocorticographic high gamma activity versus electrical cortical stimulation mapping of naming},
	volume = {128},
	issn = {0006-8950},
	doi = {10.1093/brain/awh491},
	pages = {1556--1570},
	journaltitle = {Brain},
	author = {Sinai, A and Bowers, {CW} and Crainiceanu, {CM} and Boatman, D and Gordon, B and Lesser, {RP} and Lenz, {FA} and Crone, {NE}},
	date = {2005},
	note = {Type: Journal Article},
}

@article{smith_locked-syndrome_2005,
	title = {Locked-in syndrome},
	volume = {330},
	issn = {0959-8138},
	pages = {406--409},
	number = {7488},
	journaltitle = {Bmj},
	author = {Smith, Eimear and Delargy, Mark},
	date = {2005},
	note = {Type: Journal Article},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\2HHCRR4U\\Smith and Delargy - 2005 - Locked-in syndrome.pdf:application/pdf;PubMed Central Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\TC9U2IQP\\Smith and Delargy - 2005 - Locked-in syndrome.pdf:application/pdf},
}

@book{snyder_activemq_2011,
	location = {Greenwich Conn.},
	title = {{ActiveMQ} in action},
	isbn = {9781933988948 (pbk.) 1933988940 (pbk.)},
	pagetotal = {xxii, 382 p.},
	publisher = {Manning},
	author = {Snyder, Bruce and Bosnanac, Dejan and Davies, Rob},
	date = {2011},
	note = {Type: Book},
}

@article{soman_using_2015,
	title = {Using brain computer interface for synthesized speech communication for the physically disabled},
	volume = {46},
	issn = {1877-0509},
	pages = {292--298},
	journaltitle = {Procedia Computer Science},
	author = {Soman, Sumit and Murthy, {BK}},
	date = {2015},
	note = {Type: Journal Article},
}

@article{stark_source-filter-based_2011,
	title = {Source-Filter-Based Single-Channel Speech Separation Using Pitch Information},
	volume = {19},
	issn = {1558-7916},
	doi = {10.1109/TASL.2010.2047419},
	pages = {242--255},
	number = {2},
	journaltitle = {Ieee Transactions on Audio Speech and Language Processing},
	author = {Stark, M and Wohlmayr, M and Pernkopf, F},
	date = {2011},
	note = {Type: Journal Article},
}

@inproceedings{taal_short-time_nodate,
	title = {A short-time objective intelligibility measure for time-frequency weighted noisy speech},
	isbn = {1-4244-4295-8},
	pages = {4214--4217},
	booktitle = {2010 {IEEE} international conference on acoustics, speech and signal processing},
	publisher = {{IEEE}},
	author = {Taal, Cees H and Hendriks, Richard C and Heusdens, Richard and Jensen, Jesper},
	note = {Type: Conference Proceedings},
}

@article{tourville_diva_2011,
	title = {The {DIVA} model: A neural theory of speech acquisition and production},
	volume = {26},
	issn = {0169-0965},
	pages = {952--981},
	number = {7},
	journaltitle = {Language and cognitive processes},
	author = {Tourville, Jason A and Guenther, Frank H},
	date = {2011},
	note = {Type: Journal Article},
}

@article{vale_outcome_2013,
	title = {Outcome and complications of chronically implanted subdural electrodes for the treatment of medically resistant epilepsy},
	volume = {115},
	issn = {0303-8467},
	doi = {10.1016/j.clineuro.2012.10.007},
	pages = {985--990},
	number = {7},
	journaltitle = {Clinical Neurology and Neurosurgery},
	author = {Vale, {FL} and Pollock, G and Dionisio, J and Benbadis, {SR} and Tatum, {WO}},
	date = {2013},
	note = {Type: Journal Article},
}

@article{valin_real-time_2019,
	title = {A real-time wideband neural vocoder at 1.6 kb/s using {LPCNet}},
	journaltitle = {{arXiv} preprint {arXiv}:1903.12087},
	author = {Valin, Jean-Marc and Skoglund, Jan},
	date = {2019},
	note = {Type: Journal Article},
}

@article{vansteensel_fully_2016,
	title = {Fully Implanted Brain-Computer Interface in a Locked-In Patient with {ALS}},
	volume = {375},
	issn = {0028-4793},
	doi = {10.1056/NEJMoa1608085},
	pages = {2060--2066},
	number = {21},
	journaltitle = {New England Journal of Medicine},
	author = {Vansteensel, {MJ} and Pels, {EGM} and Bleichner, {MG} and Branco, {MP} and Denison, T and Freudenburg, {ZV} and Gosselaar, P and Leinders, S and Ottens, {TH} and Van den Boom, {MA} and Van Rijen, {PC} and Aarnoutse, {EJ} and Ramsey, {NF}},
	date = {2016},
	note = {Type: Journal Article},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\BZ86WRCZ\\Vansteensel et al. - 2016 - Fully Implanted Brain–Computer Interface in a Lock.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\GIG95D3H\\NEJMoa1608085.html:text/html},
}

@book{videla_rabbitmq_2012,
	location = {Shelter Island},
	title = {{RabbitMQ} in Action : {DISTRIBUTED} {MESSAGING} {FOR} {EVERYONE}},
	isbn = {978-1-935182-97-9},
	url = {Publisher description http://www.loc.gov/catdir/enhancements/fy1216/2011277787-d.html},
	pagetotal = {xxiv, 288 pages},
	publisher = {{MANNING}},
	author = {Videla, Alvaro and Williams, Jason J. W.},
	date = {2012},
	note = {Type: Book},
}

@article{wang_decoding_2011,
	title = {Decoding semantic information from human electrocorticographic ({ECoG}) signals},
	volume = {2011},
	issn = {1557-170X},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/22255777},
	doi = {10.1109/IEMBS.2011.6091553},
	pages = {6294--8},
	journaltitle = {Conf Proc {IEEE} Eng Med Biol Soc},
	author = {Wang, W. and Degenhart, A. D. and Sudre, G. P. and Pomerleau, D. A. and Tyler-Kabara, E. C.},
	date = {2011},
	note = {Type: Journal Article},
}

@book{wernicke_aphasische_1874,
	title = {Der aphasische Symptomencomplex: eine psychologische Studie auf anatomischer Basis},
	publisher = {Cohn.},
	author = {Wernicke, Carl},
	date = {1874},
	note = {Type: Book},
}

@article{wolpaw_brain-computer_2002,
	title = {Brain-computer interfaces for communication and control},
	volume = {113},
	issn = {1388-2457},
	url = {https://www.ncbi.nlm.nih.gov/pubmed/12048038},
	doi = {10.1016/s1388-2457(02)00057-3},
	pages = {767--91},
	number = {6},
	journaltitle = {Clin Neurophysiol},
	author = {Wolpaw, J. R. and Birbaumer, N. and {McFarland}, D. J. and Pfurtscheller, G. and Vaughan, T. M.},
	date = {2002},
	note = {Type: Journal Article},
}

@article{zeiler_adadelta_2012,
	title = {Adadelta: an adaptive learning rate method},
	journaltitle = {{arXiv} preprint {arXiv}:1212.5701},
	author = {Zeiler, Matthew D},
	date = {2012},
	note = {Type: Journal Article},
}

@incollection{gunduz_deep_2020,
	location = {Cham},
	title = {Deep Brain Stimulation: Emerging Technologies and Applications},
	isbn = {978-3-030-43395-6},
	url = {https://doi.org/10.1007/978-3-030-43395-6_6},
	shorttitle = {Deep Brain Stimulation},
	abstract = {Deep brain stimulation ({DBS}) is a neurosurgical technique that consists of continuous delivery of electrical pulses through chronically implanted electrodes connected to a neurostimulator, programmable in amplitude, pulse width, frequency, and stimulation channel. {DBS} is a promising treatment option for addressing severe and drug-resistant movement disorders. The success of {DBS} therapy stems from a combination of surgical implantation techniques, device technologies, and clinical programming strategies. Changes in device settings require highly trained and experienced clinicians to achieve maximal therapeutic benefit for each targeted symptom, and optimization of stimulation parameters can take many clinic visits. Thus, the development of innovative {DBS} technologies that can optimize the clinical implementation of {DBS} will lead to wider-scale utilization. This chapter aims to discuss engineering approaches that have the potential to improve clinical outcomes of {DBS}, focusing on the development novel temporal patterns, innovative electrode designs, computational models to guide stimulation, closed-loop {DBS}, emerging clinical indications, and future noninvasive strategies.},
	pages = {223--243},
	booktitle = {Neural Engineering},
	publisher = {Springer International Publishing},
	author = {Gunduz, Aysegul},
	editor = {He, Bin},
	urldate = {2020-09-29},
	date = {2020},
	langid = {english},
	doi = {10.1007/978-3-030-43395-6_6},
	keywords = {Ablation, Basal ganglia, Deep brain stimulation, Implantable pulse generator, Parkinson’s disorder, Stereotactic surgery, Thalamus, Tremor},
	file = {Springer Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\IZMUJP8I\\Gunduz - 2020 - Deep Brain Stimulation Emerging Technologies and .pdf:application/pdf},
}

@article{marshel_functional_2011,
	title = {Functional Specialization of Seven Mouse Visual Cortical Areas},
	volume = {72},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627311010464},
	doi = {10.1016/j.neuron.2011.12.004},
	abstract = {To establish the mouse as a genetically tractable model for high-order visual processing, we characterized fine-scale retinotopic organization of visual cortex and determined functional specialization of layer 2/3 neuronal populations in seven retinotopically identified areas. Each area contains a distinct visuotopic representation and encodes a unique combination of spatiotemporal features. Areas {LM}, {AL}, {RL}, and {AM} prefer up to three times faster temporal frequencies and significantly lower spatial frequencies than V1, while V1 and {PM} prefer high spatial and low temporal frequencies. {LI} prefers both high spatial and temporal frequencies. All extrastriate areas except {LI} increase orientation selectivity compared to V1, and three areas are significantly more direction selective ({AL}, {RL}, and {AM}). Specific combinations of spatiotemporal representations further distinguish areas. These results reveal that mouse higher visual areas are functionally distinct, and separate groups of areas may be specialized for motion-related versus pattern-related computations, perhaps forming pathways analogous to dorsal and ventral streams in other species.},
	pages = {1040--1054},
	number = {6},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Marshel, James H. and Garrett, Marina E. and Nauhaus, Ian and Callaway, Edward M.},
	urldate = {2020-10-05},
	date = {2011-12-22},
	langid = {english},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\JVIWVUGM\\Marshel et al. - 2011 - Functional Specialization of Seven Mouse Visual Co.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\CYCBBYYH\\S0896627311010464.html:text/html},
}

@article{wang_network_2012,
	title = {Network Analysis of Corticocortical Connections Reveals Ventral and Dorsal Processing Streams in Mouse Visual Cortex},
	volume = {32},
	rights = {Copyright © 2012 the authors 0270-6474/12/324386-14\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/32/13/4386},
	doi = {10.1523/JNEUROSCI.6063-11.2012},
	abstract = {Much of the information used for visual perception and visually guided actions is processed in complex networks of connections within the cortex. To understand how this works in the normal brain and to determine the impact of disease, mice are promising models. In primate visual cortex, information is processed in a dorsal stream specialized for visuospatial processing and guided action and a ventral stream for object recognition. Here, we traced the outputs of 10 visual areas and used quantitative graph analytic tools of modern network science to determine, from the projection strengths in 39 cortical targets, the community structure of the network. We found a high density of the cortical graph that exceeded that shown previously in monkey. Each source area showed a unique distribution of projection weights across its targets (i.e., connectivity profile) that was well fit by a lognormal function. Importantly, the community structure was strongly dependent on the location of the source area: outputs from medial/anterior extrastriate areas were more strongly linked to parietal, motor, and limbic cortices, whereas lateral extrastriate areas were preferentially connected to temporal and parahippocampal cortices. These two subnetworks resemble dorsal and ventral cortical streams in primates, demonstrating that the basic layout of cortical networks is conserved across species.},
	pages = {4386--4399},
	number = {13},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Wang, Quanxin and Sporns, Olaf and Burkhalter, Andreas},
	urldate = {2020-10-05},
	date = {2012-03-28},
	langid = {english},
	pmid = {22457489},
	note = {Publisher: Society for Neuroscience
Section: Articles},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\2NTY49KT\\Wang et al. - 2012 - Network Analysis of Corticocortical Connections Re.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\YWC9K75C\\4386.html:text/html},
}

@article{murakami_functional_2017,
	title = {Functional Segregation and Development of Mouse Higher Visual Areas},
	volume = {37},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.0731-17.2017},
	doi = {10.1523/JNEUROSCI.0731-17.2017},
	pages = {9424--9437},
	number = {39},
	journaltitle = {The Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Murakami, Tomonari and Matsui, Teppei and Ohki, Kenichi},
	urldate = {2020-10-06},
	date = {2017-09-27},
	langid = {english},
	file = {Murakami et al. - 2017 - Functional Segregation and Development of Mouse Hi.pdf:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\BBHCRDKN\\Murakami et al. - 2017 - Functional Segregation and Development of Mouse Hi.pdf:application/pdf},
}

@article{bowers_what_2011,
	title = {What is a grandmother cell? And how would you know if you found one?},
	volume = {23},
	issn = {0954-0091},
	url = {https://doi.org/10.1080/09540091.2011.568608},
	doi = {10.1080/09540091.2011.568608},
	shorttitle = {What is a grandmother cell?},
	abstract = {The key claim associated with a grandmother cell theory is that single neurons selectively represent one complex ‘thing’ (e.g. object and face). However, this theory is often mischaracterised in the cognitive and neuroscience literatures. I summarise two common confusions here. First, critics of grandmother cells often fail to distinguish between the selectivity and sparseness of neural firing and, as a result, predict (incorrectly) that one and only one neuron should fire in response to a given input. Second, critics often fail to distinguish between what a neuron responds to and what it represents – as detailed below – and as a result, predict (incorrectly) that a grandmother cell should fire in response to one and only one thing. I argue that these two confusions often lead to the premature rejection of grandmother cell theories.},
	pages = {91--95},
	number = {2},
	journaltitle = {Connection Science},
	author = {Bowers, Jeffrey S.},
	urldate = {2020-10-06},
	date = {2011-06-01},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/09540091.2011.568608},
	keywords = {distributed representation, grandmother cell, parallel distributed processing},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\UWXLKTFQ\\Bowers - 2011 - What is a grandmother cell And how would you know.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\3RYTIU6E\\09540091.2011.html:text/html},
}

@article{barwich_value_2019,
	title = {The Value of Failure in Science: The Story of Grandmother Cells in Neuroscience},
	volume = {13},
	issn = {1662-4548},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6822296/},
	doi = {10.3389/fnins.2019.01121},
	shorttitle = {The Value of Failure in Science},
	abstract = {The annals of science are filled with successes. Only in footnotes do we hear about the failures, the cul-de-sacs, and the forgotten ideas. Failure is how research advances. Yet it hardly features in theoretical perspectives on science. That is a mistake. Failures, whether clear-cut or ambiguous, are heuristically fruitful in their own right. Thinking about failure questions our measures of success, including the conceptual foundations of current practice, that can only be transient in an experimental context. This article advances the heuristics of failure analysis, meaning the explicit treatment of certain ideas or models as failures. The value of failures qua being a failure is illustrated with the example of grandmother cells; the contested idea of a hypothetical neuron that encodes a highly specific but complex stimulus, such as the image of one’s grandmother. Repeatedly evoked in popular science and maintained in textbooks, there is sufficient reason to critically review the theoretical and empirical background of this idea.},
	journaltitle = {Frontiers in Neuroscience},
	shortjournal = {Front Neurosci},
	author = {Barwich, Ann-Sophie},
	urldate = {2020-10-06},
	date = {2019-10-24},
	pmid = {31708726},
	pmcid = {PMC6822296},
	keywords = {Gnostic units, grandmother cells, History of Science, Localist theory, localization, Model pluralism, object recogntion, Philosphy of science, Sparse Coding},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\MC98NMKX\\Barwich - 2019 - The Value of Failure in Science The Story of Gran.pdf:application/pdf;Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\DKQ5IPXD\\Barwich - 2019 - The Value of Failure in Science The Story of Gran.pdf:application/pdf;PubMed Central Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\43L37XNT\\Barwich - 2019 - The Value of Failure in Science The Story of Gran.pdf:application/pdf},
}

@article{quiroga_sparse_2008,
	title = {Sparse but not ‘Grandmother-cell’ coding in the medial temporal lobe},
	volume = {12},
	issn = {1364-6613},
	url = {http://www.sciencedirect.com/science/article/pii/S1364661308000235},
	doi = {10.1016/j.tics.2007.12.003},
	abstract = {Although a large number of neuropsychological and imaging studies have demonstrated that the medial temporal lobe ({MTL}) plays an important role in human memory, there are few data regarding the activity of neurons involved in this process. The {MTL} receives massive inputs from visual cortical areas, and evidence over the last decade has consistently shown that {MTL} neurons respond selectively to complex visual stimuli. Here, we focus on how the activity patterns of these cells might reflect the transformation of visual percepts into long-term memories. Given the very sparse and abstract representation of visual information by these neurons, they could in principle be considered as ‘grandmother cells’. However, we give several arguments that make such an extreme interpretation unlikely.},
	pages = {87--91},
	number = {3},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Quiroga, R. Quian and Kreiman, G. and Koch, C. and Fried, I.},
	urldate = {2020-10-06},
	date = {2008-03-01},
	langid = {english},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\2EU7MSZY\\Quiroga et al. - 2008 - Sparse but not ‘Grandmother-cell’ coding in the me.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\9HDIUHKQ\\S1364661308000235.html:text/html},
}

@article{shannon_speech_1995,
	title = {Speech Recognition with Primarily Temporal Cues},
	volume = {270},
	issn = {0036-8075, 1095-9203},
	url = {https://www.sciencemag.org/lookup/doi/10.1126/science.270.5234.303},
	doi = {10.1126/science.270.5234.303},
	pages = {303--304},
	number = {5234},
	journaltitle = {Science},
	shortjournal = {Science},
	author = {Shannon, R. V. and Zeng, F.-G. and Kamath, V. and Wygonski, J. and Ekelid, M.},
	urldate = {2020-10-06},
	date = {1995-10-13},
	langid = {english},
	file = {Shannon et al. - 1995 - Speech Recognition with Primarily Temporal Cues.pdf:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\9FU8J3D9\\Shannon et al. - 1995 - Speech Recognition with Primarily Temporal Cues.pdf:application/pdf},
}

@article{horton_cortical_2005,
	title = {The cortical column: a structure without a function},
	volume = {360},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rstb.2005.1623},
	doi = {10.1098/rstb.2005.1623},
	shorttitle = {The cortical column},
	abstract = {This year, the field of neuroscience celebrates the 50th anniversary of Mountcastle's discovery of the cortical column. In this review, we summarize half a century of research and come to the disappointing realization that the column may have no function. Originally, it was described as a discrete structure, spanning the layers of the somatosensory cortex, which contains cells responsive to only a single modality, such as deep joint receptors or cutaneous receptors. Subsequently, examples of columns have been uncovered in numerous cortical areas, expanding the original concept to embrace a variety of different structures and principles. A ‘column’ now refers to cells in any vertical cluster that share the same tuning for any given receptive field attribute. In striate cortex, for example, cells with the same eye preference are grouped into ocular dominance columns. Unaccountably, ocular dominance columns are present in some species, but not others. In principle, it should be possible to determine their function by searching for species differences in visual performance that correlate with their presence or absence. Unfortunately, this approach has been to no avail; no visual faculty has emerged that appears to require ocular dominance columns. Moreover, recent evidence has shown that the expression of ocular dominance columns can be highly variable among members of the same species, or even in different portions of the visual cortex in the same individual. These observations deal a fatal blow to the idea that ocular dominance columns serve a purpose. More broadly, the term ‘column’ also denotes the periodic termination of anatomical projections within or between cortical areas. In many instances, periodic projections have a consistent relationship with some architectural feature, such as the cytochrome oxidase patches in V1 or the stripes in V2. These tissue compartments appear to divide cells with different receptive field properties into distinct processing streams. However, it is unclear what advantage, if any, is conveyed by this form of columnar segregation. Although the column is an attractive concept, it has failed as a unifying principle for understanding cortical function. Unravelling the organization of the cerebral cortex will require a painstaking description of the circuits, projections and response properties peculiar to cells in each of its various areas.},
	pages = {837--862},
	number = {1456},
	journaltitle = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	shortjournal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	author = {Horton, Jonathan C and Adams, Daniel L},
	urldate = {2020-10-06},
	date = {2005-04-29},
	note = {Publisher: Royal Society},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\N8F9NLZS\\Horton and Adams - 2005 - The cortical column a structure without a functio.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\FYQZVLR9\\rstb.2005.html:text/html},
}

@article{bisley_neuronal_2003,
	title = {Neuronal Activity in the Lateral Intraparietal Area and Spatial Attention},
	volume = {299},
	issn = {0036-8075, 1095-9203},
	url = {https://science.sciencemag.org/content/299/5603/81},
	doi = {10.1126/science.1077395},
	abstract = {Although the parietal cortex has been implicated in the neural processes underlying visual attention, the nature of its contribution is not well understood. We tracked attention in the monkey and correlated the activity of neurons in the lateral intraparietal area ({LIP}) with the monkey's attentional performance. The ensemble activity in {LIP} across the entire visual field describes the spatial and temporal dynamics of a monkey's attention. Activity subtending a single location in the visual field describes the attentional priority at that area but does not predict that the monkey will actually attend to or make an eye movement to that location.
Activity in an ensemble of neurons in one area of the monkey's cortex predicts where the animal will focus its attention.
Activity in an ensemble of neurons in one area of the monkey's cortex predicts where the animal will focus its attention.},
	pages = {81--86},
	number = {5603},
	journaltitle = {Science},
	author = {Bisley, James W. and Goldberg, Michael E.},
	urldate = {2020-10-14},
	date = {2003-01-03},
	langid = {english},
	pmid = {12511644},
	note = {Publisher: American Association for the Advancement of Science
Section: Research Article},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\CHB7VJRC\\Bisley and Goldberg - 2003 - Neuronal Activity in the Lateral Intraparietal Are.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\27DEC6VF\\81.html:text/html},
}

@article{valin_hybrid_2018,
	title = {A Hybrid {DSP}/Deep Learning Approach to Real-Time Full-Band Speech Enhancement},
	url = {http://arxiv.org/abs/1709.08243},
	abstract = {Despite noise suppression being a mature area in signal processing, it remains highly dependent on fine tuning of estimator algorithms and parameters. In this paper, we demonstrate a hybrid {DSP}/deep learning approach to noise suppression. A deep neural network with four hidden layers is used to estimate ideal critical band gains, while a more traditional pitch filter attenuates noise between pitch harmonics. The approach achieves significantly higher quality than a traditional minimum mean squared error spectral estimator, while keeping the complexity low enough for real-time operation at 48 {kHz} on a low-power processor.},
	journaltitle = {{arXiv}:1709.08243 [cs, eess]},
	author = {Valin, Jean-Marc},
	urldate = {2020-10-14},
	date = {2018-05-31},
	eprinttype = {arxiv},
	eprint = {1709.08243},
	keywords = {Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing, vocoder},
	file = {arXiv Fulltext PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\KSVZ9B4R\\Valin - 2018 - A Hybrid DSPDeep Learning Approach to Real-Time F.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\KS7XDXHI\\1709.html:text/html},
}

@article{petersen_functional_2007,
	title = {The Functional Organization of the Barrel Cortex},
	volume = {56},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627307007155},
	doi = {10.1016/j.neuron.2007.09.017},
	abstract = {The tactile somatosensory pathway from whisker to cortex in rodents provides a well-defined system for exploring the link between molecular mechanisms, synaptic circuits, and behavior. The primary somatosensory cortex has an exquisite somatotopic map where each individual whisker is represented in a discrete anatomical unit, the “barrel,” allowing precise delineation of functional organization, development, and plasticity. Sensory information is actively acquired in awake behaving rodents and processed differently within the barrel map depending upon whisker-related behavior. The prominence of state-dependent cortical sensory processing is likely to be crucial in our understanding of active sensory perception, experience-dependent plasticity and learning.},
	pages = {339--355},
	number = {2},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Petersen, Carl C. H.},
	urldate = {2020-10-24},
	date = {2007-10-25},
	langid = {english},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\RCSTDXH3\\Petersen - 2007 - The Functional Organization of the Barrel Cortex.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\VKIAHQR6\\S0896627307007155.html:text/html},
}

@article{brecht_body_2017,
	title = {The Body Model Theory of Somatosensory Cortex},
	volume = {94},
	issn = {0896-6273},
	url = {http://www.sciencedirect.com/science/article/pii/S0896627317304567},
	doi = {10.1016/j.neuron.2017.05.018},
	abstract = {I outline a microcircuit theory of somatosensory cortex as a body model serving both for body representation and “body simulation.” A modular model of innervated and non-innervated body parts resides in somatosensory cortical layer 4. This body model is continuously updated and compares to an avatar (an animatable puppet) rather than a mere sensory map. Superficial layers provide context and store sensory memories, whereas layer 5 provides motor output and stores motor memories. I predict that layer-6-to-layer-4 inputs initiate body simulations allowing rehearsal and risk assessment of difficult actions, such as jumps.},
	pages = {985--992},
	number = {5},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Brecht, Michael},
	urldate = {2020-10-24},
	date = {2017-06-07},
	langid = {english},
	keywords = {body model, brain theory, cortical simulation, ownership, rubber hand illusion, somatosensory cortex},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\36NFV2VY\\Brecht - 2017 - The Body Model Theory of Somatosensory Cortex.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\PD6DQVHK\\S0896627317304567.html:text/html},
}

@article{bernardo_local_1990,
	title = {Local axonal trajectories in mouse barrel cortex},
	volume = {82},
	issn = {0014-4819},
	doi = {10.1007/BF00231244},
	abstract = {Quantitative studies were made of the distribution of labeled intracortical axons after focal injections of horseradish peroxidase ({HRP}) into mouse barrel cortex, in vitro. The pattern of labeled fibers was compared to that of labeled cell bodies with respect to the barrel map in layer {IV}. We analyzed 4 cortices with injections in supragranular layers and centered above a single barrel row. Computer microscope/image analysis routines were used to collect the data and to perform various statistical analyses on them. The distributions of both labeled cells and fibers in layer {IV} and in the infragranular layers show strong connectional tendencies between barrels representing a whisker row. This result is consistent with single unit recordings from barrel cortex. Fiber labeling is more widespread than cell body labeling in layer {IV}. In addition, the fibers show a directional bias into the adjacent anterior barrel row (e.g., C----D, D----E). In earlier 2-deoxyglucose (2-{DG}) studies of behaving animals, the anterior barrel rows were more heavily labeled; inter-row projections are therefore predominantly from less active to more active barrel columns. These data show that labeled fiber distribution differs from the distribution pattern of labeled cell bodies. The findings indicate that integration of information between whisker rows within barrel cortex involves asymmetrical connections within layer {IV} and infragranular layers.},
	pages = {247--253},
	number = {2},
	journaltitle = {Experimental Brain Research},
	shortjournal = {Exp Brain Res},
	author = {Bernardo, K. L. and {McCasland}, J. S. and Woolsey, T. A.},
	date = {1990},
	pmid = {2286230},
	keywords = {Animals, Axons, Cerebral Cortex, Horseradish Peroxidase, Image Interpretation, Computer-Assisted, Mice},
}

@article{erzurumlu_how_2020,
	title = {How the Barrel Cortex Became a Working Model for Developmental Plasticity: A Historical Perspective},
	volume = {40},
	rights = {Copyright © 2020 the authors},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/40/34/6460},
	doi = {10.1523/JNEUROSCI.0582-20.2020},
	shorttitle = {How the Barrel Cortex Became a Working Model for Developmental Plasticity},
	abstract = {For half a century now, the barrel cortex of common laboratory rodents has been an exceptionally useful model for studying the formation of topographically organized maps, neural patterning, and plasticity, both in development and in maturity. We present a historical perspective on how barrels were discovered, and how thereafter, they became a workhorse for developmental neuroscientists and for studies on brain plasticity and activity-dependent modeling of brain circuits. What is particularly remarkable about this sensory system is a cellular patterning that is induced by signals derived from the sensory receptors surrounding the snout whiskers and transmitted centrally to the brainstem (barrelettes), the thalamus (barreloids), and the neocortex (barrels). Injury to the sensory receptors shortly after birth leads to predictable pattern alterations at all levels of the system. Mouse genetics have increased our understanding of how barrels are constructed and revealed the interplay of the molecular programs that direct axon growth and cell specification, with activity-dependent mechanisms. There is an ever-rising interest in this sensory system as a neurobiological model to study development of somatotopy, patterning, and plasticity at both the morphologic and physiological levels. This article is part of a group of articles commemorating the 50th anniversary of the Society for Neuroscience.},
	pages = {6460--6473},
	number = {34},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Erzurumlu, Reha S. and Gaspar, Patricia},
	urldate = {2020-10-24},
	date = {2020-08-19},
	langid = {english},
	pmid = {32817388},
	note = {Publisher: Society for Neuroscience
Section: Viewpoints},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\JB3XVPAV\\Erzurumlu and Gaspar - 2020 - How the Barrel Cortex Became a Working Model for D.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\EY626R3B\\6460.html:text/html},
}

@article{petersen_sensorimotor_2019,
	title = {Sensorimotor processing in the rodent barrel cortex},
	volume = {20},
	rights = {2019 Springer Nature Limited},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/s41583-019-0200-y},
	doi = {10.1038/s41583-019-0200-y},
	abstract = {Tactile sensory information from facial whiskers provides nocturnal tunnel-dwelling rodents, including mice and rats, with important spatial and textural information about their immediate surroundings. Whiskers are moved back and forth to scan the environment (whisking), and touch signals from each whisker evoke sparse patterns of neuronal activity in whisker-related primary somatosensory cortex ({wS}1; barrel cortex). Whisking is accompanied by desynchronized brain states and cell-type-specific changes in spontaneous and evoked neuronal activity. Tactile information, including object texture and location, appears to be computed in {wS}1 through integration of motor and sensory signals. {wS}1 also directly controls whisker movements and contributes to learned, whisker-dependent, goal-directed behaviours. The cell-type-specific neuronal circuitry in {wS}1 that contributes to whisker sensory perception is beginning to be defined.},
	pages = {533--546},
	number = {9},
	journaltitle = {Nature Reviews Neuroscience},
	author = {Petersen, Carl C. H.},
	urldate = {2020-10-24},
	date = {2019-09},
	langid = {english},
	note = {Number: 9
Publisher: Nature Publishing Group},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\T7LAS6X3\\Petersen - 2019 - Sensorimotor processing in the rodent barrel corte.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\7RENTC25\\s41583-019-0200-y.html:text/html},
}

@article{marder_central_2001,
	title = {Central pattern generators and the control of rhythmic movements},
	volume = {11},
	issn = {0960-9822},
	url = {http://www.sciencedirect.com/science/article/pii/S0960982201005814},
	doi = {10.1016/S0960-9822(01)00581-4},
	abstract = {Central pattern generators are neuronal circuits that when activated can produce rhythmic motor patterns such as walking, breathing, flying, and swimming in the absence of sensory or descending inputs that carry specific timing information. General principles of the organization of these circuits and their control by higher brain centers have come from the study of smaller circuits found in invertebrates. Recent work on vertebrates highlights the importance of neuro-modulatory control pathways in enabling spinal cord and brain stem circuits to generate meaningful motor patterns. Because rhythmic motor patterns are easily quantified and studied, central pattern generators will provide important testing grounds for understanding the effects of numerous genetic mutations on behavior. Moreover, further understanding of the modulation of spinal cord circuitry used in rhythmic behaviors should facilitate the development of new treatments to enhance recovery after spinal cord damage.},
	pages = {R986--R996},
	number = {23},
	journaltitle = {Current Biology},
	shortjournal = {Current Biology},
	author = {Marder, Eve and Bucher, Dirk},
	urldate = {2020-11-03},
	date = {2001-11-27},
	langid = {english},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\5DEMLCKT\\Marder and Bucher - 2001 - Central pattern generators and the control of rhyt.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\65GVA32D\\S0960982201005814.html:text/html},
}

@article{georgopoulos_relations_1982,
	title = {On the relations between the direction of two-dimensional arm movements and cell discharge in primate motor cortex},
	volume = {2},
	rights = {© 1982 by Society for Neuroscience},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/2/11/1527},
	doi = {10.1523/JNEUROSCI.02-11-01527.1982},
	abstract = {The activity of single cells in the motor cortex was recorded while monkeys made arm movements in eight directions (at 45 degrees intervals) in a two-dimensional apparatus. These movements started from the same point and were of the same amplitude. The activity of 606 cells related to proximal arm movements was examined in the task; 323 of the 606 cells were active in that task and were studied in detail. The frequency of discharge of 241 of the 323 cells (74.6\%) varied in an orderly fashion with the direction of movement. Discharge was most intense with movements in a preferred direction and was reduced gradually when movements were made in directions farther and farther away from the preferred one. This resulted in a bell-shaped directional tuning curve. These relations were observed for cell discharge during the reaction time, the movement time, and the period that preceded the earliest changes in the electromyographic activity (approximately 80 msec before movement onset). In about 75\% of the 241 directionally tuned cells, the frequency of discharge, D, was a sinusoidal function of the direction of movement, theta: D = b0 + b1 sin theta + b2cos theta, or, in terms of the preferred direction, theta 0: D = b0 + c1cos (theta - theta0), where b0, b1, b2, and c1 are regression coefficients. Preferred directions differed for different cells so that the tuning curves partially overlapped. The orderly variation of cell discharge with the direction of movement and the fact that cells related to only one of the eight directions of movement tested were rarely observed indicate that movements in a particular direction are not subserved by motor cortical cells uniquely related to that movement. It is suggested, instead, that a movement trajectory in a desired direction might be generated by the cooperation of cells with overlapping tuning curves. The nature of this hypothetical population code for movement direction remains to be elucidated.},
	pages = {1527--1537},
	number = {11},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Georgopoulos, A. P. and Kalaska, J. F. and Caminiti, R. and Massey, J. T.},
	urldate = {2020-11-06},
	date = {1982-11-01},
	langid = {english},
	pmid = {7143039},
	note = {Publisher: Society for Neuroscience
Section: Articles},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\GTGB232L\\Georgopoulos et al. - 1982 - On the relations between the direction of two-dime.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\XYELHQMK\\1527.html:text/html},
}

@article{georgopoulos_neuronal_1986,
	title = {Neuronal population coding of movement direction},
	volume = {233},
	issn = {0036-8075, 1095-9203},
	url = {https://www.sciencemag.org/lookup/doi/10.1126/science.3749885},
	doi = {10.1126/science.3749885},
	pages = {1416--1419},
	number = {4771},
	journaltitle = {Science},
	shortjournal = {Science},
	author = {Georgopoulos, A. and Schwartz, A. and Kettner, R.},
	urldate = {2020-11-06},
	date = {1986-09-26},
	langid = {english},
	file = {Georgopoulos et al. - 1986 - Neuronal population coding of movement direction.pdf:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\HMTWFDTN\\Georgopoulos et al. - 1986 - Neuronal population coding of movement direction.pdf:application/pdf;Georgopoulos et al. - 1986 - Neuronal population coding of movement direction.pdf:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\8UFIPS4G\\Georgopoulos et al. - 1986 - Neuronal population coding of movement direction.pdf:application/pdf},
}

@article{kim_parallel_2015,
	title = {Parallel basal ganglia circuits for voluntary and automatic behaviour to reach rewards},
	volume = {138},
	issn = {0006-8950},
	url = {https://academic.oup.com/brain/article/138/7/1776/254756},
	doi = {10.1093/brain/awv134},
	abstract = {The contributions of topographically distinct basal ganglia circuits to reward-oriented behaviours are unclear. Kim and Hikosaka propose that parallel circuits},
	pages = {1776--1800},
	number = {7},
	journaltitle = {Brain},
	shortjournal = {Brain},
	author = {Kim, Hyoung F. and Hikosaka, Okihide},
	urldate = {2020-11-11},
	date = {2015-07-01},
	langid = {english},
	note = {Publisher: Oxford Academic},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\N69BEACR\\Kim and Hikosaka - 2015 - Parallel basal ganglia circuits for voluntary and .pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\CIPF39KW\\254756.html:text/html},
}

@article{roberts_nucleus_2014,
	title = {Nucleus accumbens neuronal maturation differences in young rats bred for low versus high voluntary running behaviour},
	volume = {592},
	issn = {0022-3751},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4227898/},
	doi = {10.1113/jphysiol.2013.268805},
	abstract = {We compared the nucleus accumbens ({NAc}) transcriptomes of generation 8 (G8), 34-day-old rats selectively bred for low ({LVR}) versus high voluntary running ({HVR}) behaviours in rats that never ran ({LVRnon}-run and {HVRnon}-run), as well as in rats after 6 days of voluntary wheel running ({LVRrun} and {HVRrun}). In addition, the {NAc} transcriptome of wild-type Wistar rats was compared. The purpose of this transcriptomics approach was to generate testable hypotheses as to possible {NAc} features that may be contributing to running motivation differences between lines. Ingenuity Pathway Analysis and Gene Ontology analyses suggested that ‘cell cycle’-related transcripts and the running-induced plasticity of dopamine-related transcripts were lower in {LVR} versus {HVR} rats. From these data, a hypothesis was generated that {LVR} rats might have less {NAc} neuron maturation than {HVR} rats. Follow-up immunohistochemistry in G9–10 {LVRnon}-run rats suggested that the {LVR} line inherently possessed fewer mature medium spiny (Darpp-32-positive) neurons (P {\textless} 0.001) and fewer immature (Dcx-positive) neurons (P {\textless} 0.001) than their G9–10 {HVR} counterparts. However, voluntary running wheel access in our G9–10 {LVRs} uniquely increased their Darpp-32-positive and Dcx-positive neuron densities. In summary, {NAc} cellularity differences and/or the lack of running-induced plasticity in dopamine signalling-related transcripts may contribute to low voluntary running motivation in {LVR} rats.},
	pages = {2119--2135},
	issue = {Pt 10},
	journaltitle = {The Journal of Physiology},
	shortjournal = {J Physiol},
	author = {Roberts, Michael D and Toedebusch, Ryan G and Wells, Kevin D and Company, Joseph M and Brown, Jacob D and Cruthirds, Clayton L and Heese, Alexander J and Zhu, Conan and Rottinghaus, George E and Childs, Thomas E and Booth, Frank W},
	urldate = {2020-11-11},
	date = {2014-05-15},
	pmid = {24665095},
	pmcid = {PMC4227898},
	file = {PubMed Central Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\8Z49G5XJ\\Roberts et al. - 2014 - Nucleus accumbens neuronal maturation differences .pdf:application/pdf},
}

@article{nachev_dynamic_2015,
	title = {Dynamic risk control by human nucleus accumbens},
	volume = {138},
	issn = {0006-8950},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4655342/},
	doi = {10.1093/brain/awv285},
	abstract = {The nucleus accumbens is a key node in the network linking reward to action. Studying a rare series of patients with bilaterally implanted electrodes in the nucleus accumbens, Nachev et al. show that external electrical stimulation of the accumbens dynamically shifts behaviour towards more risky decision making., 
The nucleus accumbens is a key node in the network linking reward to action. Studying a rare series of patients with bilaterally implanted electrodes in the nucleus accumbens, Nachev et al. show that external electrical stimulation of the accumbens dynamically shifts behaviour towards more risky decision making.
, Real-world decisions about reward often involve a complex counterbalance of risk and value. Although the nucleus accumbens has been implicated in the underlying neural substrate, its criticality to human behaviour remains an open question, best addressed with interventional methodology that probes the behavioural consequences of focal neural modulation. Combining a psychometric index of risky decision-making with transient electrical modulation of the nucleus accumbens, here we reveal profound, highly dynamic alteration of the relation between probability of reward and choice during therapeutic deep brain stimulation in four patients with treatment-resistant psychiatric disease. Short-lived phasic electrical stimulation of the region of the nucleus accumbens dynamically altered risk behaviour, transiently shifting the psychometric function towards more risky decisions only for the duration of stimulation. A critical, on-line role of human nucleus accumbens in dynamic risk control is thereby established.},
	pages = {3496--3502},
	number = {12},
	journaltitle = {Brain},
	shortjournal = {Brain},
	author = {Nachev, Parashkev and Lopez-Sosa, Fernando and Gonzalez-Rosa, Javier Jesus and Galarza, Ana and Avecillas, Josue and Pineda-Pardo, Jose Angel and Lopez-Ibor, Juan José and Reneses, Blanca and Barcia, Juan Antonio and Strange, Bryan},
	urldate = {2020-11-11},
	date = {2015-12},
	pmid = {26428667},
	pmcid = {PMC4655342},
	file = {PubMed Central Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\INXUZZNK\\Nachev et al. - 2015 - Dynamic risk control by human nucleus accumbens.pdf:application/pdf},
}

@article{bastian_moving_2011,
	title = {Moving, sensing and learning with cerebellar damage},
	volume = {21},
	issn = {0959-4388},
	url = {http://www.sciencedirect.com/science/article/pii/S0959438811001061},
	doi = {10.1016/j.conb.2011.06.007},
	series = {Sensory and motor systems},
	abstract = {The cerebellum is a subcortical brain structure that is essential for learning and controlling movement. Recent work shows that the cerebellum also plays a role in certain perceptual abilities, beyond what would be expected secondary to poor movement control. This review covers these and other recent advances, focusing on how cerebellar damage affects human abilities ranging from sensory perception to movement control and motor learning.},
	pages = {596--601},
	number = {4},
	journaltitle = {Current Opinion in Neurobiology},
	shortjournal = {Current Opinion in Neurobiology},
	author = {Bastian, Amy J},
	urldate = {2020-11-11},
	date = {2011-08-01},
	langid = {english},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\FGVPPZ8T\\Bastian - 2011 - Moving, sensing and learning with cerebellar damag.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\TPMK3M8J\\S0959438811001061.html:text/html},
}

@article{nawrot_motion_1995,
	title = {Motion perception deficits from midline cerebellar lesions in human},
	volume = {35},
	issn = {0042-6989},
	url = {http://www.sciencedirect.com/science/article/pii/004269899400168L},
	doi = {10.1016/0042-6989(94)00168-L},
	abstract = {Although visual motion processing is commonly thought to be mediated solely by visual cortical areas, this human lesion study suggests that the cerebellum also has a role. We found motion direction discrimination deficits in a group of patients with acute midline cerebellar lesions. Unlike normals and patients with hemispheric cerebellar lesions, these patients with midline lesions were unable to discern a global motion vector in a local stochastic motion display. This resembles the perceptual defect reported following cortical area {MT} lesions in primates. This motion perception deficit may result from damage to a cerebellar mechanism involved in perceptual stabilization. Disruption of this comparator mechanism is sufficient to produce a severe motion perception deficit even though cortical visual processing mechanisms are still intact.},
	pages = {723--731},
	number = {5},
	journaltitle = {Vision Research},
	shortjournal = {Vision Research},
	author = {Nawrot, Mark and Rizzo, Matthew},
	urldate = {2020-11-11},
	date = {1995-03-01},
	langid = {english},
	keywords = {Brain lesions, Cerebellum, Cortical circuits, Motion perception, Subcortical circuits},
	file = {ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\MAK24Z5F\\004269899400168L.html:text/html},
}

@incollection{morton_cerebellar_2009,
	location = {Oxford},
	title = {Cerebellar Lesions and Effects on Posture, Locomotion and Limb Movement},
	isbn = {978-0-08-045046-9},
	url = {http://www.sciencedirect.com/science/article/pii/B9780080450469013048},
	abstract = {The cerebellum is a subcortical structure important for controlling and adapting movements. Damage to the cerebellum results in ataxia (i.e., incoordination) but not loss of movement or paralysis. There are many distinct signs of limb, balance, and gait ataxia, which are exacerbated by moving multiple joints together and by moving quickly. Some cerebellar deficits seem to result from a failure of motor commands to account for mechanical interactions between segments. Others appear to be more related to timing control or generating predictive motor commands. Optimal cerebellar control is maintained through adaptive learning processes, which are important for keeping movements appropriately adjusted for varying environmental demands.},
	pages = {717--722},
	booktitle = {Encyclopedia of Neuroscience},
	publisher = {Academic Press},
	author = {Morton, S. M. and Bastian, A. J.},
	editor = {Squire, Larry R.},
	urldate = {2020-11-11},
	date = {2009-01-01},
	langid = {english},
	doi = {10.1016/B978-008045046-9.01304-8},
	keywords = {Tremor, Ataxia, Coordination, Dysmetria, Gait, Motor, Movement disorder, Multijoint, Stroke},
	file = {ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\VVNLMW4L\\B9780080450469013048.html:text/html},
}

@article{bayley_fate_2006,
	title = {The Fate of Old Memories after Medial Temporal Lobe Damage},
	volume = {26},
	issn = {0270-6474},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2424208/},
	doi = {10.1523/JNEUROSCI.4262-06.2006},
	abstract = {Damage to the hippocampal region and related medial temporal lobe structures (perirhinal, entorhinal, and parahippocampal cortices) impairs new learning (anterograde amnesia) as well as memory for information that was acquired before the damage occurred (retrograde amnesia). We assessed retrograde amnesia with the Autobiographical Memory Interview ({AMI}) and with a news events test in six patients with damage limited primarily to the hippocampal region (H group) and two patients with large medial temporal lobe lesions ({MTL} group). On the news event test, the H group exhibited temporally limited retrograde amnesia covering ∼5 years. On the same test, the {MTL} group exhibited an extensive retrograde amnesia covering decades. Nevertheless, performance was relatively spared for very remote time periods. On the {AMI}, all patients had intact remote autobiographical memory. Because our patients with hippocampal lesions, as well as our patients with large {MTL} lesions, performed normally on the {AMI}, patients who perform poorly on the same test presumably have damage beyond the hippocampus and related structures in the medial temporal lobe. The findings emphasize the difference in the extent of retrograde amnesia associated with hippocampal lesions and large {MTL} lesions.},
	pages = {13311--13317},
	number = {51},
	journaltitle = {The Journal of Neuroscience},
	shortjournal = {J Neurosci},
	author = {Bayley, Peter J. and Hopkins, Ramona O. and Squire, Larry R.},
	urldate = {2020-11-16},
	date = {2006-12-20},
	pmid = {17182781},
	pmcid = {PMC2424208},
	file = {PubMed Central Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\UTNLEPTZ\\Bayley et al. - 2006 - The Fate of Old Memories after Medial Temporal Lob.pdf:application/pdf},
}

@article{alvarez_memory_1994,
	title = {Memory consolidation and the medial temporal lobe: a simple network model.},
	volume = {91},
	issn = {0027-8424},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC44334/},
	shorttitle = {Memory consolidation and the medial temporal lobe},
	abstract = {Some forms of memory have been shown to depend on a system of medial temporal lobe structures that includes the hippocampus and the adjacent cortical areas (entorhinal, perirhinal, and parahippocampal cortex). The role of this system is only temporary, however, as indicated by the fact that, after damage to the medial temporal lobe, recent memories are impaired but very remote memories are intact. Here we review the evidence that the medial temporal lobe memory system is involved in a process of consolidation: memories are initially dependent on this system but gradually become established in other areas of the brain. We then review some of the ideas that have been proposed about the phenomenon of consolidation and suggest a synthesis of these views. Finally, we describe a simple neural network model that captures some key features of consolidation.},
	pages = {7041--7045},
	number = {15},
	journaltitle = {Proceedings of the National Academy of Sciences of the United States of America},
	shortjournal = {Proc Natl Acad Sci U S A},
	author = {Alvarez, P and Squire, L R},
	urldate = {2020-11-17},
	date = {1994-07-19},
	pmid = {8041742},
	pmcid = {PMC44334},
	file = {PubMed Central Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\FN6DJ5IH\\Alvarez and Squire - 1994 - Memory consolidation and the medial temporal lobe.pdf:application/pdf},
}

@article{bayley_medial_2002,
	title = {Medial Temporal Lobe Amnesia: Gradual Acquisition of Factual Information by Nondeclarative Memory},
	volume = {22},
	issn = {0270-6474},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2821083/},
	doi = {10.1523/JNEUROSCI.22-13-05741.2002},
	shorttitle = {Medial Temporal Lobe Amnesia},
	abstract = {Most amnesic patients with damage to the medial temporal lobe retain some capacity to learn new information about facts and events. In many cases, the learning appears to depend on a residual ability to acquire conscious (declarative) knowledge. We have studied the capacity for semantic (fact) learning in the profoundly amnesic patient E.P., who has extensive damage limited primarily to the medial temporal lobe. E.P. was presented with factual information (novel three-word sentences) during 24 study sessions across 12 weeks. E.P. performed much more poorly than controls but demonstrated unmistakable improvement across the sessions, achieving after 12 weeks a score of 18.8\% correct on a cued-recall test and 64.6\% correct on a two-alternative, forced-choice test. Unlike controls, E.P.'s learning was not accompanied by conscious knowledge about which answers were correct. He assigned the same confidence ratings to his correct answers as his incorrect answers. Moreover, on the forced-choice test his response times were identical for correct and incorrect responses. Furthermore, unlike controls, he could not respond correctly when the second word in each sentence was replaced by a synonym. Thus, what E.P. learned was rigidly organized, unavailable as conscious knowledge, and in all respects exhibited the characteristics of nondeclarative memory. Thus, factual information, which is ordinarily learned as declarative (conscious) knowledge and with the participation of the medial temporal lobe, can be acquired as nondeclarative memory, albeit very gradually and in a form that is outside of awareness and that is not represented as factual knowledge. We suggest that E.P.'s learning depended on a process akin to perceptual learning and occurred directly within neocortex.},
	pages = {5741--5748},
	number = {13},
	journaltitle = {The Journal of Neuroscience},
	shortjournal = {J Neurosci},
	author = {Bayley, Peter J. and Squire, Larry R.},
	urldate = {2020-11-17},
	date = {2002-07-01},
	pmid = {12097527},
	pmcid = {PMC2821083},
	file = {PubMed Central Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\CNKESD28\\Bayley and Squire - 2002 - Medial Temporal Lobe Amnesia Gradual Acquisition .pdf:application/pdf},
}

@article{insausti_human_2013,
	title = {Human amnesia and the medial temporal lobe illuminated by neuropsychological and neurohistological findings for patient E.P.},
	volume = {110},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/110/21/E1953},
	doi = {10.1073/pnas.1306244110},
	abstract = {We present neurohistological information for a case of bilateral, symmetrical damage to the medial temporal lobe and well-documented memory impairment. E.P. developed profound memory impairment at age 70 y and then was studied for 14 y He had no capacity for learning facts and events and had retrograde amnesia covering several decades. He also had a modest impairment of semantic knowledge. Neurohistological analysis revealed bilaterally symmetrical lesions of the medial temporal lobe that eliminated the temporal pole, the amygdala, the entorhinal cortex, the hippocampus, the perirhinal cortex, and rostral parahippocampal cortex. The lesion also extended laterally to involve the fusiform gyrus substantially. Last, the superior, inferior, and middle temporal gyri were atrophic, and subjacent white matter was gliotic. Several considerations indicate that E.P.’s severe memory impairment was caused by his medial temporal lesions, whereas his impaired semantic knowledge was caused by lateral temporal damage. His lateral temporal damage also may have contributed to his extensive retrograde amnesia. The findings illuminate the anatomical relationship between memory, perception, and semantic knowledge.},
	pages = {E1953--E1962},
	number = {21},
	journaltitle = {Proceedings of the National Academy of Sciences},
	shortjournal = {{PNAS}},
	author = {Insausti, Ricardo and Annese, Jacopo and Amaral, David G. and Squire, Larry R.},
	urldate = {2020-11-17},
	date = {2013-05-21},
	langid = {english},
	pmid = {23620517},
	note = {{ISBN}: 9781306244114
Publisher: National Academy of Sciences
Section: {PNAS} Plus},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\EAQT2MZB\\Insausti et al. - 2013 - Human amnesia and the medial temporal lobe illumin.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\6K3JWT8E\\E1953.html:text/html},
}

@article{clark_animal_2010,
	title = {An animal model of recognition memory and medial temporal lobe amnesia: History and current issues},
	volume = {48},
	issn = {0028-3932},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2975590/},
	doi = {10.1016/j.neuropsychologia.2010.02.004},
	shorttitle = {An animal model of recognition memory and medial temporal lobe amnesia},
	abstract = {The medial temporal lobe includes a system of anatomically connected structures that are essential for declarative memory (conscious memory for facts and events). A prominent form of declarative memory is recognition memory (the ability to identify a recently encountered item as familiar). Recognition memory has been frequently assessed in humans and in the experimental animal. This article traces the successful development of an animal model of human medial temporal lobe amnesia, which eventually identified the structures in the medial temporal lobe important for memory. Attention is given to two prominent behavioral paradigms (delayed nonmatching to sample and tests of spontaneous novelty preference).},
	pages = {2234--2244},
	number = {8},
	journaltitle = {Neuropsychologia},
	shortjournal = {Neuropsychologia},
	author = {Clark, Robert E. and Squire, Larry R.},
	urldate = {2020-11-17},
	date = {2010-07},
	pmid = {20144894},
	pmcid = {PMC2975590},
	file = {PubMed Central Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\TSWQICNM\\Clark and Squire - 2010 - An animal model of recognition memory and medial t.pdf:application/pdf},
}

@article{papademetris_bioimage_2006,
	title = {{BioImage} Suite: An integrated medical image analysis suite: An update},
	volume = {2006},
	issn = {2327-770X},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4213804/},
	shorttitle = {{BioImage} Suite},
	abstract = {{BioImage} Suite is an {NIH}-supported medical image analysis software suite developed at Yale. It leverages both the Visualization Toolkit ({VTK}) and the Insight Toolkit ({ITK}) and it includes many additional algorithms for image analysis especially in the areas of segmentation, registration, diffusion weighted image processing and {fMRI} analysis. {BioImage} Suite has a user-friendly user interface developed in the Tcl scripting language. A final beta version is freely available for download},
	pages = {209},
	journaltitle = {The insight journal},
	shortjournal = {Insight J},
	author = {Papademetris, Xenophon and Jackowski, Marcel P. and Rajeevan, Nallakkandi and {DiStasio}, Marcello and Okuda, Hirohito and Constable, R. Todd and Staib, Lawrence H.},
	urldate = {2020-11-17},
	date = {2006},
	pmid = {25364771},
	pmcid = {PMC4213804},
	file = {PubMed Central Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\AHH8G3A8\\Papademetris et al. - 2006 - BioImage Suite An integrated medical image analys.pdf:application/pdf},
}

@inproceedings{valin_lpcnet_2019,
	title = {{LPCNET}: Improving Neural Speech Synthesis through Linear Prediction},
	doi = {10.1109/ICASSP.2019.8682804},
	shorttitle = {{LPCNET}},
	abstract = {Neural speech synthesis models have recently demonstrated the ability to synthesize high quality speech for text-to-speech and compression applications. These new models often require powerful {GPUs} to achieve real-time operation, so being able to reduce their complexity would open the way for many new applications. We propose {LPCNet}, a {WaveRNN} variant that combines linear prediction with recurrent neural networks to significantly improve the efficiency of speech synthesis. We demonstrate that {LPCNet} can achieve significantly higher quality than {WaveRNN} for the same network size and that high quality {LPCNet} speech synthesis is achievable with a complexity under 3 {GFLOPS}. This makes it easier to deploy neural synthesis applications on lower-power devices, such as embedded systems and mobile phones.},
	eventtitle = {{ICASSP} 2019 - 2019 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	pages = {5891--5895},
	booktitle = {{ICASSP} 2019 - 2019 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	author = {Valin, J. and Skoglund, J.},
	date = {2019-05},
	note = {{ISSN}: 2379-190X},
	keywords = {Cepstrum, Complexity theory, compression applications, embedded systems, {GPU}, high quality {LPCNet} speech synthesis, high quality speech, linear prediction, Logic gates, {LPCNet}, neural audio synthesis, Neural networks, neural speech synthesis models, parametric coding, Predictive models, real-time operation, recurrent neural nets, recurrent neural networks, Sparse matrices, speech synthesis, Speech synthesis, text-to-speech, {WaveRNN}},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\JT3LJ5XY\\8682804.html:text/html;Submitted Version:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\SNSIEZPU\\Valin and Skoglund - 2019 - LPCNET Improving Neural Speech Synthesis through .pdf:application/pdf},
}

@article{ramsey_decoding_2018,
	title = {Decoding spoken phonemes from sensorimotor cortex with high-density {ECoG} grids},
	volume = {180},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811917308248},
	doi = {10.1016/j.neuroimage.2017.10.011},
	series = {New advances in encoding and decoding of brain signals},
	abstract = {For people who cannot communicate due to severe paralysis or involuntary movements, technology that decodes intended speech from the brain may offer an alternative means of communication. If decoding proves to be feasible, intracranial Brain-Computer Interface systems can be developed which are designed to translate decoded speech into computer generated speech or to instructions for controlling assistive devices. Recent advances suggest that such decoding may be feasible from sensorimotor cortex, but it is not clear how this challenge can be approached best. One approach is to identify and discriminate elements of spoken language, such as phonemes. We investigated feasibility of decoding four spoken phonemes from the sensorimotor face area, using electrocorticographic signals obtained with high-density electrode grids. Several decoding algorithms including spatiotemporal matched filters, spatial matched filters and support vector machines were compared. Phonemes could be classified correctly at a level of over 75\% with spatiotemporal matched filters. Support Vector machine analysis reached a similar level, but spatial matched filters yielded significantly lower scores. The most informative electrodes were clustered along the central sulcus. Highest scores were achieved from time windows centered around voice onset time, but a 500 ms window before onset time could also be classified significantly. The results suggest that phoneme production involves a sequence of robust and reproducible activity patterns on the cortical surface. Importantly, decoding requires inclusion of temporal information to capture the rapid shifts of robust patterns associated with articulator muscle group contraction during production of a phoneme. The high classification scores are likely to be enabled by the use of high density grids, and by the use of discrete phonemes. Implications for use in Brain-Computer Interfaces are discussed.},
	pages = {301--311},
	journaltitle = {{NeuroImage}},
	shortjournal = {{NeuroImage}},
	author = {Ramsey, N. F. and Salari, E. and Aarnoutse, E. J. and Vansteensel, M. J. and Bleichner, M. G. and Freudenburg, Z. V.},
	urldate = {2020-11-18},
	date = {2018-10-15},
	langid = {english},
	keywords = {Brain-computer interface, Decoding, {ECoG}, Language, Phonemes},
	file = {Accepted Version:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\G8NQ7F6W\\Ramsey et al. - 2018 - Decoding spoken phonemes from sensorimotor cortex .pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\7QRM8ZUM\\S1053811917308248.html:text/html},
}

@article{correia_decoding_2015,
	title = {Decoding Articulatory Features from {fMRI} Responses in Dorsal Speech Regions},
	volume = {35},
	rights = {Copyright © 2015 the authors 0270-6474/15/3515015-11\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/35/45/15015},
	doi = {10.1523/JNEUROSCI.0977-15.2015},
	abstract = {The brain's circuitry for perceiving and producing speech may show a notable level of overlap that is crucial for normal development and behavior. The extent to which sensorimotor integration plays a role in speech perception remains highly controversial, however. Methodological constraints related to experimental designs and analysis methods have so far prevented the disentanglement of neural responses to acoustic versus articulatory speech features. Using a passive listening paradigm and multivariate decoding of single-trial {fMRI} responses to spoken syllables, we investigated brain-based generalization of articulatory features (place and manner of articulation, and voicing) beyond their acoustic (surface) form in adult human listeners. For example, we trained a classifier to discriminate place of articulation within stop syllables (e.g., /pa/ vs /ta/) and tested whether this training generalizes to fricatives (e.g., /fa/ vs /sa/). This novel approach revealed generalization of place and manner of articulation at multiple cortical levels within the dorsal auditory pathway, including auditory, sensorimotor, motor, and somatosensory regions, suggesting the representation of sensorimotor information. Additionally, generalization of voicing included the right anterior superior temporal sulcus associated with the perception of human voices as well as somatosensory regions bilaterally. Our findings highlight the close connection between brain systems for speech perception and production, and in particular, indicate the availability of articulatory codes during passive speech perception.
{SIGNIFICANCE} {STATEMENT} Sensorimotor integration is central to verbal communication and provides a link between auditory signals of speech perception and motor programs of speech production. It remains highly controversial, however, to what extent the brain's speech perception system actively uses articulatory (motor), in addition to acoustic/phonetic, representations. In this study, we examine the role of articulatory representations during passive listening using carefully controlled stimuli (spoken syllables) in combination with multivariate {fMRI} decoding. Our approach enabled us to disentangle brain responses to acoustic and articulatory speech properties. In particular, it revealed articulatory-specific brain responses of speech at multiple cortical levels, including auditory, sensorimotor, and motor regions, suggesting the representation of sensorimotor information during passive speech perception.},
	pages = {15015--15025},
	number = {45},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Correia, Joao M. and Jansma, Bernadette M. B. and Bonte, Milene},
	urldate = {2020-11-18},
	date = {2015-11-11},
	langid = {english},
	pmid = {26558773},
	note = {Publisher: Society for Neuroscience
Section: Articles},
	keywords = {articulatory gestures, auditory cortex, {fMRI}, {MVPA}, sensorimotor, speech perception},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\7N6VK7EU\\Correia et al. - 2015 - Decoding Articulatory Features from fMRI Responses.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\NR94QFF8\\15015.html:text/html},
}

@article{huth_natural_2016,
	title = {Natural speech reveals the semantic maps that tile human cerebral cortex},
	volume = {532},
	rights = {2016 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature17637},
	doi = {10.1038/nature17637},
	abstract = {The meaning of language is represented in regions of the cerebral cortex collectively known as the ‘semantic system’. However, little of the semantic system has been mapped comprehensively, and the semantic selectivity of most regions is unknown. Here we systematically map semantic selectivity across the cortex using voxel-wise modelling of functional {MRI} ({fMRI}) data collected while subjects listened to hours of narrative stories. We show that the semantic system is organized into intricate patterns that seem to be consistent across individuals. We then use a novel generative model to create a detailed semantic atlas. Our results suggest that most areas within the semantic system represent information about specific semantic domains, or groups of related concepts, and our atlas shows which domains are represented in each area. This study demonstrates that data-driven methods—commonplace in studies of human neuroanatomy and functional connectivity—provide a powerful and efficient means for mapping functional representations in the brain.},
	pages = {453--458},
	number = {7600},
	journaltitle = {Nature},
	author = {Huth, Alexander G. and de Heer, Wendy A. and Griffiths, Thomas L. and Theunissen, Frédéric E. and Gallant, Jack L.},
	urldate = {2020-11-18},
	date = {2016-04},
	langid = {english},
	note = {Number: 7600
Publisher: Nature Publishing Group},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\G9YW8V84\\Huth et al. - 2016 - Natural speech reveals the semantic maps that tile.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\3SPS95B6\\nature17637.html:text/html},
}

@article{liu_speech_2018,
	title = {Speech Recognition via {fNIRS} Based Brain Signals},
	volume = {12},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2018.00695/full#B24},
	doi = {10.3389/fnins.2018.00695},
	abstract = {In this paper, we present the first evidence that perceived speech can be identified from the listeners’ brain signals measured via functional-near infrared spectroscopy ({fNIRS}) – a non-invasive, portable and wearable neuroimaging technique suitable for ecologically valid settings. In this study, participants listened audio clips containing English stories while prefrontal and parietal cortices were monitored with {fNIRS}. Machine learning was applied to train predictive models using {fNIRS} data from a subject pool to predict which part of a story was listened by a new subject not in the pool based on the brain’s hemodynamic response as measured by {fNIRS}. {fNIRS} signals can vary considerably from subject to subject due to the different head size, head shape and spatial locations of brain functional regions. To overcome this difficulty, a generalized canonical correlation analysis ({GCCA}) was adopted to extract latent variables that are shared among the listeners before applying principal component analysis ({PCA}) for dimension reduction and applying logistic regression for classification. A 74.7\% average accuracy has been achieved for differentiating between two 50 sec. long story segments and a 43.6\% average accuracy has been achieved for differentiating four 25 sec. long story segments. These results suggest the potential of an {fNIRS} based-approach for building a speech decoding brain-computer-interface for developing a new type of neural prosthetic system.},
	journaltitle = {Frontiers in Neuroscience},
	shortjournal = {Front. Neurosci.},
	author = {Liu, Yichuan and Ayaz, Hasan},
	urldate = {2020-11-18},
	date = {2018},
	note = {Publisher: Frontiers},
	keywords = {Decoding, {BCI}, {fNIRS}, Parietal Lobe, prefrontal cortex ({PFC}), Speech Perception},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\NWKNJR24\\Liu and Ayaz - 2018 - Speech Recognition via fNIRS Based Brain Signals.pdf:application/pdf},
}

@article{santoro_reconstructing_2017,
	title = {Reconstructing the spectrotemporal modulations of real-life sounds from {fMRI} response patterns},
	volume = {114},
	rights = {©  . Freely available online through the {PNAS} open access option.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/114/18/4799},
	doi = {10.1073/pnas.1617622114},
	abstract = {Ethological views of brain functioning suggest that sound representations and computations in the auditory neural system are optimized finely to process and discriminate behaviorally relevant acoustic features and sounds (e.g., spectrotemporal modulations in the songs of zebra finches). Here, we show that modeling of neural sound representations in terms of frequency-specific spectrotemporal modulations enables accurate and specific reconstruction of real-life sounds from high-resolution functional magnetic resonance imaging ({fMRI}) response patterns in the human auditory cortex. Region-based analyses indicated that response patterns in separate portions of the auditory cortex are informative of distinctive sets of spectrotemporal modulations. Most relevantly, results revealed that in early auditory regions, and progressively more in surrounding regions, temporal modulations in a range relevant for speech analysis (∼2–4 Hz) were reconstructed more faithfully than other temporal modulations. In early auditory regions, this effect was frequency-dependent and only present for lower frequencies ({\textless}∼2 {kHz}), whereas for higher frequencies, reconstruction accuracy was higher for faster temporal modulations. Further analyses suggested that auditory cortical processing optimized for the fine-grained discrimination of speech and vocal sounds underlies this enhanced reconstruction accuracy. In sum, the present study introduces an approach to embed models of neural sound representations in the analysis of {fMRI} response patterns. Furthermore, it reveals that, in the human brain, even general purpose and fundamental neural processing mechanisms are shaped by the physical features of real-world stimuli that are most relevant for behavior (i.e., speech, voice).},
	pages = {4799--4804},
	number = {18},
	journaltitle = {Proceedings of the National Academy of Sciences},
	shortjournal = {{PNAS}},
	author = {Santoro, Roberta and Moerel, Michelle and Martino, Federico De and Valente, Giancarlo and Ugurbil, Kamil and Yacoub, Essa and Formisano, Elia},
	urldate = {2020-11-18},
	date = {2017-05-02},
	langid = {english},
	pmid = {28420788},
	note = {Publisher: National Academy of Sciences
Section: Biological Sciences},
	keywords = {auditory cortex, functional {MRI}, model-based decoding, natural sounds, spectrotemporal modulations},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\AI2JU5S3\\Santoro et al. - 2017 - Reconstructing the spectrotemporal modulations of .pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\3NBUSZPS\\4799.html:text/html;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\UUM3XR76\\4799.html:text/html},
}

@inproceedings{bocquelet_robust_2014,
	location = {Singapour, Singapore},
	title = {Robust Articulatory Speech Synthesis using Deep Neural Networks for {BCI} Applications},
	url = {https://hal.archives-ouvertes.fr/hal-01228891},
	series = {Proc. of the 15th Annual Conference of the International Speech Communication Association (Interspeech 2014)},
	abstract = {Brain-Computer Interfaces ({BCIs}) usually propose typing strategies to restore communication for paralyzed and aphasic people. A more natural way would be to use speech {BCI} directly controlling a speech synthesizer. Toward this goal, a prerequisite is the development a synthesizer that should i) produce intelligible speech, ii) run in real time, iii) depend on as few parameters as possible, and iv) be robust to error fluctuations on the control parameters. In this context, we describe here an articulatory-to-acoustic mapping approach based on deep neural network ({DNN}) trained on electromagnetic articulography ({EMA}) data recorded synchronously with produced speech sounds. On this corpus, the {DNN}-based model provided a speech synthesis quality (as assessed by automatic speech recognition and behavioral testing) comparable to a state-of-the-art Gaussian mixture model ({GMM}), yet showing higher robustness when noise was added to the {EMA} coordinates. Moreover, to envision {BCI} applications, this robustness was also assessed when the space covered by the 12 original articulatory parameters was reduced to 7 parameters using deep auto-encoders ({DAE}). Given that this method can be implemented in real time, {DNN}-based articulatory speech synthesis seems a good candidate for speech {BCI} applications.},
	booktitle = {15th Annual Conference of the International Speech Communication Association (Interspeech 2014)},
	author = {Bocquelet, Florent and Hueber, Thomas and Girin, Laurent and Badin, Pierre and Yvert, Blaise},
	urldate = {2020-11-18},
	date = {2014-09},
	keywords = {articulatory speech synthesis, brain computer interface ({BCI}), deep auto-encoder, deep neural networks, dimensionality reduction, {EMA}, noise robustness},
	file = {HAL PDF Full Text:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\IU4FXWS4\\Bocquelet et al. - 2014 - Robust Articulatory Speech Synthesis using Deep Ne.pdf:application/pdf;HAL PDF Full Text:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\CJCBVJ94\\Bocquelet et al. - 2014 - Robust Articulatory Speech Synthesis using Deep Ne.pdf:application/pdf},
}

@article{epstein_cognitive_2017,
	title = {The cognitive map in humans: spatial navigation and beyond},
	volume = {20},
	rights = {2017 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.4656},
	doi = {10.1038/nn.4656},
	shorttitle = {The cognitive map in humans},
	abstract = {Cognitive maps are internal representations of large-scale navigable spaces. While they have been long studied in rodents, recent work in humans reveals new insights into how cognitive maps are encoded, anchored to environmental landmarks and used to plan routes. Similar neural mechanisms might be used to form ‘maps’ of nonphysical spaces.},
	pages = {1504--1513},
	number = {11},
	journaltitle = {Nature Neuroscience},
	author = {Epstein, Russell A. and Patai, Eva Zita and Julian, Joshua B. and Spiers, Hugo J.},
	urldate = {2020-11-25},
	date = {2017-11},
	langid = {english},
	note = {Number: 11
Publisher: Nature Publishing Group},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\7HBGPTVR\\Epstein et al. - 2017 - The cognitive map in humans spatial navigation an.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\LU8SJA94\\nn.html:text/html},
}

@article{marozzi_place_2012,
	title = {Place, space and memory cells},
	volume = {22},
	issn = {09609822},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982212012079},
	doi = {10.1016/j.cub.2012.10.022},
	pages = {R939--R942},
	number = {22},
	journaltitle = {Current Biology},
	shortjournal = {Current Biology},
	author = {Marozzi, Elizabeth and Jeffery, Kathryn J.},
	urldate = {2020-11-25},
	date = {2012-11},
	langid = {english},
	file = {Marozzi and Jeffery - 2012 - Place, space and memory cells.pdf:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\9AVQIVKA\\Marozzi and Jeffery - 2012 - Place, space and memory cells.pdf:application/pdf;ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\A9YBG8R6\\Marozzi and Jeffery - 2012 - Place, space and memory cells.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\ZZ6G2WFH\\S0960982212012079.html:text/html},
}

@article{ekstrom_space_2018,
	title = {Space, time, and episodic memory: The hippocampus is all over the cognitive map},
	volume = {28},
	issn = {1098-1063},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hipo.22750},
	doi = {https://doi.org/10.1002/hipo.22750},
	shorttitle = {Space, time, and episodic memory},
	abstract = {In recent years, the field has reached an impasse between models suggesting that the hippocampus is fundamentally involved in spatial processing and models suggesting that the hippocampus automatically encodes all dimensions of experience in the service of memory. Here, we consider key conceptual issues that have impeded progress in our understanding of hippocampal function, and we review findings that establish the scope and limits of hippocampal involvement in navigation and memory. We argue that space and time serve as a primary scaffold to break up experiences into specific contexts, and to organize multimodal input that is to be associated within a context. However, the hippocampus is clearly capable of incorporating additional dimensions into the scaffold if they are determined to be relevant in the event-defined context. Conceiving of the hippocampal representation as constrained by immediate task demands—yet preferring axes that involve space and time—helps to reconcile an otherwise disparate set of findings on the core function of the hippocampus.},
	pages = {680--687},
	number = {9},
	journaltitle = {Hippocampus},
	author = {Ekstrom, Arne D. and Ranganath, Charan},
	urldate = {2020-11-25},
	date = {2018},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/hipo.22750},
	keywords = {allocentric, cognitive map, egocentric, hippocampus, humans, path integration, spatial navigation},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\YKAXWTYN\\Ekstrom and Ranganath - 2018 - Space, time, and episodic memory The hippocampus .pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\XQQZ7Y7H\\hipo.html:text/html},
}

@article{roussel_observation_2020,
	title = {Observation and assessment of acoustic contamination of electrophysiological brain signals during speech production and sound perception},
	volume = {17},
	issn = {1741-2552},
	url = {https://iopscience.iop.org/article/10.1088/1741-2552/abb25e},
	doi = {10.1088/1741-2552/abb25e},
	pages = {056028},
	number = {5},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Roussel, Philémon and Godais, Gaël Le and Bocquelet, Florent and Palma, Marie and Hongjie, Jiang and Zhang, Shaomin and Giraud, Anne-Lise and Mégevand, Pierre and Miller, Kai and Gehrig, Johannes and Kell, Christian and Kahane, Philippe and Chabardés, Stéphan and Yvert, Blaise},
	urldate = {2020-12-02},
	date = {2020-10-15},
	langid = {english},
	file = {Roussel et al. - 2020 - Observation and assessment of acoustic contaminati.pdf:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\N89THEY9\\Roussel et al. - 2020 - Observation and assessment of acoustic contaminati.pdf:application/pdf},
}

@article{namboodiri_rationalizing_2014,
	title = {Rationalizing Decision-Making: Understanding the Cost and Perception of Time},
	volume = {1},
	issn = {2405-4496, 2405-4550},
	url = {https://brill.com/view/journals/ttpr/1/1/article-p1_4.xml},
	doi = {10.1163/24054496-00101004},
	shorttitle = {Rationalizing Decision-Making},
	abstract = {"Rationalizing Decision-Making: Understanding the Cost and Perception of Time" published on 01 Jan 2014 by Brill.},
	pages = {1--40},
	number = {1},
	journaltitle = {Timing \& Time Perception Reviews},
	author = {Namboodiri, Vijay Mohan K. and Mihalas, Stefan and Shuler, Marshall G. H.},
	urldate = {2020-12-11},
	date = {2014-01-01},
	langid = {english},
	note = {Publisher: Brill
Section: Timing \& Time Perception Reviews},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\DHXQVVMK\\Namboodiri et al. - 2014 - Rationalizing Decision-Making Understanding the C.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\UH7I2KTC\\article-p1_4.html:text/html;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\TXR7D8EW\\article-p1_4.html:text/html},
}

@article{nestler_fosb_2001,
	title = {Δ{FosB}: A sustained molecular switch for addiction},
	volume = {98},
	rights = {Copyright © 2001, The National Academy of Sciences},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/98/20/11042},
	doi = {10.1073/pnas.191352698},
	shorttitle = {Δ{FosB}},
	abstract = {The longevity of some of the behavioral abnormalities that characterize drug addiction has suggested that regulation of neural gene expression may be involved in the process by which drugs of abuse cause a state of addiction. Increasing evidence suggests that the transcription factor Δ{FosB} represents one mechanism by which drugs of abuse produce relatively stable changes in the brain that contribute to the addiction phenotype. Δ{FosB}, a member of the Fos family of transcription factors, accumulates within a subset of neurons of the nucleus accumbens and dorsal striatum (brain regions important for addiction) after repeated administration of many kinds of drugs of abuse. Similar accumulation of Δ{FosB} occurs after compulsive running, which suggests that Δ{FosB} may accumulate in response to many types of compulsive behaviors. Importantly, Δ{FosB} persists in neurons for relatively long periods of time because of its extraordinary stability. Therefore, Δ{FosB} represents a molecular mechanism that could initiate and then sustain changes in gene expression that persist long after drug exposure ceases. Studies in inducible transgenic mice that overexpress either Δ{FosB} or a dominant negative inhibitor of the protein provide direct evidence that Δ{FosB} causes increased sensitivity to the behavioral effects of drugs of abuse and, possibly, increased drug seeking behavior. This work supports the view that Δ{FosB} functions as a type of sustained “molecular switch” that gradually converts acute drug responses into relatively stable adaptations that contribute to the long-term neural and behavioral plasticity that underlies addiction.},
	pages = {11042--11046},
	number = {20},
	journaltitle = {Proceedings of the National Academy of Sciences},
	shortjournal = {{PNAS}},
	author = {Nestler, Eric J. and Barrot, Michel and Self, David W.},
	urldate = {2020-12-16},
	date = {2001-09-25},
	langid = {english},
	pmid = {11572966},
	note = {Publisher: National Academy of Sciences
Section: Colloquium Paper},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\DPUFAH6A\\Nestler et al. - 2001 - ΔFosB A sustained molecular switch for addiction.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\72S2IEHS\\11042.html:text/html},
}

@incollection{prus_conditioned_2009,
	location = {Boca Raton ({FL})},
	edition = {2nd},
	title = {Conditioned Place Preference},
	rights = {Copyright © 2009, Taylor \& Francis Group, {LLC}.},
	isbn = {978-1-4200-5234-3},
	url = {http://www.ncbi.nlm.nih.gov/books/NBK5229/},
	series = {Frontiers in Neuroscience},
	abstract = {The conditioned place preference paradigm is a standard preclinical behavioral model used to study the rewarding and aversive effects of drugs. Although a number of different designs and apparatuses are used in this model, the basic characteristics of this task involve the association of a particular environment with drug treatment, followed by the association of a different environment with the absence of the drug (i.e., the drug’s vehicle). A common variation of this design consists of a three-compartment chamber with the outer compartments being designed to have different characteristics (e.g., white vs. black walls, pine vs. corn bedding, horizontal grid vs. cross-grid flooring). The center compartment has no special characteristics and is not paired with a drug, and the gates between the compartments can be opened to allow an animal to pass freely between them. During training, an animal (typically a rat or mouse) is given an injection of a drug with potentially rewarding or aversive properties, and is then placed into one of the outer compartments for several minutes. On the following day, the rat is injected with the drug’s vehicle and then placed in the opposite compartment. Generally, these daily sessions alternate between drug and vehicle for 2 or 3 days each. Afterward, a test session is conducted, which consists of placing the animal in the center compartment and then, after opening the gates to both of the outer compartments, recording the time the animal spends in each of the outer compartments during the session. A conditioned place preference ({CPP}) is found if the animals spend significantly more time in the drug-paired compartment versus the vehicle-paired compartment. On the other hand, if the animals spend significantly more time in the vehicle-paired compartment versus the drug-paired compartment, then this is considered a conditioned place aversion ({CPA}). Typically, drugs of abuse, such as cocaine, produce {CPP}, and drugs that elicit aversive effects, such as lithium chloride, produce {CPA}. As with other behavioral models used in pharmacology research, the behavioral effects of drugs used in the {CPP} paradigm depend on species, strain, route of administration, time interval of drug administration, dose concentration, and the {CPP} apparatus used. Many drugs of abuse produce both {CPP} and {CPA}, depending on the dose administered. In drug-dependent animals, withdrawal effects generally produce {CPA}. Because the {CPP} paradigm generally provides a reliable indicator for studying the rewarding effects of drugs that require relatively little training compared to self-administration paradigm, the {CPP} paradigm has been commonly used in conjunction with standard neuroscience techniques to elucidate the subjective effects of drugs (Table 4.1).},
	booktitle = {Methods of Behavior Analysis in Neuroscience},
	publisher = {{CRC} Press/Taylor \& Francis},
	author = {Prus, Adam J. and James, John R. and Rosecrans, John A.},
	editor = {Buccafusco, Jerry J.},
	urldate = {2020-12-16},
	date = {2009},
	pmid = {21204336},
	file = {Printable HTML:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\UR5H8IQM\\NBK5229.html:text/html},
}

@article{panlilio_self-administration_2007,
	title = {Self-administration of drugs in animals and humans as a model and an investigative tool},
	volume = {102},
	issn = {0965-2140},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2695138/},
	doi = {10.1111/j.1360-0443.2007.02011.x},
	abstract = {Aim
To briefly review the methods, assumptions, models, accomplishments, drawbacks, and future directions of research using drug self-administration in animals and humans.

Background
The use of drug self-administration to study addiction is based on the assumption that drugs reinforce the behavior that results in their delivery. A wide range of drug self-administration techniques have been developed to model specific aspects of addiction. These techniques are highly amenable to being combined with a wide variety of neuroscience techniques.

Conclusions
The identification of drug use as behavior that is reinforced by drugs has contributed greatly to the understanding and treatment of addiction. As part of a program of preclinical research that also involves screening with a variety of simpler behavioral techniques, drug self-administration procedures can provide an important last step in testing potential treatments for addiction. There is currently a concerted effort to develop self-administration procedures that model the extreme nature of the behavior engendered by addiction. As advances continue to be made in neuroscience techniques, self-administration should continue to provide a means of applying these techniques within a sophisticated and valid model of human drug addiction.},
	pages = {1863--1870},
	number = {12},
	journaltitle = {Addiction (Abingdon, England)},
	shortjournal = {Addiction},
	author = {Panlilio, Leigh V. and Goldberg, Steven R.},
	urldate = {2020-12-16},
	date = {2007-12},
	pmid = {18031422},
	pmcid = {PMC2695138},
	file = {PubMed Central Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\T5I7HRTV\\Panlilio and Goldberg - 2007 - Self-administration of drugs in animals and humans.pdf:application/pdf},
}

@article{recanzone_plasticity_1993,
	title = {Plasticity in the frequency representation of primary auditory cortex following discrimination training in adult owl monkeys},
	volume = {13},
	rights = {© 1993 by Society for Neuroscience},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/13/1/87},
	doi = {10.1523/JNEUROSCI.13-01-00087.1993},
	abstract = {Previous studies have shown that the tonotopic organization of primary auditory cortex is altered subsequent to restricted cochlear lesions (Robertson and Irvine, 1989) and that the topographic reorganization of the primary somatosensory cortex is correlated with changes in the perceptual acuity of the animal (Recanzone et al., 1992a-d). Here we report an increase in the cortical area of representation of a restricted frequency range in primary auditory cortex of adult owl monkeys that is correlated with the animal's performance at a frequency discrimination task. Monkeys trained for several weeks to discriminate small differences in the frequency of sequentially presented tonal stimuli revealed a progressive improvement in performance with training. At the end of the training period, the tonotopic organization of Al was defined by recording multiple-unit responses at 70-258 cortical locations. These responses were compared to those derived from three normal monkeys and from two monkeys that received the same auditory stimuli but that were engaged in a tactile discrimination task. The cortical representation, the sharpness of tuning, and the latency of the response were greater for the behaviorally relevant frequencies of trained monkeys when compared to the same frequencies of control monkeys. The cortical area of representation was the only studied parameter that was correlated with behavioral performance. These results demonstrate that attended natural stimulation can modify the tonotopic organization of Al in the adult primate, and that this alteration is correlated with changes in perceptual acuity.},
	pages = {87--103},
	number = {1},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Recanzone, G. H. and Schreiner, C. E. and Merzenich, M. M.},
	urldate = {2020-12-18},
	date = {1993-01-01},
	langid = {english},
	pmid = {8423485},
	note = {Publisher: Society for Neuroscience
Section: Articles},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\2TM9CBAN\\Recanzone et al. - 1993 - Plasticity in the frequency representation of prim.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\6NQSYTL7\\87.html:text/html},
}

@article{polley_perceptual_2006,
	title = {Perceptual Learning Directs Auditory Cortical Map Reorganization through Top-Down Influences},
	volume = {26},
	rights = {Copyright © 2006 Society for Neuroscience 0270-6474/06/264970-•\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/26/18/4970},
	doi = {10.1523/JNEUROSCI.3771-05.2006},
	abstract = {The primary sensory cortex is positioned at a confluence of bottom-up dedicated sensory inputs and top-down inputs related to higher-order sensory features, attentional state, and behavioral reinforcement. We tested whether topographic map plasticity in the adult primary auditory cortex and a secondary auditory area, the suprarhinal auditory field, was controlled by the statistics of bottom-up sensory inputs or by top-down task-dependent influences. Rats were trained to attend to independent parameters, either frequency or intensity, within an identical set of auditory stimuli, allowing us to vary task demands while holding the bottom-up sensory inputs constant. We observed a clear double-dissociation in map plasticity in both cortical fields. Rats trained to attend to frequency cues exhibited an expanded representation of the target frequency range within the tonotopic map but no change in sound intensity encoding compared with controls. Rats trained to attend to intensity cues expressed an increased proportion of nonmonotonic intensity response profiles preferentially tuned to the target intensity range but no change in tonotopic map organization relative to controls. The degree of topographic map plasticity within the task-relevant stimulus dimension was correlated with the degree of perceptual learning for rats in both tasks. These data suggest that enduring receptive field plasticity in the adult auditory cortex may be shaped by task-specific top-down inputs that interact with bottom-up sensory inputs and reinforcement-based neuromodulator release. Top-down inputs might confer the selectivity necessary to modify a single feature representation without affecting other spatially organized feature representations embedded within the same neural circuitry.},
	pages = {4970--4982},
	number = {18},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Polley, Daniel B. and Steinberg, Elizabeth E. and Merzenich, Michael M.},
	urldate = {2020-12-18},
	date = {2006-05-03},
	langid = {english},
	pmid = {16672673},
	note = {Publisher: Society for Neuroscience
Section: Articles},
	keywords = {attention, conditioning, cortex, plasticity, reward, topographic map},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\82L57FEE\\Polley et al. - 2006 - Perceptual Learning Directs Auditory Cortical Map .pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\L4MGUXBU\\4970.html:text/html},
}

@article{weinberger_specific_2004,
	title = {Specific long-term memory traces in primary auditory cortex},
	volume = {5},
	rights = {2004 Nature Publishing Group},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/nrn1366},
	doi = {10.1038/nrn1366},
	abstract = {Although the primary sensory cortices have traditionally been viewed as 'stimulus analysers', there is increasing evidence that they can undergo learning-associated plasticity. In the auditory cortex, pairing a tone with a weak shock can alter the subsequent response of the primary auditory cortex (A1) to the frequency of the tone. More recent studies have provided evidence for specificity of information storage, by combining the techniques of sensory physiology with learning and memory studies. Together, the findings indicate that A1 can store specific memory traces.Changes that have been measured in A1 after learning include metabolic changes, shifts in receptive field tuning towards the conditioned stimulus frequency that occur rapidly and can last for weeks, and specific modifications of tonotopic maps to give a larger representation to the conditioned frequency. Imaging studies in humans have also shown specific, associative plasticity in A1. Together, the findings indicate that A1 can store specific memory traces.Two main models have been proposed to account for such plasticity. Although they differ regarding the loci of plasticity, they agree on the importance of the nucleus basalis ({NB}) cholinergic system for long-term plasticity in A1. The {NB} is the main source of cortical acetylcholine ({ACh}), and cholinergic treatment of A1 causes lasting plasticity. Neurons in the {NB} respond to tone–shock conditioning and stimulation of the {NB} can substitute for a standard reinforcer in inducing plasticity in A1 and behavioural {changesThe} emerging picture of the function of A1 includes the analysis and storage of the behavioural significance of stimulus features such as frequency. Other cognitive functions for A1 are also being uncovered, including perceptual learning, rapid 'on-line' adjustments to maximize attentive captures of stimulus elements, learning of complex tasks, processing of abstract features and encoding planned behavioural acts. It will be necessary to integrate these functions and to develop a broader functional conceptualization of A1 and of the other primary sensory cortices.},
	pages = {279--290},
	number = {4},
	journaltitle = {Nature Reviews Neuroscience},
	author = {Weinberger, Norman M.},
	urldate = {2020-12-18},
	date = {2004-04},
	langid = {english},
	note = {Number: 4
Publisher: Nature Publishing Group},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\4MX8P7NN\\Weinberger - 2004 - Specific long-term memory traces in primary audito.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\RH5TCMQV\\nrn1366.html:text/html},
}

@article{bakin_classical_1990,
	title = {Classical conditioning induces {CS}-specific receptive field plasticity in the auditory cortex of the guinea pig},
	volume = {536},
	issn = {0006-8993},
	url = {http://www.sciencedirect.com/science/article/pii/000689939090035A},
	doi = {10.1016/0006-8993(90)90035-A},
	abstract = {To determine if classical conditioning produces general or specific modification of responses to acoustic conditioned stimuli ({CS}), frequency receptive fields ({RF}) of neurons in guinea pig auditory cortex were determined before and up to 24 h after conditioning. Highly specific {RF} plasticity characterized by maximal increased responses to the {CS} frequency and decreased responses to the pretraining best frequency ({BF}) and other frequencies was observed in 70\% of conditioning cases. These opposing changes were often sufficient to produce a shift in tuning such that the frequency of the {CS} became the new {BF}. {CS} frequency specific plasticity was maintained as long as 24 h. Sensitization training produced general increased responses across the {RF} without {CS} specificity. The findings indicate that associative processes produce systematic modification of the auditory system's processing of frequency information and exemplify the advantages of combining receptive field analysis with behavioral training in the study of the neural bases of learning and memory.},
	pages = {271--286},
	number = {1},
	journaltitle = {Brain Research},
	shortjournal = {Brain Research},
	author = {Bakin, Jonathan S. and Weinberger, Norman M.},
	urldate = {2020-12-18},
	date = {1990-12-17},
	langid = {english},
	keywords = {Auditory cortex, Conditioning, Learning, Plasticity, Receptive fields},
	file = {ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\5T3NJSUW\\000689939090035A.html:text/html},
}

@article{graf_features_2015,
	title = {Features for voice activity detection: a comparative analysis},
	volume = {2015},
	issn = {1687-6180},
	url = {https://doi.org/10.1186/s13634-015-0277-z},
	doi = {10.1186/s13634-015-0277-z},
	shorttitle = {Features for voice activity detection},
	abstract = {In many speech signal processing applications, voice activity detection ({VAD}) plays an essential role for separating an audio stream into time intervals that contain speech activity and time intervals where speech is absent. Many features that reflect the presence of speech were introduced in literature. However, to our knowledge, no extensive comparison has been provided yet. In this article, we therefore present a structured overview of several established {VAD} features that target at different properties of speech. We categorize the features with respect to properties that are exploited, such as power, harmonicity, or modulation, and evaluate the performance of some dedicated features. The importance of temporal context is discussed in relation to latency restrictions imposed by different applications. Our analyses allow for selecting promising {VAD} features and finding a reasonable trade-off between performance and complexity.},
	pages = {91},
	number = {1},
	journaltitle = {{EURASIP} Journal on Advances in Signal Processing},
	shortjournal = {{EURASIP} J. Adv. Signal Process.},
	author = {Graf, Simon and Herbig, Tobias and Buck, Markus and Schmidt, Gerhard},
	urldate = {2020-12-22},
	date = {2015-11-11},
	langid = {english},
	file = {Springer Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\3VND6VTP\\Graf et al. - 2015 - Features for voice activity detection a comparati.pdf:application/pdf},
}

@article{dubnov_generalization_2004,
	title = {Generalization of spectral flatness measure for non-Gaussian linear processes},
	volume = {11},
	issn = {1558-2361},
	doi = {10.1109/LSP.2004.831663},
	abstract = {We present an information-theoretic measure for the amount of randomness or stochasticity that exists in a signal. This measure is formulated in terms of the rate of growth of multi-information for every new signal sample of the signal that is observed over time. In case of a Gaussian statistics it is shown that this measure is equivalent to the well-known spectral flatness measure that is commonly used in audio processing. For {nonGaussian} linear processes a generalized spectral flatness measure is developed, which estimates the excessive structure that is present in the signal due to the {nonGaussianity} of the innovation process. An estimator for this measure is developed using Negentropy approximation to the non-Gaussian signal and the innovation process statistics. Applications of this new measure are demonstrated for the problem of voiced/unvoiced determination, showing improved performance.},
	pages = {698--701},
	number = {8},
	journaltitle = {{IEEE} Signal Processing Letters},
	author = {Dubnov, S.},
	date = {2004-08},
	note = {Conference Name: {IEEE} Signal Processing Letters},
	keywords = {Acoustic noise, entropy, Entropy, Gaussian processes, Gaussian statistics, generalized spectral flatness measure, innovation process statistics, Negentropy approximation, {nonGaussian} linear processes, Nonlinear filters, Probability distribution, random processes, Random variables, Signal processing, signal sampling, spectral analysis, Statistics, stochastic processes, Technological innovation, Time measurement, voiced-unvoiced determination},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\CLE4ZL7S\\1316889.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\7VETCEFB\\Dubnov - 2004 - Generalization of spectral flatness measure for no.pdf:application/pdf},
}

@article{branco_brain-computer_2021,
	title = {Brain-Computer Interfaces for Communication: Preferences of Individuals With Locked-in Syndrome},
	issn = {1545-9683},
	url = {https://journals.sagepub.com/doi/abs/10.1177/1545968321989331},
	doi = {10.1177/1545968321989331},
	shorttitle = {Brain-Computer Interfaces for Communication},
	abstract = {{BackgroundBrain}-computer interfaces ({BCIs}) have been proposed as an assistive technology ({AT}) allowing people with locked-in syndrome ({LIS}) to use neural signals to communicate. To design a communication {BCI} ({cBCI}) that is fully accepted by the users, their opinion should be taken into consideration during the research and development process.{ObjectiveWe} assessed the preferences of prospective {cBCI} users regarding (1) the applications they would like to control with a {cBCI}, (2) the mental strategies they would prefer to use to control the {cBCI}, and (3) when during their clinical trajectory they would like to be informed about {AT} and {cBCIs}. Furthermore, we investigated if individuals diagnosed with progressive and sudden onset ({SO}) disorders differ in their opinion.{MethodsWe} interviewed 28 Dutch individuals with {LIS} during a 3-hour home visit using multiple-choice, ranking, and open questions. During the interview, participants were informed about {BCIs} and the possible mental strategies.{ResultsParticipants} rated (in)direct forms of communication, computer use, and environmental control as the most desired {cBCI} applications. In addition, active {cBCI} control strategies were preferred over reactive strategies. Furthermore, individuals with progressive and {SO} disorders preferred to be informed about {AT} and {cBCIs} at the moment they would need it.{ConclusionsWe} show that individuals diagnosed with progressive and {SO} disorders preferred, in general, the same applications, mental strategies, and time of information. By collecting the opinion of a large sample of individuals with {LIS}, this study provides valuable information to stakeholders in {cBCI} and other {AT} development.},
	pages = {1545968321989331},
	journaltitle = {Neurorehabilitation and Neural Repair},
	shortjournal = {Neurorehabil Neural Repair},
	author = {Branco, Mariana P. and Pels, Elmar G. M. and Sars, Ruben H. and Aarnoutse, Erik J. and Ramsey, Nick F. and Vansteensel, Mariska J. and Nijboer, Femke},
	urldate = {2021-02-06},
	date = {2021-02-03},
	note = {Publisher: {SAGE} Publications Inc {STM}},
	file = {SAGE PDF Full Text:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\TWDT3MQT\\Branco et al. - 2021 - Brain-Computer Interfaces for Communication Prefe.pdf:application/pdf},
}

@article{kubler_braincomputer_2009,
	title = {A Brain–Computer Interface Controlled Auditory Event-Related Potential (P300) Spelling System for Locked-In Patients},
	volume = {1157},
	rights = {© 2009 Association for Research in Nervous and Mental Disease},
	issn = {1749-6632},
	url = {https://nyaspubs.onlinelibrary.wiley.com/doi/abs/10.1111/j.1749-6632.2008.04122.x},
	doi = {https://doi.org/10.1111/j.1749-6632.2008.04122.x},
	abstract = {Using brain–computer interfaces ({BCI}) humans can select letters or other targets on a computer screen without any muscular involvement. An intensively investigated kind of {BCI} is based on the recording of visual event-related brain potentials ({ERP}). However, some severely paralyzed patients who need a {BCI} for communication have impaired vision or lack control of gaze movement, thus making a {BCI} depending on visual input no longer feasible. In an effort to render the {ERP}–{BCI} usable for this group of patients, the {ERP}–{BCI} was adapted to auditory stimulation. Letters of the alphabet were assigned to cells in a 5 × 5 matrix. Rows of the matrix were coded with numbers 1 to 5, and columns with numbers 6 to 10, and the numbers were presented auditorily. To select a letter, users had to first select the row and then the column containing the desired letter. Four severely paralyzed patients in the end-stage of a neurodegenerative disease were examined. All patients performed above chance level. Spelling accuracy was significantly lower with the auditory system as compared with a similar visual system. Patients reported difficulties in concentrating on the task when presented with the auditory system. In future studies, the auditory {ERP}–{BCI} should be adjusted by taking into consideration specific features of severely paralyzed patients, such as reduced attention span. This adjustment in combination with more intensive training will show whether an auditory {ERP}–{BCI} can become an option for visually impaired patients.},
	pages = {90--100},
	number = {1},
	journaltitle = {Annals of the New York Academy of Sciences},
	author = {Kübler, Andrea and Furdea, Adrian and Halder, Sebastian and Hammer, Eva Maria and Nijboer, Femke and Kotchoubey, Boris},
	urldate = {2021-04-28},
	date = {2009},
	langid = {english},
	note = {\_eprint: https://nyaspubs.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1749-6632.2008.04122.x},
	keywords = {amyotrophic lateral sclerosis, auditory, brain-computer interface, communication, event-related potentials, locked-in syndrome, P300},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\6WNTI798\\Kübler et al. - 2009 - A Brain–Computer Interface Controlled Auditory Eve.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\IQ4YNR8W\\j.1749-6632.2008.04122.html:text/html;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\TKTEPLWC\\j.1749-6632.2008.04122.html:text/html},
}

@article{lesenfants_independent_2014,
	title = {An independent {SSVEP}-based brain–computer interface in locked-in syndrome},
	volume = {11},
	issn = {1741-2552},
	url = {https://doi.org/10.1088/1741-2560/11/3/035002},
	doi = {10.1088/1741-2560/11/3/035002},
	abstract = {Objective. Steady-state visually evoked potential ({SSVEP})-based brain–computer interfaces ({BCIs}) allow healthy subjects to communicate. However, their dependence on gaze control prevents their use with severely disabled patients. Gaze-independent {SSVEP}-{BCIs} have been designed but have shown a drop in accuracy and have not been tested in brain-injured patients. In the present paper, we propose a novel independent {SSVEP}-{BCI} based on covert attention with an improved classification rate. We study the influence of feature extraction algorithms and the number of harmonics. Finally, we test online communication on healthy volunteers and patients with locked-in syndrome ({LIS}). Approach. Twenty-four healthy subjects and six {LIS} patients participated in this study. An independent covert two-class {SSVEP} paradigm was used with a newly developed portable light emitting diode-based ‘interlaced squares' stimulation pattern. Main results. Mean offline and online accuracies on healthy subjects were respectively 85 ± 2\% and 74 ± 13\%, with eight out of twelve subjects succeeding to communicate efficiently with 80 ± 9\% accuracy. Two out of six {LIS} patients reached an offline accuracy above the chance level, illustrating a response to a command. One out of four {LIS} patients could communicate online. Significance. We have demonstrated the feasibility of online communication with a covert {SSVEP} paradigm that is truly independent of all neuromuscular functions. The potential clinical use of the presented {BCI} system as a diagnostic (i.e., detecting command-following) and communication tool for severely brain-injured patients will need to be further explored.},
	pages = {035002},
	number = {3},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Lesenfants, D. and Habbal, D. and Lugo, Z. and Lebeau, M. and Horki, P. and Amico, E. and Pokorny, C. and Gómez, F. and Soddu, A. and Müller-Putz, G. and Laureys, S. and Noirhomme, Q.},
	urldate = {2021-04-28},
	date = {2014-05},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\GSBCC84I\\Lesenfants et al. - 2014 - An independent SSVEP-based brain–computer interfac.pdf:application/pdf},
}

@article{zelinka_impact_2012,
	title = {Impact of vocal effort variability on automatic speech recognition},
	volume = {54},
	issn = {0167-6393},
	url = {https://www.sciencedirect.com/science/article/pii/S016763931200009X},
	doi = {10.1016/j.specom.2012.01.002},
	abstract = {The impact of changes in a speaker’s vocal effort on the performance of automatic speech recognition has largely been overlooked by researchers and virtually no speech resources exist for the development and testing of speech recognizers at all vocal effort levels. This study deals with speech properties in the whole range of vocal modes – whispering, soft speech, normal speech, loud speech, and shouting. Fundamental acoustic and phonetic changes are documented. The impact of vocal effort variability on the performance of an isolated-word recognizer is shown and effective means of improving the system’s robustness are tested. The proposed multiple model framework approach reaches a 50\% relative reduction of word error rate compared to the baseline system. A new specialized speech database, {BUT}-{VE}1, is presented, which contains speech recordings of 13 speakers at 5 vocal effort levels with manual phonetic segmentation and sound pressure level calibration.},
	pages = {732--742},
	number = {6},
	journaltitle = {Speech Communication},
	shortjournal = {Speech Communication},
	author = {Zelinka, Petr and Sigmund, Milan and Schimmel, Jiri},
	urldate = {2021-04-29},
	date = {2012-07-01},
	langid = {english},
	keywords = {Machine learning, Robust speech recognition, Vocal effort level},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\TTMZZP59\\Zelinka et al. - 2012 - Impact of vocal effort variability on automatic sp.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\KHZ8XW5S\\S016763931200009X.html:text/html},
}

@article{benzeghiba_automatic_2007,
	title = {Automatic speech recognition and speech variability: A review},
	volume = {49},
	issn = {0167-6393},
	url = {https://www.sciencedirect.com/science/article/pii/S0167639307000404},
	doi = {10.1016/j.specom.2007.02.006},
	series = {Intrinsic Speech Variations},
	shorttitle = {Automatic speech recognition and speech variability},
	abstract = {Major progress is being recorded regularly on both the technology and exploitation of automatic speech recognition ({ASR}) and spoken language systems. However, there are still technological barriers to flexible solutions and user satisfaction under some circumstances. This is related to several factors, such as the sensitivity to the environment (background noise), or the weak representation of grammatical and semantic knowledge. Current research is also emphasizing deficiencies in dealing with variation naturally present in speech. For instance, the lack of robustness to foreign accents precludes the use by specific populations. Also, some applications, like directory assistance, particularly stress the core recognition technology due to the very high active vocabulary (application perplexity). There are actually many factors affecting the speech realization: regional, sociolinguistic, or related to the environment or the speaker herself. These create a wide range of variations that may not be modeled correctly (speaker, gender, speaking rate, vocal effort, regional accent, speaking style, non-stationarity, etc.), especially when resources for system training are scarce. This paper outlines current advances related to these topics.},
	pages = {763--786},
	number = {10},
	journaltitle = {Speech Communication},
	shortjournal = {Speech Communication},
	author = {Benzeghiba, M. and De Mori, R. and Deroo, O. and Dupont, S. and Erbes, T. and Jouvet, D. and Fissore, L. and Laface, P. and Mertins, A. and Ris, C. and Rose, R. and Tyagi, V. and Wellekens, C.},
	urldate = {2021-04-29},
	date = {2007-10-01},
	langid = {english},
	keywords = {Speech analysis, Speech intrinsic variations, Speech modeling, Speech recognition},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\Y44CGWJJ\\Benzeghiba et al. - 2007 - Automatic speech recognition and speech variabilit.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\K6XBPMEI\\S0167639307000404.html:text/html},
}

@article{graves_framewise_2005,
	title = {Framewise phoneme classification with bidirectional {LSTM} and other neural network architectures},
	volume = {18},
	issn = {0893-6080},
	url = {https://www.sciencedirect.com/science/article/pii/S0893608005001206},
	doi = {10.1016/j.neunet.2005.06.042},
	series = {{IJCNN} 2005},
	abstract = {In this paper, we present bidirectional Long Short Term Memory ({LSTM}) networks, and a modified, full gradient version of the {LSTM} learning algorithm. We evaluate Bidirectional {LSTM} ({BLSTM}) and several other network architectures on the benchmark task of framewise phoneme classification, using the {TIMIT} database. Our main findings are that bidirectional networks outperform unidirectional ones, and Long Short Term Memory ({LSTM}) is much faster and also more accurate than both standard Recurrent Neural Nets ({RNNs}) and time-windowed Multilayer Perceptrons ({MLPs}). Our results support the view that contextual information is crucial to speech processing, and suggest that {BLSTM} is an effective architecture with which to exploit it.11An abbreviated version of some portions of this article appeared in (Graves and Schmidhuber, 2005), as part of the {IJCNN} 2005 conference proceedings, published under the {IEEE} copyright.},
	pages = {602--610},
	number = {5},
	journaltitle = {Neural Networks},
	shortjournal = {Neural Networks},
	author = {Graves, Alex and Schmidhuber, Jürgen},
	urldate = {2021-04-30},
	date = {2005-07-01},
	langid = {english},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\F9CTHRJ6\\Graves and Schmidhuber - 2005 - Framewise phoneme classification with bidirectiona.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\NF6XDEWZ\\S0893608005001206.html:text/html},
}

@inproceedings{maia_trainable_2007,
	title = {A Trainable Excitation Model for {HMM}-Based Speech Synthesis},
	booktitle = {Eighth Annual Conference of the International Speech Communication Association},
	author = {Maia, R. and Toda, Tomoki and Zen, Heiga and Nankaku, Yoshihiko and Tokuda, Keiichi},
	date = {2007},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\GQK4DDC5\\Maia et al. - 2007 - A Trainable Excitation Model for HMM-Based Speech .pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\BCATCDSI\\8149.html:text/html},
}

@article{rabiner_tutorial_1989,
	title = {A tutorial on hidden Markov models and selected applications in speech recognition},
	volume = {77},
	pages = {257--286},
	number = {2},
	journaltitle = {Proceedings of the {IEEE}},
	author = {Rabiner, Lawrence R.},
	date = {1989},
	note = {Publisher: Ieee},
	file = {Full Text:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\RC7KDJVK\\Rabiner - 1989 - A tutorial on hidden Markov models and selected ap.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\4TCZB55S\\18626.html:text/html},
}

@article{hermansky_perceptual_1990,
	title = {Perceptual linear predictive ({PLP}) analysis of speech},
	volume = {87},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.399423},
	doi = {10.1121/1.399423},
	pages = {1738--1752},
	number = {4},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Hermansky, Hynek},
	urldate = {2021-05-06},
	date = {1990-04-01},
	note = {Publisher: Acoustical Society of America},
}

@article{pandarinath_high_2017,
	title = {High performance communication by people with paralysis using an intracortical brain-computer interface},
	volume = {6},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.18554},
	doi = {10.7554/eLife.18554},
	abstract = {Brain-computer interfaces ({BCIs}) have the potential to restore communication for people with tetraplegia and anarthria by translating neural activity into control signals for assistive communication devices. While previous pre-clinical and clinical studies have demonstrated promising proofs-of-concept (Serruya et al., 2002; Simeral et al., 2011; Bacher et al., 2015; Nuyujukian et al., 2015; Aflalo et al., 2015; Gilja et al., 2015; Jarosiewicz et al., 2015; Wolpaw et al., 1998; Hwang et al., 2012; Spüler et al., 2012; Leuthardt et al., 2004; Taylor et al., 2002; Schalk et al., 2008; Moran, 2010; Brunner et al., 2011; Wang et al., 2013; Townsend and Platsko, 2016; Vansteensel et al., 2016; Nuyujukian et al., 2016; Carmena et al., 2003; Musallam et al., 2004; Santhanam et al., 2006; Hochberg et al., 2006; Ganguly et al., 2011; O’Doherty et al., 2011; Gilja et al., 2012), the performance of human clinical {BCI} systems is not yet high enough to support widespread adoption by people with physical limitations of speech. Here we report a high-performance intracortical {BCI} ({iBCI}) for communication, which was tested by three clinical trial participants with paralysis. The system leveraged advances in decoder design developed in prior pre-clinical and clinical studies (Gilja et al., 2015; Kao et al., 2016; Gilja et al., 2012). For all three participants, performance exceeded previous {iBCIs} (Bacher et al., 2015; Jarosiewicz et al., 2015) as measured by typing rate (by a factor of 1.4–4.2) and information throughput (by a factor of 2.2–4.0). This high level of performance demonstrates the potential utility of {iBCIs} as powerful assistive communication devices for people with limited motor function. Clinical Trial No: {NCT}00912041},
	pages = {e18554},
	journaltitle = {{eLife}},
	author = {Pandarinath, Chethan and Nuyujukian, Paul and Blabe, Christine H and Sorice, Brittany L and Saab, Jad and Willett, Francis R and Hochberg, Leigh R and Shenoy, Krishna V and Henderson, Jaimie M},
	editor = {Kastner, Sabine},
	urldate = {2021-05-14},
	date = {2017-02-21},
	note = {Publisher: {eLife} Sciences Publications, Ltd},
	keywords = {{ALS}, assistive technology, brain-machine interface, neural prosthesis},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\MDXWXRCQ\\Pandarinath et al. - 2017 - High performance communication by people with para.pdf:application/pdf},
}

@article{chang_toward_2020,
	title = {Toward a Speech Neuroprosthesis},
	volume = {323},
	issn = {0098-7484},
	url = {https://doi.org/10.1001/jama.2019.19813},
	doi = {10.1001/jama.2019.19813},
	abstract = {Spoken communication is a basic human function. As such, loss of the ability to speak can be devastating for affected individuals. Stroke or neurodegenerative conditions, such as amyotrophic lateral sclerosis, can result in paralysis or dysfunction of vocal structures that produce speech. Current options are assistive devices that use residual movements, for example, cheek twitches or eye movements, to navigate alphabet displays to type out words. While some users depend on these alternative communication approaches, these devices tend to be slow, error-prone, and laborious. A next generation of rehabilitative technologies currently being developed, called brain-computer interfaces ({BCIs}), directly read out brain signals to replace lost function. The application of neuroprostheses to restore speech has the potential to improve the quality of life of patients with neurological disease, but also including patients who have lost speech from vocal tract injury (eg, from cancer or cancer-related surgery).},
	pages = {413--414},
	number = {5},
	journaltitle = {{JAMA}},
	shortjournal = {{JAMA}},
	author = {Chang, Edward F. and Anumanchipalli, Gopala K.},
	urldate = {2021-05-14},
	date = {2020-02-04},
	file = {Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\2ANGKSPD\\2758116.html:text/html;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\P6EDQDMG\\2758116.html:text/html},
}

@article{sun_brain2char_2020,
	title = {Brain2Char: a deep architecture for decoding text from brain recordings},
	volume = {17},
	issn = {1741-2552},
	url = {https://doi.org/10.1088/1741-2552/abc742},
	doi = {10.1088/1741-2552/abc742},
	shorttitle = {Brain2Char},
	abstract = {Objective. Decoding language representations directly from the brain can enable new brain–computer interfaces ({BCIs}) for high bandwidth human–human and human–machine communication. Clinically, such technologies can restore communication in people with neurological conditions affecting their ability to speak. Approach. In this study, we propose a novel deep network architecture Brain2Char, for directly decoding text (specifically character sequences) from direct brain recordings (called electrocorticography, {ECoG}). Brain2Char framework combines state-of-the-art deep learning modules—3D Inception layers for multiband spatiotemporal feature extraction from neural data and bidirectional recurrent layers, dilated convolution layers followed by language model weighted beam search to decode character sequences, and optimizing a connectionist temporal classification loss. Additionally, given the highly non-linear transformations that underlie the conversion of cortical function to character sequences, we perform regularizations on the network’s latent representations motivated by insights into cortical encoding of speech production and artifactual aspects specific to {ECoG} data acquisition. To do this, we impose auxiliary losses on latent representations for articulatory movements, speech acoustics and session specific non-linearities. Main results. In three (out of four) participants reported here, Brain2Char achieves 10.6\%, 8.5\%, and 7.0\% word error rates respectively on vocabulary sizes ranging from 1200 to 1900 words. Significance. These results establish a new end-to-end approach on decoding text from brain signals and demonstrate the potential of Brain2Char as a high-performance communication {BCI}.},
	pages = {066015},
	number = {6},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Sun, Pengfei and Anumanchipalli, Gopala K. and Chang, Edward F.},
	urldate = {2021-05-14},
	date = {2020-12},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\EYHSSDVE\\Sun et al. - 2020 - Brain2Char a deep architecture for decoding text .pdf:application/pdf},
}

@article{pei_decoding_2011,
	title = {Decoding vowels and consonants in spoken and imagined words using electrocorticographic signals in humans},
	volume = {8},
	issn = {1741-2552},
	url = {https://doi.org/10.1088/1741-2560/8/4/046028},
	doi = {10.1088/1741-2560/8/4/046028},
	abstract = {Several stories in the popular media have speculated that it may be possible to infer from the brain which word a person is speaking or even thinking. While recent studies have demonstrated that brain signals can give detailed information about actual and imagined actions, such as different types of limb movements or spoken words, concrete experimental evidence for the possibility to ‘read the mind’, i.e. to interpret internally-generated speech, has been scarce. In this study, we found that it is possible to use signals recorded from the surface of the brain (electrocorticography) to discriminate the vowels and consonants embedded in spoken and in imagined words, and we defined the cortical areas that held the most information about discrimination of vowels and consonants. The results shed light on the distinct mechanisms associated with production of vowels and consonants, and could provide the basis for brain-based communication using imagined speech.},
	pages = {046028},
	number = {4},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Pei, Xiaomei and Barbour, Dennis L. and Leuthardt, Eric C. and Schalk, Gerwin},
	urldate = {2021-05-15},
	date = {2011-07},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\NBD2YC3G\\Pei et al. - 2011 - Decoding vowels and consonants in spoken and imagi.pdf:application/pdf},
}

@inproceedings{bouchard_neural_2014,
	title = {Neural decoding of spoken vowels from human sensory-motor cortex with high-density electrocorticography},
	doi = {10.1109/EMBC.2014.6945185},
	abstract = {We present the first demonstration of single-trial neural decoding of vowel acoustic features during speech production with high performance. The ability to predict trial-by-trial fluctuations in speech production was facilitated by using high-density, large-area electrocorticography ({ECoG}) combined with an adaptive principal components regression. In experiments from two human neurosurgical patients with a high-density 256-channel {ECoG} grid implanted over speech cortices, we demonstrate that as much as 81\% of the acoustic variability across vowels could be accurately predicted from the spatial patterns of neural activity during speech production. These results demonstrate continuous, single-trial decoding of vowel acoustics.},
	eventtitle = {2014 36th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society},
	pages = {6782--6785},
	booktitle = {2014 36th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society},
	author = {Bouchard, Kristofer E. and Chang, Edward F.},
	date = {2014-08},
	note = {{ISSN}: 1558-4615},
	keywords = {Decoding, Acoustics, Band-pass filters, Educational institutions, Electrodes, Mathematical model, Speech},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\G2NLCHUT\\6945185.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\55BNHH9E\\Bouchard and Chang - 2014 - Neural decoding of spoken vowels from human sensor.pdf:application/pdf},
}

@article{brumberg_classification_2011,
	title = {Classification of intended phoneme production from chronic intracortical microelectrode recordings in speech motor cortex},
	volume = {5},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2011.00065/full},
	doi = {10.3389/fnins.2011.00065},
	abstract = {We conducted a neurophysiological study of attempted speech production in a paralyzed human volunteer using chronic microelectrode recordings. The volunteer suffers from locked-in syndrome leaving him in a state of near-total paralysis, though he maintains good cognition and sensation. In this study, we investigated the feasibility of supervised classification techniques for prediction of intended phoneme production in the absence of any overt movements including speech. Such classification or decoding ability has the potential to greatly improve the quality-of-life of many people who are otherwise unable to speak by providing a direct communicative link to the general community. We examined the performance of three classifiers on a multi-class discrimination problem in which the items were 38 American English phonemes including monophthong and diphthong vowels and consonants. The three classifiers differed in performance, but averaged between 16-21\% overall accuracy (chance-level is 1/38 or 2.6\%). Further, the distribution of phonemes classified statistically above chance was non-uniform though 20 of 38 phonemes were classified with statistical significance for all three classifiers. These preliminary results suggest supervised classification techniques are capable of performing large scale multi-class discrimination for attempted speech production and may provide the basis for future communication prostheses.},
	journaltitle = {Frontiers in Neuroscience},
	shortjournal = {Front. Neurosci.},
	author = {Brumberg, Jonathan S. and Wright, E. Joe and Andreasen, Dinal S. and Guenther, Frank H. and Kennedy, Philip R.},
	urldate = {2021-05-15},
	date = {2011},
	note = {Publisher: Frontiers},
	keywords = {locked-in syndrome, chronic recording, Motor Cortex, Neurotrophic Electrode, speech prosthesis},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\2GN4UIG8\\Brumberg et al. - 2011 - Classification of intended phoneme production from.pdf:application/pdf},
}

@article{ikeda_neural_2014,
	title = {Neural decoding of single vowels during covert articulation using electrocorticography},
	volume = {8},
	issn = {1662-5161},
	url = {https://www.frontiersin.org/articles/10.3389/fnhum.2014.00125/full},
	doi = {10.3389/fnhum.2014.00125},
	abstract = {The human brain has important abilities for manipulating phonemes, the basic building blocks of speech; these abilities represent phonological processing. Previous studies have shown change in the activation levels of broad cortical areas such as the premotor cortex, the inferior frontal gyrus, and the superior temporal gyrus during phonological processing. However, whether these areas actually convey signals to representations related to individual phonemes remains unclear. This study focused on single vowels and investigated cortical areas important for representing single vowels using electrocorticography ({ECoG}) during covert articulation. To identify such cortical areas, we used a neural decoding approach in which machine learning models identify vowels. A decoding model was trained on the {ECoG} signals from individual electrodes placed on the subjects’ cortices. We then statistically evaluated whether each decoding model showed accurate identification of vowels, and we found cortical areas such as the premotor cortex and the superior temporal gyrus. These cortical areas were consistent with previous findings. On the other hand, no electrodes over Broca’s area showed significant decoding accuracies. This was inconsistent with findings from a previous study showing that vowels within the phonemic sequence of words can be decoded using {ECoG} signals from Broca’s area. Our results therefore suggest that Broca’s area is involved in the processing of vowels within phonemic sequences, but not in the processing of single vowels.},
	journaltitle = {Frontiers in Human Neuroscience},
	shortjournal = {Front. Hum. Neurosci.},
	author = {Ikeda, Shigeyuki and Shibata, Tomohiro and Nakano, Naoki and Okada, Rieko and Tsuyuguchi, Naohiro and Ikeda, Kazushi and Kato, Amami},
	urldate = {2021-05-15},
	date = {2014},
	note = {Publisher: Frontiers},
	keywords = {covert articulation, electrocorticography ({ECoG}), Functional Mapping, neural decoding, single vowel},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\G9TSXA27\\Ikeda et al. - 2014 - Neural decoding of single vowels during covert art.pdf:application/pdf},
}

@article{chang_categorical_2010,
	title = {Categorical speech representation in human superior temporal gyrus},
	volume = {13},
	rights = {2010 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.2641},
	doi = {10.1038/nn.2641},
	abstract = {A continuum of acoustically varying speech sounds is not perceived as a continuum, but as distinct phonetic categories. Chang et al. recorded directly from human posterior superior temporal gyrus and found that this area has a similarly discontinuous coding of objectively continuous sound, matching perception and indicating higher-level processing.},
	pages = {1428--1432},
	number = {11},
	journaltitle = {Nature Neuroscience},
	author = {Chang, Edward F. and Rieger, Jochem W. and Johnson, Keith and Berger, Mitchel S. and Barbaro, Nicholas M. and Knight, Robert T.},
	urldate = {2021-05-15},
	date = {2010-11},
	langid = {english},
	note = {Number: 11
Publisher: Nature Publishing Group},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\NYSNJGUL\\Chang et al. - 2010 - Categorical speech representation in human superio.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\B5FHRNWG\\nn.html:text/html},
}

@article{tankus_structured_2012,
	title = {Structured neuronal encoding and decoding of human speech features},
	volume = {3},
	rights = {2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/ncomms1995},
	doi = {10.1038/ncomms1995},
	abstract = {Human speech sounds are produced through a coordinated movement of structures along the vocal tract. Here we show highly structured neuronal encoding of vowel articulation. In medial–frontal neurons, we observe highly specific tuning to individual vowels, whereas superior temporal gyrus neurons have nonspecific, sinusoidally modulated tuning (analogous to motor cortical directional tuning). At the neuronal population level, a decoding analysis reveals that the underlying structure of vowel encoding reflects the anatomical basis of articulatory movements. This structured encoding enables accurate decoding of volitional speech segments and could be applied in the development of brain–machine interfaces for restoring speech in paralysed individuals.},
	pages = {1015},
	number = {1},
	journaltitle = {Nature Communications},
	author = {Tankus, Ariel and Fried, Itzhak and Shoham, Shy},
	urldate = {2021-05-15},
	date = {2012-08-21},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\EGKB5WMS\\Tankus et al. - 2012 - Structured neuronal encoding and decoding of human.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\WG5EURYP\\ncomms1995.html:text/html},
}

@article{kellis_decoding_2010,
	title = {Decoding spoken words using local field potentials recorded from the cortical surface},
	volume = {7},
	issn = {1741-2552},
	url = {https://doi.org/10.1088/1741-2560/7/5/056007},
	doi = {10.1088/1741-2560/7/5/056007},
	abstract = {Pathological conditions such as amyotrophic lateral sclerosis or damage to the brainstem can leave patients severely paralyzed but fully aware, in a condition known as ‘locked-in syndrome’. Communication in this state is often reduced to selecting individual letters or words by arduous residual movements. More intuitive and rapid communication may be restored by directly interfacing with language areas of the cerebral cortex. We used a grid of closely spaced, nonpenetrating micro-electrodes to record local field potentials ({LFPs}) from the surface of face motor cortex and Wernicke's area. From these {LFPs} we were successful in classifying a small set of words on a trial-by-trial basis at levels well above chance. We found that the pattern of electrodes with the highest accuracy changed for each word, which supports the idea that closely spaced micro-electrodes are capable of capturing neural signals from independent neural processing assemblies. These results further support using cortical surface potentials (electrocorticography) in brain–computer interfaces. These results also show that {LFPs} recorded from the cortical surface (micro-electrocorticography) of language areas can be used to classify speech-related cortical rhythms and potentially restore communication to locked-in patients.},
	pages = {056007},
	number = {5},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Kellis, Spencer and Miller, Kai and Thomson, Kyle and Brown, Richard and House, Paul and Greger, Bradley},
	urldate = {2021-05-15},
	date = {2010-09},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\UX8XSJ6Y\\Kellis et al. - 2010 - Decoding spoken words using local field potentials.pdf:application/pdf},
}

@article{pasley_reconstructing_2012,
	title = {Reconstructing Speech from Human Auditory Cortex},
	volume = {10},
	issn = {1545-7885},
	url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001251},
	doi = {10.1371/journal.pbio.1001251},
	abstract = {Direct brain recordings from neurosurgical patients listening to speech reveal that the acoustic speech signals can be reconstructed from neural activity in auditory cortex.},
	pages = {e1001251},
	number = {1},
	journaltitle = {{PLOS} Biology},
	shortjournal = {{PLOS} Biology},
	author = {Pasley, Brian N. and David, Stephen V. and Mesgarani, Nima and Flinker, Adeen and Shamma, Shihab A. and Crone, Nathan E. and Knight, Robert T. and Chang, Edward F.},
	urldate = {2021-05-15},
	date = {2012-01-31},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Auditory cortex, Acoustics, Speech, Bioacoustics, Electrode potentials, Modulation, Power grids, Speech signal processing},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\NKAL47PJ\\Pasley et al. - 2012 - Reconstructing Speech from Human Auditory Cortex.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\IU2H7EYM\\article.html:text/html},
}

@article{martin_word_2016,
	title = {Word pair classification during imagined speech using direct brain recordings},
	volume = {6},
	rights = {2016 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/srep25803},
	doi = {10.1038/srep25803},
	abstract = {People that cannot communicate due to neurological disorders would benefit from an internal speech decoder. Here, we showed the ability to classify individual words during imagined speech from electrocorticographic signals. In a word imagery task, we used high gamma (70–150 Hz) time features with a support vector machine model to classify individual words from a pair of words. To account for temporal irregularities during speech production, we introduced a non-linear time alignment into the {SVM} kernel. Classification accuracy reached 88\% in a two-class classification framework (50\% chance level), and average classification accuracy across fifteen word-pairs was significant across five subjects (mean = 58\%; p {\textless} 0.05). We also compared classification accuracy between imagined speech, overt speech and listening. As predicted, higher classification accuracy was obtained in the listening and overt speech conditions (mean = 89\% and 86\%, respectively; p {\textless} 0.0001), where speech stimuli were directly presented. The results provide evidence for a neural representation for imagined words in the temporal lobe, frontal lobe and sensorimotor cortex, consistent with previous findings in speech perception and production. These data represent a proof of concept study for basic decoding of speech imagery, and delineate a number of key challenges to usage of speech imagery neural representations for clinical applications.},
	pages = {25803},
	number = {1},
	journaltitle = {Scientific Reports},
	author = {Martin, S. and Brunner, Peter and Iturrate, Iñaki and Millán, José del R. and Schalk, Gerwin and Knight, Robert T. and Pasley, Brian N.},
	urldate = {2021-05-15},
	date = {2016-05-11},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\227ML563\\Martin et al. - 2016 - Word pair classification during imagined speech us.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\RLX4XSFL\\srep25803.html:text/html},
}

@article{li_brain--speech_2018,
	title = {Brain-to-speech decoding will require linguistic and pragmatic data},
	volume = {15},
	issn = {1741-2552},
	url = {https://doi.org/10.1088/1741-2552/aae466},
	doi = {10.1088/1741-2552/aae466},
	abstract = {Objective. Advances in electrophysiological methods such as electrocorticography ({ECoG}) have enabled researchers to decode phonemes, syllables, and words from brain activity. The ultimate aspiration underlying these efforts is the development of a brain-machine interface ({BMI}) that will enable speakers to produce real-time, naturalistic speech. In the effort to create such a device, researchers have typically followed a bottom-up approach whereby low-level units of language (e.g. phonemes, syllables, or letters) are decoded from articulation areas (e.g. premotor cortex) with the aim of assembling these low-level units into words and sentences. Approach. In this paper, we recommend that researchers supplement the existing bottom-up approach with a novel top-down approach. According to the top-down proposal, initial decoding of top-down information may facilitate the subsequent decoding of downstream representations by constraining the hypothesis space from which low-level units are selected. Main results. We identify types and sources of top-down information that may crucially inform {BMI} decoding ecosystems: communicative intentions (e.g. speech acts), situational pragmatics (e.g. recurrent communicative pressures), and formal linguistic data (e.g. syntactic rules and constructions, lexical collocations, speakers’ individual speech histories). Significance. Given the inherently interactive nature of communication, we further propose that {BMIs} be entrained on neural responses associated with interactive dialogue tasks, as opposed to the typical practice of entraining {BMIs} with non-interactive presentations of language stimuli.},
	pages = {063001},
	number = {6},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Li, Leon and Negoita, Serban},
	urldate = {2021-05-17},
	date = {2018-10},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\VK33NI4Z\\Li and Negoita - 2018 - Brain-to-speech decoding will require linguistic a.pdf:application/pdf},
}

@inproceedings{blakely_localization_2008,
	title = {Localization and classification of phonemes using high spatial resolution electrocorticography ({ECoG}) grids},
	doi = {10.1109/IEMBS.2008.4650328},
	abstract = {We present results of cortical activity during phoneme pronunciation, recorded using miniaturized electrocorticography grids with high spatial resolution. A patient implanted with the miniature grid was instructed to audibly pronounce one of four phonemes. For each phoneme, we observed distinct spatial correlation patterns at the 3mm electrode spacing. We applied a support vector machine classification scheme and, for the first time, were able to distinguish discrete phonemes with high accuracy. In addition, we found that sub-regions of our miniature array were specific for distinct pairs of phonemes, showing that cortical phoneme processing occurs at a higher resolution than previously though.},
	eventtitle = {2008 30th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society},
	pages = {4964--4967},
	booktitle = {2008 30th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society},
	author = {Blakely, Timothy and Miller, Kai J. and Rao, Rajesh P.N. and Holmes, Mark D. and Ojemann, Jeffrey G.},
	date = {2008-08},
	note = {{ISSN}: 1558-4615},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\KP7XR88L\\4650328.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\CILDQSFM\\Blakely et al. - 2008 - Localization and classification of phonemes using .pdf:application/pdf},
}

@inproceedings{mugler_decoding_2015,
	title = {Decoding of articulatory gestures during word production using speech motor and premotor cortical activity},
	doi = {10.1109/EMBC.2015.7319597},
	abstract = {Brain-machine interfaces that directly translate attempted speech from the speech motor areas could change the lives of people with complete paralysis. However, it remains uncertain exactly how speech production is encoded in cortex. Improving this understanding could greatly improve brain-machine interface design. Specifically, it is not clear to what extent the different levels of speech production (phonemes, or speech sounds, and articulatory gestures, which describe the movements of the articulator muscles) are represented in the motor cortex. Using electrocorticographic ({ECoG}) electrodes on the cortical surface, we recorded neural activity from speech motor and premotor areas during speech production. We decoded both gestures and phonemes using the neural signals. Overall classification accuracy was higher for gestures than phonemes. In particular, gestures were better represented in the primary sensorimotor cortices, while phonemes were better represented in more anterior areas.},
	eventtitle = {2015 37th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society ({EMBC})},
	pages = {5339--5342},
	booktitle = {2015 37th Annual International Conference of the {IEEE} Engineering in Medicine and Biology Society ({EMBC})},
	author = {Mugler, Emily M. and Goldrick, Matthew and Rosenow, Joshua M. and Tate, Matthew C. and Slutzky, Marc W.},
	date = {2015-08},
	note = {{ISSN}: 1558-4615},
	keywords = {Decoding, Acoustics, Electrodes, Speech, Accuracy, Context, Production},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\UANKILE4\\7319597.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\QR47W2R2\\Mugler et al. - 2015 - Decoding of articulatory gestures during word prod.pdf:application/pdf},
}

@article{mugler_differential_2018,
	title = {Differential Representation of Articulatory Gestures and Phonemes in Precentral and Inferior Frontal Gyri},
	volume = {38},
	rights = {Copyright © 2018 the authors 0270-6474/18/389803-11\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/38/46/9803},
	doi = {10.1523/JNEUROSCI.1206-18.2018},
	abstract = {Speech is a critical form of human communication and is central to our daily lives. Yet, despite decades of study, an understanding of the fundamental neural control of speech production remains incomplete. Current theories model speech production as a hierarchy from sentences and phrases down to words, syllables, speech sounds (phonemes), and the actions of vocal tract articulators used to produce speech sounds (articulatory gestures). Here, we investigate the cortical representation of articulatory gestures and phonemes in ventral precentral and inferior frontal gyri in men and women. Our results indicate that ventral precentral cortex represents gestures to a greater extent than phonemes, while inferior frontal cortex represents both gestures and phonemes. These findings suggest that speech production shares a common cortical representation with that of other types of movement, such as arm and hand movements. This has important implications both for our understanding of speech production and for the design of brain–machine interfaces to restore communication to people who cannot speak.
{SIGNIFICANCE} {STATEMENT} Despite being studied for decades, the production of speech by the brain is not fully understood. In particular, the most elemental parts of speech, speech sounds (phonemes) and the movements of vocal tract articulators used to produce these sounds (articulatory gestures), have both been hypothesized to be encoded in motor cortex. Using direct cortical recordings, we found evidence that primary motor and premotor cortices represent gestures to a greater extent than phonemes. Inferior frontal cortex (part of Broca's area) appears to represent both gestures and phonemes. These findings suggest that speech production shares a similar cortical organizational structure with the movement of other body parts.},
	pages = {9803--9813},
	number = {46},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Mugler, Emily M. and Tate, Matthew C. and Livescu, Karen and Templer, Jessica W. and Goldrick, Matthew A. and Slutzky, Marc W.},
	urldate = {2021-05-18},
	date = {2018-11-14},
	langid = {english},
	pmid = {30257858},
	note = {Publisher: Society for Neuroscience
Section: Research Articles},
	keywords = {articulatory gestures, speech production, brain–computer interface, encoding, phonemes, segments},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\947T3ERH\\Mugler et al. - 2018 - Differential Representation of Articulatory Gestur.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\PDJHPVUW\\9803.html:text/html},
}

@article{lotte_electrocorticographic_2015,
	title = {Electrocorticographic representations of segmental features in continuous speech},
	volume = {9},
	issn = {1662-5161},
	url = {https://www.frontiersin.org/articles/10.3389/fnhum.2015.00097/full},
	doi = {10.3389/fnhum.2015.00097},
	abstract = {Acoustic speech output results from coordinated articulation of dozens of muscles, bones and cartilages of the vocal mechanism. While we commonly take the fluency and speed of our speech productions for granted, the neural mechanisms facilitating the requisite muscular control are not completely understood. Previous neuroimaging and electrophysiology studies of speech sensorimotor control has typically concentrated on speech sounds (i.e., phonemes, syllables and words) in isolation; sentence-length investigations have largely been used to inform coincident linguistic processing. In this study, we examined the neural representations of segmental features (place and manner of articulation, and voicing status) in the context of fluent, continuous speech production. We used recordings from the cortical surface (electrocorticography ({ECoG})) to simultaneously evaluate the spatial topography and temporal dynamics of the neural correlates of speech articulation that may mediate the generation of hypothesized gestural or articulatory scores. We found that the representation of place of articulation involved broad networks of brain regions during all phases of speech production: preparation, execution and monitoring. In contrast, manner of articulation and voicing status were dominated by auditory cortical responses after speech had been initiated. These results provide a new insight into the articulatory and auditory processes underlying speech production in terms of their motor requirements and acoustic correlates.},
	journaltitle = {Frontiers in Human Neuroscience},
	shortjournal = {Front. Hum. Neurosci.},
	author = {Lotte, Fabien and Brumberg, Jonathan S. and Brunner, Peter and Gunduz, Aysegul and Ritaccio, Anthony L. and Guan, Cuntai and Schalk, Gerwin},
	urldate = {2021-05-18},
	date = {2015},
	note = {Publisher: Frontiers},
	keywords = {electrocorticography ({ECoG}), manner of articulation, place of articulation, Speech Processing, Voicing},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\KVYWQS45\\Lotte et al. - 2015 - Electrocorticographic representations of segmental.pdf:application/pdf},
}

@article{bocquelet_key_2016,
	title = {Key considerations in designing a speech brain-computer interface},
	volume = {110},
	issn = {0928-4257},
	url = {https://www.sciencedirect.com/science/article/pii/S0928425717300426},
	doi = {10.1016/j.jphysparis.2017.07.002},
	series = {{SI}: {GDR} Multielectrode},
	abstract = {Restoring communication in case of aphasia is a key challenge for neurotechnologies. To this end, brain-computer strategies can be envisioned to allow artificial speech synthesis from the continuous decoding of neural signals underlying speech imagination. Such speech brain-computer interfaces do not exist yet and their design should consider three key choices that need to be made: the choice of appropriate brain regions to record neural activity from, the choice of an appropriate recording technique, and the choice of a neural decoding scheme in association with an appropriate speech synthesis method. These key considerations are discussed here in light of (1) the current understanding of the functional neuroanatomy of cortical areas underlying overt and covert speech production, (2) the available literature making use of a variety of brain recording techniques to better characterize and address the challenge of decoding cortical speech signals, and (3) the different speech synthesis approaches that can be considered depending on the level of speech representation (phonetic, acoustic or articulatory) envisioned to be decoded at the core of a speech {BCI} paradigm.},
	pages = {392--401},
	number = {4},
	journaltitle = {Journal of Physiology-Paris},
	shortjournal = {Journal of Physiology-Paris},
	author = {Bocquelet, Florent and Hueber, Thomas and Girin, Laurent and Chabardès, Stéphan and Yvert, Blaise},
	urldate = {2021-05-20},
	date = {2016-11-01},
	langid = {english},
	keywords = {Speech synthesis, Aphasia, Neural decoding, Neural prosthesis, Rehabilitation, Silent speech},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\W2D7ZA2P\\Bocquelet et al. - 2016 - Key considerations in designing a speech brain-com.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\ESJS3EX9\\S0928425717300426.html:text/html},
}

@article{gaikwad_review_2010,
	title = {A Review on Speech Recognition Technique},
	volume = {10},
	issn = {09758887},
	url = {http://www.ijcaonline.org/volume10/number3/pxc3871976.pdf},
	doi = {10.5120/1462-1976},
	abstract = {The Speech is most prominent \& primary mode of Communication among of human being. The communication among human computer interaction is called human computer interface. Speech has potential of being important mode of interaction with computer .This paper gives an overview of major technological perspective and appreciation of the fundamental progress of speech recognition and also gives overview technique developed in each stage of speech recognition. This paper helps in choosing the technique along with their relative merits \& demerits. A comparative study of different technique is done as per stages. This paper is concludes with the decision on feature direction for developing technique in human computer interface system using Marathi Language.},
	pages = {16--24},
	number = {3},
	journaltitle = {International Journal of Computer Applications},
	shortjournal = {{IJCA}},
	author = {Gaikwad, Santosh K. and Gawali, Bharti W. and Yannawar, Pravin},
	urldate = {2021-05-21},
	date = {2010-11-10},
	langid = {english},
	file = {Gaikwad et al. - 2010 - A Review on Speech Recognition Technique.pdf:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\KBPI27WW\\Gaikwad et al. - 2010 - A Review on Speech Recognition Technique.pdf:application/pdf},
}

@book{sapir_language_1921,
	title = {Language: An Introduction to the Study of Speech},
	isbn = {978-0-7426-4001-6},
	shorttitle = {Language},
	abstract = {Professor Sapir analyzes, for student and common reader, the elements of language. Among these are the units of language, grammatical concepts and their origins, how languages differ and resemble each other, and the history of the growth of representative languages--Cover.},
	pagetotal = {278},
	publisher = {Harcourt, Brace},
	author = {Sapir, Edward},
	date = {1921},
	langid = {english},
	note = {Google-Books-{ID}: {JJJMAAAAMAAJ}},
}

@article{bouchard_functional_2013,
	title = {Functional organization of human sensorimotor cortex for speech articulation},
	volume = {495},
	rights = {2013 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature11911},
	doi = {10.1038/nature11911},
	abstract = {Speaking is one of the most complex actions that we perform, but nearly all of us learn to do it effortlessly. Production of fluent speech requires the precise, coordinated movement of multiple articulators (for example, the lips, jaw, tongue and larynx) over rapid time scales. Here we used high-resolution, multi-electrode cortical recordings during the production of consonant-vowel syllables to determine the organization of speech sensorimotor cortex in humans. We found speech-articulator representations that are arranged somatotopically on ventral pre- and post-central gyri, and that partially overlap at individual electrodes. These representations were coordinated temporally as sequences during syllable production. Spatial patterns of cortical activity showed an emergent, population-level representation, which was organized by phonetic features. Over tens of milliseconds, the spatial patterns transitioned between distinct representations for different consonants and vowels. These results reveal the dynamic organization of speech sensorimotor cortex during the generation of multi-articulator movements that underlies our ability to speak.},
	pages = {327--332},
	number = {7441},
	journaltitle = {Nature},
	author = {Bouchard, Kristofer E. and Mesgarani, Nima and Johnson, Keith and Chang, Edward F.},
	urldate = {2021-05-23},
	date = {2013-03},
	langid = {english},
	note = {Number: 7441
Publisher: Nature Publishing Group},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\LIUKFBL8\\Bouchard et al. - 2013 - Functional organization of human sensorimotor cort.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\T9MIU9XM\\nature11911.html:text/html},
}

@article{bocquelet_real-time_2016,
	title = {Real-Time Control of an Articulatory-Based Speech Synthesizer for Brain Computer Interfaces},
	volume = {12},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005119},
	doi = {10.1371/journal.pcbi.1005119},
	abstract = {Restoring natural speech in paralyzed and aphasic people could be achieved using a Brain-Computer Interface ({BCI}) controlling a speech synthesizer in real-time. To reach this goal, a prerequisite is to develop a speech synthesizer producing intelligible speech in real-time with a reasonable number of control parameters. We present here an articulatory-based speech synthesizer that can be controlled in real-time for future {BCI} applications. This synthesizer converts movements of the main speech articulators (tongue, jaw, velum, and lips) into intelligible speech. The articulatory-to-acoustic mapping is performed using a deep neural network ({DNN}) trained on electromagnetic articulography ({EMA}) data recorded on a reference speaker synchronously with the produced speech signal. This {DNN} is then used in both offline and online modes to map the position of sensors glued on different speech articulators into acoustic parameters that are further converted into an audio signal using a vocoder. In offline mode, highly intelligible speech could be obtained as assessed by perceptual evaluation performed by 12 listeners. Then, to anticipate future {BCI} applications, we further assessed the real-time control of the synthesizer by both the reference speaker and new speakers, in a closed-loop paradigm using {EMA} data recorded in real time. A short calibration period was used to compensate for differences in sensor positions and articulatory differences between new speakers and the reference speaker. We found that real-time synthesis of vowels and consonants was possible with good intelligibility. In conclusion, these results open to future speech {BCI} applications using such articulatory-based speech synthesizer.},
	pages = {e1005119},
	number = {11},
	journaltitle = {{PLOS} Computational Biology},
	shortjournal = {{PLOS} Computational Biology},
	author = {Bocquelet, Florent and Hueber, Thomas and Girin, Laurent and Savariaux, Christophe and Yvert, Blaise},
	urldate = {2021-05-23},
	date = {2016-11-23},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Speech, Speech signal processing, Acoustic signals, Audio equipment, Audio signal processing, Consonants, Signal filtering, Vowels},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\6C2EDINE\\Bocquelet et al. - 2016 - Real-Time Control of an Articulatory-Based Speech .pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\QMPP2NUB\\article.html:text/html},
}

@article{moses_real-time_2019,
	title = {Real-time decoding of question-and-answer speech dialogue using human cortical activity},
	volume = {10},
	rights = {2019 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-019-10994-4},
	doi = {10.1038/s41467-019-10994-4},
	abstract = {Natural communication often occurs in dialogue, differentially engaging auditory and sensorimotor brain regions during listening and speaking. However, previous attempts to decode speech directly from the human brain typically consider listening or speaking tasks in isolation. Here, human participants listened to questions and responded aloud with answers while we used high-density electrocorticography ({ECoG}) recordings to detect when they heard or said an utterance and to then decode the utterance’s identity. Because certain answers were only plausible responses to certain questions, we could dynamically update the prior probabilities of each answer using the decoded question likelihoods as context. We decode produced and perceived utterances with accuracy rates as high as 61\% and 76\%, respectively (chance is 7\% and 20\%). Contextual integration of decoded question likelihoods significantly improves answer decoding. These results demonstrate real-time decoding of speech in an interactive, conversational setting, which has important implications for patients who are unable to communicate.},
	pages = {3096},
	number = {1},
	journaltitle = {Nature Communications},
	author = {Moses, {DA} and Leonard, Matthew K. and Makin, Joseph G. and Chang, Edward F.},
	urldate = {2021-05-23},
	date = {2019-07-30},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\ZW6BKUFH\\Moses et al. - 2019 - Real-time decoding of question-and-answer speech d.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\NG5UXMRY\\s41467-019-10994-4.html:text/html},
}

@article{conant_human_2018,
	title = {Human Sensorimotor Cortex Control of Directly Measured Vocal Tract Movements during Vowel Production},
	volume = {38},
	rights = {Copyright © 2018 the authors 0270-6474/18/382955-12\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/38/12/2955},
	doi = {10.1523/JNEUROSCI.2382-17.2018},
	abstract = {During speech production, we make vocal tract movements with remarkable precision and speed. Our understanding of how the human brain achieves such proficient control is limited, in part due to the challenge of simultaneously acquiring high-resolution neural recordings and detailed vocal tract measurements. To overcome this challenge, we combined ultrasound and video monitoring of the supralaryngeal articulators (lips, jaw, and tongue) with electrocorticographic recordings from the cortical surface of 4 subjects (3 female, 1 male) to investigate how neural activity in the ventral sensory-motor cortex ({vSMC}) relates to measured articulator movement kinematics (position, speed, velocity, acceleration) during the production of English vowels. We found that high-gamma activity at many individual {vSMC} electrodes strongly encoded the kinematics of one or more articulators, but less so for vowel formants and vowel identity. Neural population decoding methods further revealed the structure of kinematic features that distinguish vowels. Encoding of articulator kinematics was sparsely distributed across time and primarily occurred during the time of vowel onset and offset. In contrast, encoding was low during the steady-state portion of the vowel, despite sustained neural activity at some electrodes. Significant representations were found for all kinematic parameters, but speed was the most robust. These findings enabled by direct vocal tract monitoring demonstrate novel insights into the representation of articulatory kinematic parameters encoded in the {vSMC} during speech production.
{SIGNIFICANCE} {STATEMENT} Speaking requires precise control and coordination of the vocal tract articulators (lips, jaw, and tongue). Despite the impressive proficiency with which humans move these articulators during speech production, our understanding of how the brain achieves such control is rudimentary, in part because the movements themselves are difficult to observe. By simultaneously measuring speech movements and the neural activity that gives rise to them, we demonstrate how neural activity in sensorimotor cortex produces complex, coordinated movements of the vocal tract.},
	pages = {2955--2966},
	number = {12},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Conant, David F. and Bouchard, Kristofer E. and Leonard, Matthew K. and Chang, Edward F.},
	urldate = {2021-05-23},
	date = {2018-03-21},
	langid = {english},
	pmid = {29439164},
	note = {Publisher: Society for Neuroscience
Section: Research Articles},
	keywords = {electrocorticography, speech production, sensorimotor cortex, speech motor control, vowels},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\57SPV567\\Conant et al. - 2018 - Human Sensorimotor Cortex Control of Directly Meas.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\SSQMV4MW\\2955.html:text/html},
}

@inproceedings{govalkar_comparison_2019,
	title = {A Comparison of Recent Neural Vocoders for Speech Signal Reconstruction},
	url = {http://www.isca-speech.org/archive/SSW_2019/abstracts/SSW10_O_1-2.html},
	doi = {10.21437/SSW.2019-2},
	eventtitle = {10th {ISCA} Speech Synthesis Workshop},
	pages = {7--12},
	booktitle = {10th {ISCA} Speech Synthesis Workshop},
	publisher = {{ISCA}},
	author = {Govalkar, Prachi and Fischer, Johannes and Zalkow, Frank and Dittmar, Christian},
	urldate = {2021-05-23},
	date = {2019-09-20},
	langid = {english},
}

@inproceedings{black_automatically_1997,
	title = {Automatically clustering similar units for unit selection in speech synthesis.},
	url = {https://era.ed.ac.uk/handle/1842/1236},
	abstract = {This paper describes a new method for synthesizing 
speech by concatenating sub-word units from a 
database of labelled speech. A large unit inventory is 
created by automatically clustering units of the same 
phone class based on their phonetic and prosodic context. 
The appropriate cluster is then selected for a target 
unit offering a small set of candidate units. An optimal 
path is found through the candidate units based on 
their distance from the cluster center and an acoustically 
based join cost. Details of the method and justification 
are presented. The results of experiments using 
two different databases are given, optimising various 
parameters within the system. Also a comparison 
with other existing selection based synthesis techniques 
is given showing the advantages this method has over 
existing ones. The method is implemented within a full 
text-to-speech system offering efficient natural sounding 
speech synthesis.},
	publisher = {International Speech Communication Association},
	author = {Black, Alan W. and Taylor, Paul A.},
	urldate = {2021-05-23},
	date = {1997},
	langid = {english},
	note = {Accepted: 2006-06-14T15:41:53Z},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\JBVTDXHM\\Black and Taylor - 1997 - Automatically clustering similar units for unit se.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\LQCJT8YU\\1236.html:text/html},
}

@inproceedings{hunt_unit_1996,
	title = {Unit selection in a concatenative speech synthesis system using a large speech database},
	volume = {1},
	doi = {10.1109/ICASSP.1996.541110},
	abstract = {One approach to the generation of natural-sounding synthesized speech waveforms is to select and concatenate units from a large speech database. Units (in the current work, phonemes) are selected to produce a natural realisation of a target phoneme sequence predicted from text which is annotated with prosodic and phonetic context information. We propose that the units in a synthesis database can be considered as a state transition network in which the state occupancy cost is the distance between a database unit and a target, and the transition cost is an estimate of the quality of concatenation of two consecutive units. This framework has many similarities to {HMM}-based speech recognition. A pruned Viterbi search is used to select the best units for synthesis from the database. This approach to waveform synthesis permits training from natural speech: two methods for training from speech are presented which provide weights which produce more natural speech than can be obtained by hand-tuning.},
	eventtitle = {1996 {IEEE} International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings},
	pages = {373--376 vol. 1},
	booktitle = {1996 {IEEE} International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings},
	author = {Hunt, A.J. and Black, A.W.},
	date = {1996-05},
	note = {{ISSN}: 1520-6149},
	keywords = {Speech synthesis, Speech recognition, Control system synthesis, Costs, Databases, Laboratories, Natural languages, Network synthesis, State estimation, Viterbi algorithm},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\A2WE84NU\\541110.html:text/html;Submitted Version:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\22K6XKNA\\Hunt and Black - 1996 - Unit selection in a concatenative speech synthesis.pdf:application/pdf},
}

@inproceedings{wang_comparison_2018,
	title = {A comparison of recent waveform generation and acoustic modeling methods for neural-network-based speech synthesis},
	pages = {4804--4808},
	booktitle = {2018 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	publisher = {{IEEE}},
	author = {Wang, Xin and Lorenzo-Trueba, Jaime and Takaki, Shinji and Juvela, Lauri and Yamagishi, Junichi},
	date = {2018},
	file = {Full Text:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\6QXUURBJ\\Wang et al. - 2018 - A comparison of recent waveform generation and aco.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\LEXRH5UR\\8461452.html:text/html},
}

@inproceedings{black_statistical_2007,
	title = {Statistical parametric speech synthesis},
	volume = {4},
	pages = {IV--1229},
	booktitle = {2007 {IEEE} International Conference on Acoustics, Speech and Signal Processing-{ICASSP}'07},
	publisher = {{IEEE}},
	author = {Black, Alan W. and Zen, Heiga and Tokuda, Keiichi},
	date = {2007},
	file = {Full Text:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\P6JBXGRX\\Black et al. - 2007 - Statistical parametric speech synthesis.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\2UD7E98C\\4218329.html:text/html},
}

@inproceedings{griffin_signal_1983,
	title = {Signal estimation from modified short-time Fourier transform},
	volume = {8},
	doi = {10.1109/ICASSP.1983.1172092},
	abstract = {In this paper, we present an algorithm to estimate a signal from its modified short-time Fourier transform ({STFT}). This algorithm is computationally simple and is obtained by minimizing the mean squared error between the {STFT} of the estimated signal and the modified {STFT}. Using this algorithm, we also develop an iterative algorithm to estimate a signal from its modified {STFT} magnitude. The iterative algorithm is shown to decrease, in each iteration, the mean squared error between the {STFT} magnitude of the estimated signal and the modified {STFT} magnitude. The major computation involved in the iterative algorithm is the discrete Fourier transform ({DFT}) computation, and the algorithm appears to be real-time implementable with current hardware technology. The algorithm developed in this paper has been applied to the time-scale modification of speech. The resulting system generates very high-quality speech, and appears to be better in performance than any existing method.},
	eventtitle = {{ICASSP} '83. {IEEE} International Conference on Acoustics, Speech, and Signal Processing},
	pages = {804--807},
	booktitle = {{ICASSP} '83. {IEEE} International Conference on Acoustics, Speech, and Signal Processing},
	author = {Griffin, D. and Lim, Jae},
	date = {1983-04},
	keywords = {Signal processing, Laboratories, Computer errors, Degradation, Discrete Fourier transforms, Estimation, Fourier transforms, Hardware, Iterative algorithms, Speech enhancement},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\QHYNXM4V\\1172092.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\IX7X8HZS\\Griffin and Lim - 1983 - Signal estimation from modified short-time Fourier.pdf:application/pdf},
}

@inproceedings{perraudin_fast_2013,
	title = {A fast Griffin-Lim algorithm},
	doi = {10.1109/WASPAA.2013.6701851},
	abstract = {In this paper, we present a new algorithm to estimate a signal from its short-time Fourier transform modulus ({STFTM}). This algorithm is computationally simple and is obtained by an acceleration of the well-known Griffin-Lim algorithm ({GLA}). Before deriving the algorithm, we will give a new interpretation of the {GLA} and formulate the phase recovery problem in an optimization form. We then present some experimental results where the new algorithm is tested on various signals. It shows not only significant improvement in speed of convergence but it does as well recover the signals with a smaller error than the traditional {GLA}.},
	eventtitle = {2013 {IEEE} Workshop on Applications of Signal Processing to Audio and Acoustics},
	pages = {1--4},
	booktitle = {2013 {IEEE} Workshop on Applications of Signal Processing to Audio and Acoustics},
	author = {Perraudin, Nathanaël and Balazs, Peter and Søndergaard, Peter L.},
	date = {2013-10},
	note = {{ISSN}: 1947-1629},
	keywords = {Acoustics, Fourier transforms, Algorithm design and analysis, Convergence, Magnitude-only reconstruction, Phase reconstruction, Short-time Fourier transform, signal estimation, Signal processing algorithms, Spectrogram, spectrogram inversion, time-scale modification ({TSM})},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\4HGMU5R6\\6701851.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\KG2E8VJ9\\Perraudin et al. - 2013 - A fast Griffin-Lim algorithm.pdf:application/pdf},
}

@inproceedings{angrick_speech_2020,
	title = {Speech Spectrogram Estimation from Intracranial Brain Activity Using a Quantization Approach},
	url = {http://www.isca-speech.org/archive/Interspeech_2020/abstracts/2946.html},
	doi = {10.21437/Interspeech.2020-2946},
	abstract = {Direct synthesis from intracranial brain activity into acoustic speech might provide an intuitive and natural communication means for speech-impaired users. In previous studies we have used logarithmic Mel-scaled speech spectrograms ({logMels}) as an intermediate representation in the decoding from {ElectroCorticoGraphic} ({ECoG}) recordings to an audible waveform. Melscaled speech spectrograms have a long tradition in acoustic speech processing and speech synthesis applications. In the past, we relied on regression approaches to ﬁnd a mapping from brain activity to {logMel} spectral coefﬁcients, due to the continuous feature space. However, regression tasks are unbounded and thus neuronal ﬂuctuations in brain activity may result in abnormally high amplitudes in a synthesized acoustic speech signal. To mitigate these issues, we propose two methods for quantization of power values to discretize the feature space of logarithmic Mel-scaled spectral coefﬁcients by using the median and the logistic formula, respectively, to reduce the complexity and restricting the number of intervals. We evaluate the practicability in a proof-of-concept with one participant through a simple classiﬁcation based on linear discriminant analysis and compare the resulting waveform with the original speech. Reconstructed spectrograms achieve Pearson correlation coefﬁcients with a mean of r=0.5 ± 0.11 in a 5-fold cross validation.},
	eventtitle = {Interspeech 2020},
	pages = {2777--2781},
	booktitle = {Interspeech 2020},
	publisher = {{ISCA}},
	author = {Angrick, M and Herff, Christian and Johnson, Garett and Shih, Jerry and Krusienski, Dean and Schultz, Tanja},
	urldate = {2021-05-24},
	date = {2020-10-25},
	langid = {english},
	file = {Angrick et al. - 2020 - Speech Spectrogram Estimation from Intracranial Br.pdf:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\8YYQ4VMJ\\Angrick et al. - 2020 - Speech Spectrogram Estimation from Intracranial Br.pdf:application/pdf;Angrick et al. - 2020 - Speech Spectrogram Estimation from Intracranial Br.pdf:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\JBEMVN22\\Angrick et al. - 2020 - Speech Spectrogram Estimation from Intracranial Br.pdf:application/pdf},
}

@article{airaksinen_comparison_2018,
	title = {A Comparison Between {STRAIGHT}, Glottal, and Sinusoidal Vocoding in Statistical Parametric Speech Synthesis},
	volume = {26},
	issn = {2329-9304},
	doi = {10.1109/TASLP.2018.2835720},
	abstract = {A vocoder is used to express a speech waveform with a controllable parametric representation that can be converted back into a speech waveform. Vocoders representing their main categories (mixed excitation, glottal, and sinusoidal vocoders) were compared in this study with formal and crowd-sourced listening tests. The vocoder quality was measured within the context of analysis-synthesis as well as text-to-speech ({TTS}) synthesis in a modern statistical parametric speech synthesis framework. Furthermore, the {TTS} experiments were divided into synthesis with vocoder-specific features and synthesis with a shared envelope model, where the waveform generation method of the vocoders is mainly responsible for the quality differences. Finally, all of the tests included four distinct voices as a way to investigate the effect of different speakers on the synthesized speech quality. The obtained results suggest that the choice of the voice has a profound impact on the overall quality of the vocoder-generated speech, and the best vocoder for each voice can vary case by case. The single best-rated {TTS} system was obtained with the glottal vocoder {GlottDNN} using a male voice with low expressiveness. However, the results indicate that the sinusoidal vocoder {PML} (pulse model in log-domain) has the best overall performance across the performed tests. Finally, when controlling for the spectral models of the vocoders, the observed differences are similar to the baseline results. This indicates that the waveform generation method of a vocoder is essential for quality improvements.},
	pages = {1658--1670},
	number = {9},
	journaltitle = {{IEEE}/{ACM} Transactions on Audio, Speech, and Language Processing},
	author = {Airaksinen, Manu and Juvela, Lauri and Bollepalli, Bajibabu and Yamagishi, Junichi and Alku, Paavo},
	date = {2018-09},
	note = {Conference Name: {IEEE}/{ACM} Transactions on Audio, Speech, and Language Processing},
	keywords = {vocoder, Predictive models, Speech synthesis, Acoustics, Production, statistical parametric speech synthesis, Transfer functions, Vocoders},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\GPEEWRLH\\8357921.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\QN7994ZM\\Airaksinen et al. - 2018 - A Comparison Between STRAIGHT, Glottal, and Sinuso.pdf:application/pdf},
}

@unpublished{rabbani_online_nodate,
	location = {Chicago, Il},
	title = {Online {DNN}-based Synthesis and Recognition of Isolated Syllables in Electrocorticography},
	type = {Poster},
	howpublished = {Poster},
	note = {Society for Neuroscience 2019},
	author = {Rabbani, Q and Luo, S and Coogan, C and Richardson, R.M. and Hermansky, Hynek and Crone, N. E.},
}

@article{lametti_sensory_2012,
	title = {Sensory Preference in Speech Production Revealed by Simultaneous Alteration of Auditory and Somatosensory Feedback},
	volume = {32},
	rights = {Copyright © 2012 the authors 0270-6474/12/329351-08\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/32/27/9351},
	doi = {10.1523/JNEUROSCI.0404-12.2012},
	abstract = {The idea that humans learn and maintain accurate speech by carefully monitoring auditory feedback is widely held. But this view neglects the fact that auditory feedback is highly correlated with somatosensory feedback during speech production. Somatosensory feedback from speech movements could be a primary means by which cortical speech areas monitor the accuracy of produced speech. We tested this idea by placing the somatosensory and auditory systems in competition during speech motor learning. To do this, we combined two speech-learning paradigms to simultaneously alter somatosensory and auditory feedback in real time as subjects spoke. Somatosensory feedback was manipulated by using a robotic device that altered the motion path of the jaw. Auditory feedback was manipulated by changing the frequency of the first formant of the vowel sound and playing back the modified utterance to the subject through headphones. The amount of compensation for each perturbation was used as a measure of sensory reliance. All subjects were observed to correct for at least one of the perturbations, but auditory feedback was not dominant. Indeed, some subjects showed a stable preference for either somatosensory or auditory feedback during speech.},
	pages = {9351--9358},
	number = {27},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Lametti, Daniel R. and Nasir, Sazzad M. and Ostry, David J.},
	urldate = {2021-05-28},
	date = {2012-07-04},
	langid = {english},
	pmid = {22764242},
	note = {Publisher: Society for Neuroscience
Section: Articles},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\2XHZL3EX\\Lametti et al. - 2012 - Sensory Preference in Speech Production Revealed b.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\9LJ8CFMA\\9351.html:text/html},
}

@article{brainard_auditory_2000,
	title = {Auditory feedback in learning and maintenance of vocal behaviour},
	volume = {1},
	rights = {2000 Macmillan Magazines Ltd.},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/35036205},
	doi = {10.1038/35036205},
	abstract = {Songbirds are one of the best-studied examples of vocal learners. Learning of both human speech and birdsong depends on hearing. Once learned, adult song in many species remains unchanging, suggesting a reduced influence of sensory experience. Recent studies have revealed, however, that adult song is not always stable, extending our understanding of the mechanisms involved in song maintenance, and their similarity to those active during song learning. Here we review some of the processes that contribute to song learning and production, with an emphasis on the role of auditory feedback. We then consider some of the possible neural substrates involved in these processes, particularly basal ganglia circuitry. Although a thorough treatment of human speech is beyond the scope of this article, we point out similarities between speech and song learning, and ways in which studies of these disparate behaviours complement each other in developing an understanding of general principles that contribute to learning and maintenance of vocal behaviour.},
	pages = {31--40},
	number = {1},
	journaltitle = {Nature Reviews Neuroscience},
	author = {Brainard, Michael S. and Doupe, Allison J.},
	urldate = {2021-05-28},
	date = {2000-10},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\T2XUZPSI\\Brainard and Doupe - 2000 - Auditory feedback in learning and maintenance of v.pdf:application/pdf},
}

@article{jones_speech_2007,
	title = {Speech disruption during delayed auditory feedback with simultaneous visual feedback},
	volume = {122},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/10.1121/1.2772402},
	doi = {10.1121/1.2772402},
	abstract = {Delayed auditory feedback ({DAF}) regarding speech can cause dysfluency. The purpose of this study was to explore whether providing visual feedback in addition to {DAF} would ameliorate speech disruption. Speakers repeated sentences and heard their auditory feedback delayed with and without simultaneous visual feedback. {DAF} led to increased sentence durations and an increased number of speech disruptions. Although visual feedback did not reduce {DAF} effects on duration, a promising but nonsignificant trend was observed for fewer speech disruptions when visual feedback was provided. This trend was significant in speakers who were overall less affected by {DAF}. The results suggest the possibility that speakers strategically use alternative sources of feedback.},
	pages = {EL135--EL141},
	number = {4},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Jones, Jeffery A. and Striemer, Danielle},
	urldate = {2021-05-28},
	date = {2007-09-17},
	note = {Publisher: Acoustical Society of America},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\TBA4RSRC\\Jones and Striemer - 2007 - Speech disruption during delayed auditory feedback.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\ZIBN59A5\\1.html:text/html},
}

@article{stuart_effect_2002,
	title = {Effect of delayed auditory feedback on normal speakers at two speech rates},
	volume = {111},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.1466868},
	doi = {10.1121/1.1466868},
	pages = {2237--2241},
	number = {5},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Stuart, Andrew and Kalinowski, Joseph and Rastatter, Michael P. and Lynch, Kerry},
	urldate = {2021-05-28},
	date = {2002-05-01},
	note = {Publisher: Acoustical Society of America},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\BFY6JFEW\\Stuart et al. - 2002 - Effect of delayed auditory feedback on normal spea.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\FTXQVX3H\\1.html:text/html},
}

@article{guenther_role_2015,
	title = {Role of the auditory system in speech production},
	volume = {129},
	pages = {161--175},
	journaltitle = {Handbook of clinical neurology},
	author = {Guenther, Frank H. and Hickok, Gregory},
	date = {2015},
	note = {Publisher: Elsevier},
	file = {Full Text:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\H9Q2XUFR\\B9780444626301000093.html:text/html},
}

@article{waldstein_effects_1990,
	title = {Effects of postlingual deafness on speech production: Implications for the role of auditory feedback},
	volume = {88},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/abs/10.1121/1.400107},
	doi = {10.1121/1.400107},
	shorttitle = {Effects of postlingual deafness on speech production},
	pages = {2099--2114},
	number = {5},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Waldstein, Robin S.},
	urldate = {2021-05-28},
	date = {1990-11-01},
	note = {Publisher: Acoustical Society of America},
	file = {Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\X6QUDTCU\\1.html:text/html},
}

@article{perkell_time_2007,
	title = {Time course of speech changes in response to unanticipated short-term changes in hearing state},
	volume = {121},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/10.1121/1.2642349},
	doi = {10.1121/1.2642349},
	abstract = {The timing of changes in parameters of speech production was investigated in six cochlear implant users by switching their implant microphones off and on a number of times in a single experimental session. The subjects repeated four short, two-word utterances, /{dV}1n♯{SV}2d/∕{dV}1n♯{SV}2d∕{\textless}math display="inline" overflow="scroll" altimg="eq-00001.gif"{\textgreater}{\textless}mrow{\textgreater}{\textless}mo{\textgreater}∕{\textless}/mo{\textgreater}{\textless}mi{\textgreater}d{\textless}/mi{\textgreater}{\textless}msub{\textgreater}{\textless}mi{\textgreater}V{\textless}/mi{\textgreater}{\textless}mn{\textgreater}1{\textless}/mn{\textgreater}{\textless}/msub{\textgreater}{\textless}mi{\textgreater}n{\textless}/mi{\textgreater}{\textless}mi{\textgreater}♯{\textless}/mi{\textgreater}{\textless}msub{\textgreater}{\textless}mi{\textgreater}{SV}{\textless}/mi{\textgreater}{\textless}mn{\textgreater}2{\textless}/mn{\textgreater}{\textless}/msub{\textgreater}{\textless}mi{\textgreater}d{\textless}/mi{\textgreater}{\textless}mo{\textgreater}∕{\textless}/mo{\textgreater}{\textless}/mrow{\textgreater}{\textless}/math{\textgreater} (S=∕s∕S=∕s∕{\textless}math display="inline" overflow="scroll" altimg="eq-00002.gif"{\textgreater}{\textless}mrow{\textgreater}{\textless}mi mathvariant="normal"{\textgreater}S{\textless}/mi{\textgreater}{\textless}mo{\textgreater}={\textless}/mo{\textgreater}{\textless}mo{\textgreater}∕{\textless}/mo{\textgreater}{\textless}mi{\textgreater}s{\textless}/mi{\textgreater}{\textless}mo{\textgreater}∕{\textless}/mo{\textgreater}{\textless}/mrow{\textgreater}{\textless}/math{\textgreater} or /ʃ/), in quasi-random order. The changes between hearing and nonhearing states were introduced by a voice-activated switch at V1V1{\textless}math display="inline" overflow="scroll" altimg="eq-00003.gif"{\textgreater}{\textless}msub{\textgreater}{\textless}mi{\textgreater}V{\textless}/mi{\textgreater}{\textless}mn{\textgreater}1{\textless}/mn{\textgreater}{\textless}/msub{\textgreater}{\textless}/math{\textgreater} onset. “Postural” measures were made of vowel sound pressure level ({SPL}), duration, F0F0{\textless}math display="inline" overflow="scroll" altimg="eq-00004.gif"{\textgreater}{\textless}mrow{\textgreater}{\textless}mi{\textgreater}F{\textless}/mi{\textgreater}{\textless}mn{\textgreater}0{\textless}/mn{\textgreater}{\textless}/mrow{\textgreater}{\textless}/math{\textgreater}; contrast measures were made of vowel separation (distance between pair members in the formant plane) and sibilant separation (difference in spectral means). Changes in parameter values were averaged over multiple utterances, lined up with respect to the switch. No matter whether prosthetic hearing was blocked or restored, contrast measures for vowels and sibilants did not change systematically. Some changes in duration, {SPL} and F0F0{\textless}math display="inline" overflow="scroll" altimg="eq-00005.gif"{\textgreater}{\textless}mrow{\textgreater}{\textless}mi{\textgreater}F{\textless}/mi{\textgreater}{\textless}mn{\textgreater}0{\textless}/mn{\textgreater}{\textless}/mrow{\textgreater}{\textless}/math{\textgreater} were observed during the vowel within which hearing state was changed, V1V1{\textless}math display="inline" overflow="scroll" altimg="eq-00006.gif"{\textgreater}{\textless}msub{\textgreater}{\textless}mi{\textgreater}V{\textless}/mi{\textgreater}{\textless}mn{\textgreater}1{\textless}/mn{\textgreater}{\textless}/msub{\textgreater}{\textless}/math{\textgreater}, as well as during V2V2{\textless}math display="inline" overflow="scroll" altimg="eq-00007.gif"{\textgreater}{\textless}msub{\textgreater}{\textless}mi{\textgreater}V{\textless}/mi{\textgreater}{\textless}mn{\textgreater}2{\textless}/mn{\textgreater}{\textless}/msub{\textgreater}{\textless}/math{\textgreater} and subsequent utterance repetitions. Thus, sound segment contrasts appear to be controlled differently from the postural parameters of speaking rate and average {SPL} and F0F0{\textless}math display="inline" overflow="scroll" altimg="eq-00008.gif"{\textgreater}{\textless}mrow{\textgreater}{\textless}mi{\textgreater}F{\textless}/mi{\textgreater}{\textless}mn{\textgreater}0{\textless}/mn{\textgreater}{\textless}/mrow{\textgreater}{\textless}/math{\textgreater}. These findings are interpreted in terms of the function of hypothesized feedback and feedforward mechanisms for speech motor control.},
	pages = {2296--2311},
	number = {4},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Perkell, Joseph S. and Lane, Harlan and Denny, Margaret and Matthies, Melanie L. and Tiede, Mark and Zandipour, Majid and Vick, Jennell and Burton, Ellen},
	urldate = {2021-05-28},
	date = {2007-03-30},
	note = {Publisher: Acoustical Society of America},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\DXNJTKVK\\Perkell et al. - 2007 - Time course of speech changes in response to unant.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\LJCSNEIN\\1.html:text/html},
}

@article{cowie_study_1982,
	title = {A study of speech deterioration in post-lingually deafened adults},
	volume = {96},
	pages = {101--112},
	number = {2},
	journaltitle = {The Journal of Laryngology \& Otology},
	author = {Cowie, Roddy and Douglas-Cowie, Ellen and Kerr, A. G.},
	date = {1982},
	note = {Publisher: Cambridge University Press},
	file = {Full Text:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\P7J7PNJ5\\Cowie et al. - 1982 - A study of speech deterioration in post-lingually .pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\YCMGDPMC\\E716516DD00A12A00493EF750E6FA460.html:text/html},
}

@article{perkell_theory_2000,
	title = {A theory of speech motor control and supporting data from speakers with normal hearing and with profound hearing loss},
	volume = {28},
	issn = {0095-4470},
	url = {https://www.sciencedirect.com/science/article/pii/S0095447000901165},
	doi = {10.1006/jpho.2000.0116},
	abstract = {A theory of the segmental component of speech motor control is presented, followed by supporting data. According to the theory, speech movements are programmed to achieve auditory/acoustic goals. The goals are determined partly by “saturation effects”, which are basic characteristics of speakers' production systems that make it possible to produce a sound output that has some relatively stable acoustic properties despite a somewhat variable motor input. The programming of articulatory movements to achieve auditory goals utilizes an internal model (or “mapping”) of relations between articulatory configurations and their acoustic consequences. The internal model is acquired and maintained with the use of auditory feedback. The supporting data for this theory come from experiments on speakers with normal hearing, cochlear implant users and a patient with neurofibromatosis-2.},
	pages = {233--272},
	number = {3},
	journaltitle = {Journal of Phonetics},
	shortjournal = {Journal of Phonetics},
	author = {Perkell, Joseph S. and Guenther, Frank H. and Lane, Harlan and Matthies, Melanie L. and Perrier, Pascal and Vick, Jennell and Wilhelms-Tricarico, Reiner and Zandipour, Majid},
	urldate = {2021-05-28},
	date = {2000-07-01},
	langid = {english},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\62HM8R3G\\Perkell et al. - 2000 - A theory of speech motor control and supporting da.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\BM36ZW97\\S0095447000901165.html:text/html},
}

@article{chesters_effects_2015,
	title = {The effects of delayed auditory and visual feedback on speech production},
	volume = {137},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/full/10.1121/1.4906266},
	doi = {10.1121/1.4906266},
	abstract = {Monitoring the sensory consequences of articulatory movements supports speaking. For           example, delaying auditory feedback of a speaker's voice disrupts speech production. Also,           there is evidence that this disruption may be decreased by immediate visual feedback,           i.e., seeing one's own articulatory movements. It is, however, unknown whether delayed           visual feedback affects speech production in fluent speakers. Here, the effects of delayed           auditory and visual feedback on speech fluency (i.e., speech rate and errors), vocal           control (i.e., intensity and pitch), and speech rhythm were investigated. Participants received           delayed (by 200 ms) or immediate auditory feedback, while repeating sentences. Moreover,           they received either no visual feedback, immediate visual feedback, or delayed visual           feedback (by 200, 400, and 600 ms). Delayed auditory feedback affected fluency, vocal           control, and rhythm. Immediate visual feedback had no effect on any of the speech measures           when it was combined with delayed auditory feedback. Delayed visual feedback did, however,           affect speech fluency when it was combined with delayed auditory feedback. In sum, the           findings show that delayed auditory feedback disrupts fluency, vocal control, and rhythm           and that delayed visual feedback can strengthen the disruptive effect of delayed auditory           feedback on fluency.},
	pages = {873--883},
	number = {2},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {Chesters, Jennifer and Baghai-Ravary, Ladan and Möttönen, Riikka},
	urldate = {2021-05-31},
	date = {2015-02-01},
	note = {Publisher: Acoustical Society of America},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\JFCGC4F4\\Chesters et al. - 2015 - The effects of delayed auditory and visual feedbac.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\ZSJTA2GY\\1.html:text/html},
}

@article{mackay_metamorphosis_1968,
	title = {Metamorphosis of a Critical Interval: Age‐Linked Changes in the Delay in Auditory Feedback that Produces Maximal Disruption of Speech},
	volume = {43},
	issn = {0001-4966},
	url = {https://asa.scitation.org/doi/10.1121/1.1910900},
	doi = {10.1121/1.1910900},
	shorttitle = {Metamorphosis of a Critical Interval},
	pages = {811--821},
	number = {4},
	journaltitle = {The Journal of the Acoustical Society of America},
	shortjournal = {The Journal of the Acoustical Society of America},
	author = {{MacKay}, Donald G.},
	urldate = {2021-05-31},
	date = {1968-04-01},
	note = {Publisher: Acoustical Society of America},
	file = {Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\YHLRKPFN\\1.html:text/html},
}

@article{antipova_effects_2008,
	title = {Effects of altered auditory feedback ({AAF}) on stuttering frequency during monologue speech production},
	volume = {33},
	issn = {0094-730X},
	url = {https://www.sciencedirect.com/science/article/pii/S0094730X08000673},
	doi = {10.1016/j.jfludis.2008.09.002},
	abstract = {The present study investigated the immediate effects of eight altered auditory feedback ({AAF}) parameters on stuttering frequency during monologue speech production on two occasions. One of the modern commercially available portable anti-stuttering devices, “The Pocket Speech Lab” (Casa Futura Technologies®) was used in the study to produce the auditory feedback alterations. Six types of combined delayed auditory feedback ({DAF}) and frequency shifted auditory feedback ({FAF}) and two types of {DAF} alone were tested for eight participants aged 16–55 years, with stuttering severity ranging from mild to severe. The present study found that {AAF} is an effective means to reduce stuttering frequency during monologue speech production. All eight {AAF} experimental conditions reduced stuttering frequency, however, there was substantial variability in the stuttering reduction effect across experimental conditions and across participants. There was also instability in stuttering reduction across the two testing sessions. On average, a 75ms time delay on its own and a combination of the 75ms time delay and a half octave downward frequency shift were found to be more effective than other combinations of {AAF} parameters that were investigated. Educational objectives: After reading this paper, the reader should be able to (1) summarize the research investigating the effect of altered auditory feedback on stuttering frequency during monologue speech production; (2) describe the stuttering reduction effect of the eight parameters of {AAF} tested during monologue speech production; and (3) discuss the possible clinical implications of the use of {AAF} for stuttering treatment.},
	pages = {274--290},
	number = {4},
	journaltitle = {Journal of Fluency Disorders},
	shortjournal = {Journal of Fluency Disorders},
	author = {Antipova, Elena A. and Purdy, Suzanne C. and Blakeley, Marjorie and Williams, Shelley},
	urldate = {2021-05-31},
	date = {2008-12-01},
	langid = {english},
	keywords = {Altered auditory feedback, Anti-stuttering device, Delayed auditory feedback, Frequency shifted auditory feedback, Stuttering},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\TPGDA6D6\\Antipova et al. - 2008 - Effects of altered auditory feedback (AAF) on stut.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\JZ5NJZR6\\S0094730X08000673.html:text/html},
}

@article{lincoln_altered_2006,
	title = {Altered auditory feedback and the treatment of stuttering: A review},
	volume = {31},
	issn = {0094-730X},
	url = {https://www.sciencedirect.com/science/article/pii/S0094730X06000301},
	doi = {10.1016/j.jfludis.2006.04.001},
	shorttitle = {Altered auditory feedback and the treatment of stuttering},
	abstract = {Several authors have suggested that devices delivering altered auditory feedback ({AAF}) may be a viable treatment for adults and children who stutter. This paper reviews published, peer reviewed journal papers from the past 10 years that investigate the effect of {AAF} during different speaking conditions, tasks and situations. A review of that literature indicates that considerable experimental evidence and limited Phase 1 treatment outcome evidence has been accumulated about the effect of {AAF} on the speech of people who stutter. However, critical knowledge about the effect of {AAF} during conversational speech and in everyday speaking situations is missing. Knowledge about how to determine the correct levels of {AAF} for individuals, and the characteristics of those likely to benefit from {AAF}, also needs to be established. At present there is no reason to accept a recent suggestion that {AAF} devices would be a defensible clinical option for children. In general device development and availability has occurred at a faster pace than clinical trials research. Educational objectives: After reading this paper readers should be able to: (1) describe what altered auditory feedback is and common ways the speech signal is altered in stuttering; (2) describe the effects of {AAF} on the speech of adults who stutter; (3) provide a critical analysis of the literature in the area of {AAF} and stuttering.},
	pages = {71--89},
	number = {2},
	journaltitle = {Journal of Fluency Disorders},
	shortjournal = {Journal of Fluency Disorders},
	author = {Lincoln, Michelle and Packman, Ann and Onslow, Mark},
	urldate = {2021-05-31},
	date = {2006-01-01},
	langid = {english},
	keywords = {Altered auditory feedback, Delayed auditory feedback, Stuttering, Frequency altered feedback, Treatment},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\R36ZZ3KS\\Lincoln et al. - 2006 - Altered auditory feedback and the treatment of stu.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\XDYTU7FR\\S0094730X06000301.html:text/html},
}

@article{kalinowski_stuttering_1996,
	title = {Stuttering amelioration at various auditory feedback delays and speech rates},
	volume = {31},
	issn = {0963-7273},
	doi = {10.3109/13682829609033157},
	abstract = {The primary purpose of this study was to determine if the finding of Kalinowski et al. (1993) of dramatic reductions in stuttering under delayed auditory feedback ({DAF}) at normal and fast speech rates could be replicated. The second purpose was to determine if stuttering frequency is differentially affected by various delays in an attempt to identify the optimal delay for fluency enhancement for both normal and fast speech rates. Fourteen adult stutterers read eight different passages at either a normal or fast speech rate under non-altered auditory feedback ({NAF}) and {DAF} with delays of 25, 50 and 75 ms. Results showed that significant fluency enhancement occurred under {DAF} at both normal and fast speech rates at all {DAF} settings (p {\textless} 0.05). This finding corroborates the notion that a slowed rate of speech is not a necessary antecedent for fluency improvement under conditions of altered auditory feedback. In addition, the results indicated that 50 ms appears to be the shortest delay producing the maximum reduction in stuttering frequency.},
	pages = {259--269},
	number = {3},
	journaltitle = {European Journal of Disorders of Communication: The Journal of the College of Speech and Language Therapists, London},
	shortjournal = {Eur J Disord Commun},
	author = {Kalinowski, J. and Stuart, A.},
	date = {1996},
	pmid = {8944848},
	keywords = {Speech, Stuttering, Adolescent, Adult, Auditory Perception, Biofeedback, Psychology, Female, Humans, Male, Middle Aged, Time Factors},
}

@article{zimmerman_effect_1997,
	title = {Effect of Altered Auditory Feedback on People Who Stutter During Scripted Telephone Conversations},
	volume = {40},
	url = {https://pubs.asha.org/doi/10.1044/jslhr.4005.1130},
	doi = {10.1044/jslhr.4005.1130},
	abstract = {The effect of altered auditory feedback ({AAF}) conditions on stuttering during scripted
         telephone conversations was investigated. Nine adult participants made 15 scripted
         telephone calls to businesses in New York City. Alterations in the participants' auditory
         feedback signal were generated by a commercially available digital signal processor
         (Casa Futura Technologies Desktop Fluency System Model {BTD}-400) that shifted participants'
         speech one-half octave down in frequency, produced a 50-ms delay, or produced non-altered
         auditory feedback. The {AAF} effects produced by the digital signal processor were not
         perceived by the recipients of the telephone calls. The proportion of stuttering events
         per scripted telephone conversations were significantly reduced in the {AAF} conditions
         relative to the non-altered auditory feedback condition (p=.0004). Stuttering frequency was reduced by 55\% and 60\% for the {FAF} and {DAF}, respectively.
         These findings demonstrate the applicability of this technology to situations of daily
         living involving telephone use.},
	pages = {1130--1134},
	number = {5},
	journaltitle = {Journal of Speech, Language, and Hearing Research},
	shortjournal = {Journal of Speech, Language, and Hearing Research},
	author = {Zimmerman, Stephen and Kalinowski, Joseph and Stuart, Andrew and Rastatter, Michael},
	urldate = {2021-05-31},
	date = {1997-10-01},
	note = {Publisher: American Speech-Language-Hearing Association},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\TS3PXNNT\\Zimmerman Stephen et al. - 1997 - Effect of Altered Auditory Feedback on People Who .pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\JWNHHLFE\\jslhr.4005.html:text/html},
}

@article{tian_mental_2010,
	title = {Mental imagery of speech and movement implicates the dynamics of internal forward models},
	volume = {1},
	issn = {1664-1078},
	url = {https://www.frontiersin.org/articles/10.3389/fpsyg.2010.00166/full},
	doi = {10.3389/fpsyg.2010.00166},
	abstract = {The classical concept of efference copies in the context of internal forward models has stimulated productive research in cognitive science and neuroscience. There are compelling reasons to argue for such a mechanism, but finding direct evidence in the human brain remains difficult. Here we investigate the dynamics of internal forward models from an unconventional angle: mental imagery, assessed while recording high temporal resolution neuronal activity using magnetoencephalography ({MEG}). We compare two overt and covert tasks; our covert, mental imagery tasks are unconfounded by overt input/output demands – but in turn necessitate the development of appropriate multi-dimensional topographic analyses. Finger tapping (studies 1-2) and speech experiments (studies 3-5) provide temporally constrained results that implicate the estimation of an efference copy. We suggest that one internal forward model over parietal cortex subserves the kinesthetic feeling in motor imagery. Secondly, observed auditory neural activity {\textasciitilde}170 ms after motor estimation in speech experiments (studies 3-5) demonstrates the anticipated auditory consequences of planned motor commands in a second internal forward model in imagery of speech production. Our results provide neurophysiological evidence from the human brain in favor of internal forward models deploying efference copies in somatosensory and auditory cortex, in finger tapping and speech production tasks, respectively, and also suggest the dynamics and sequential updating structure of internal forward models.},
	journaltitle = {Frontiers in Psychology},
	shortjournal = {Front. Psychol.},
	author = {Tian, Xing and Poeppel, David},
	urldate = {2021-05-31},
	date = {2010},
	note = {Publisher: Frontiers},
	keywords = {articulation, Auditory Cortex, corollary discharge, efference copy, imagined speech, Magnetoencephalography ({MEG}), motor, parietal cortex},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\6AJC9ZDR\\Tian and Poeppel - 2010 - Mental imagery of speech and movement implicates t.pdf:application/pdf},
}

@article{silversmith_plug-and-play_2021,
	title = {Plug-and-play control of a brain–computer interface through neural map stabilization},
	volume = {39},
	rights = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1696},
	url = {https://www.nature.com/articles/s41587-020-0662-5},
	doi = {10.1038/s41587-020-0662-5},
	abstract = {Brain–computer interfaces ({BCIs}) enable control of assistive devices in individuals with severe motor impairments. A limitation of {BCIs} that has hindered real-world adoption is poor long-term reliability and lengthy daily recalibration times. To develop methods that allow stable performance without recalibration, we used a 128-channel chronic electrocorticography ({ECoG}) implant in a paralyzed individual, which allowed stable monitoring of signals. We show that long-term closed-loop decoder adaptation, in which decoder weights are carried across sessions over multiple days, results in consolidation of a neural map and ‘plug-and-play’ control. In contrast, daily reinitialization led to degradation of performance with variable relearning. Consolidation also allowed the addition of control features over days, that is, long-term stacking of dimensions. Our results offer an approach for reliable, stable {BCI} control by leveraging the stability of {ECoG} interfaces and neural plasticity.},
	pages = {326--335},
	number = {3},
	journaltitle = {Nature Biotechnology},
	author = {Silversmith, Daniel B. and Abiri, Reza and Hardy, Nicholas F. and Natraj, Nikhilesh and Tu-Chan, Adelyn and Chang, Edward F. and Ganguly, Karunesh},
	urldate = {2021-06-01},
	date = {2021-03},
	langid = {english},
	note = {Number: 3
Publisher: Nature Publishing Group},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\MRZGC5QQ\\Silversmith et al. - 2021 - Plug-and-play control of a brain–computer interfac.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\I5LDMTLW\\s41587-020-0662-5.html:text/html},
}

@article{benabid_exoskeleton_2019,
	title = {An exoskeleton controlled by an epidural wireless brain–machine interface in a tetraplegic patient: a proof-of-concept demonstration},
	volume = {18},
	issn = {1474-4422, 1474-4465},
	url = {https://www.thelancet.com/journals/laneur/article/PIIS1474-4422(19)30321-7/abstract},
	doi = {10.1016/S1474-4422(19)30321-7},
	shorttitle = {An exoskeleton controlled by an epidural wireless brain–machine interface in a tetraplegic patient},
	abstract = {{\textless}h2{\textgreater}Summary{\textless}/h2{\textgreater}{\textless}h3{\textgreater}Background{\textless}/h3{\textgreater}{\textless}p{\textgreater}Approximately 20\% of traumatic cervical spinal cord injuries result in tetraplegia. Neuroprosthetics are being developed to manage this condition and thus improve the lives of patients. We aimed to test the feasibility of a semi-invasive technique that uses brain signals to drive an exoskeleton.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Methods{\textless}/h3{\textgreater}{\textless}p{\textgreater}We recruited two participants at Clinatec research centre, associated with Grenoble University Hospital, Grenoble, France, into our ongoing clinical trial. Inclusion criteria were age 18–45 years, stability of neurological deficits, a need for additional mobility expressed by the patient, ambulatory or hospitalised monitoring, registration in the French social security system, and signed informed consent. The exclusion criteria were previous brain surgery, anticoagulant treatments, neuropsychological sequelae, depression, substance dependence or misuse, and contraindications to magnetoencephalography ({MEG}), {EEG}, or {MRI}. One participant was excluded because of a technical problem with the implants. The remaining participant was a 28-year-old man, who had tetraplegia following a C4–C5 spinal cord injury. Two bilateral wireless epidural recorders, each with 64 electrodes, were implanted over the upper limb sensorimotor areas of the brain. Epidural electrocorticographic ({ECoG}) signals were processed online by an adaptive decoding algorithm to send commands to effectors (virtual avatar or exoskeleton). Throughout the 24 months of the study, the patient did various mental tasks to progressively increase the number of degrees of freedom.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Findings{\textless}/h3{\textgreater}{\textless}p{\textgreater}Between June 12, 2017, and July 21, 2019, the patient cortically controlled a programme that simulated walking and made bimanual, multi-joint, upper-limb movements with eight degrees of freedom during various reach-and-touch tasks and wrist rotations, using a virtual avatar at home (64·0\% [{SD} 5·1] success) or an exoskeleton in the laboratory (70·9\% [11·6] success). Compared with microelectrodes, epidural {ECoG} is semi-invasive and has similar efficiency. The decoding models were reusable for up to approximately 7 weeks without recalibration.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Interpretation{\textless}/h3{\textgreater}{\textless}p{\textgreater}These results showed long-term (24-month) activation of a four-limb neuroprosthetic exoskeleton by a complete brain–machine interface system using continuous, online epidural {ECoG} to decode brain activity in a tetraplegic patient. Up to eight degrees of freedom could be simultaneously controlled using a unique model, which was reusable without recalibration for up to about 7 weeks.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Funding{\textless}/h3{\textgreater}{\textless}p{\textgreater}French Atomic Energy Commission, French Ministry of Health, Edmond J Safra Philanthropic Foundation, Fondation Motrice, Fondation Nanosciences, Institut Carnot, Fonds de Dotation Clinatec.{\textless}/p{\textgreater}},
	pages = {1112--1122},
	number = {12},
	journaltitle = {The Lancet Neurology},
	shortjournal = {The Lancet Neurology},
	author = {Benabid, Alim Louis and Costecalde, Thomas and Eliseyev, Andrey and Charvet, Guillaume and Verney, Alexandre and Karakas, Serpil and Foerster, Michael and Lambert, Aurélien and Morinière, Boris and Abroug, Neil and Schaeffer, Marie-Caroline and Moly, Alexandre and Sauter-Starace, Fabien and Ratel, David and Moro, Cecile and Torres-Martinez, Napoleon and Langar, Lilia and Oddoux, Manuela and Polosan, Mircea and Pezzani, Stephane and Auboiroux, Vincent and Aksenova, Tetiana and Mestais, Corinne and Chabardes, Stephan},
	urldate = {2021-06-01},
	date = {2019-12-01},
	pmid = {31587955},
	note = {Publisher: Elsevier},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\4Z3DYPPA\\Benabid et al. - 2019 - An exoskeleton controlled by an epidural wireless .pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\3ZR99UR8\\fulltext.html:text/html},
}

@article{rao_chronic_2017,
	title = {Chronic ambulatory electrocorticography from human speech cortex},
	volume = {153},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811917302975},
	doi = {10.1016/j.neuroimage.2017.04.008},
	abstract = {Direct intracranial recording of human brain activity is an important approach for deciphering neural mechanisms of cognition. Such recordings, usually made in patients with epilepsy undergoing inpatient monitoring for seizure localization, are limited in duration and depend on patients’ tolerance for the challenges associated with recovering from brain surgery. Thus, typical intracranial recordings, similar to most non-invasive approaches in humans, provide snapshots of brain activity in acute, highly constrained settings, limiting opportunities to understand long timescale and natural, real-world phenomena. A new device for treating some forms of drug-resistant epilepsy, the {NeuroPace} {RNS}® System, includes a cranially-implanted neurostimulator and intracranial electrodes that continuously monitor brain activity and respond to incipient seizures with electrical counterstimulation. The {RNS} System can record epileptic brain activity over years, but whether it can record meaningful, behavior-related physiological responses has not been demonstrated. Here, in a human subject with electrodes implanted over high-level speech-auditory cortex (Wernicke's area; posterior superior temporal gyrus), we report that cortical evoked responses to spoken sentences are robust, selective to phonetic features, and stable over nearly 1.5 years. In a second subject with {RNS} System electrodes implanted over frontal cortex (Broca's area, posterior inferior frontal gyrus), we found that word production during a naming task reliably evokes cortical responses preceding speech onset. The spatiotemporal resolution, high signal-to-noise, and wireless nature of this system's intracranial recordings make it a powerful new approach to investigate the neural correlates of human cognition over long timescales in natural ambulatory settings.},
	pages = {273--282},
	journaltitle = {{NeuroImage}},
	shortjournal = {{NeuroImage}},
	author = {Rao, Vikram R. and Leonard, Matthew K. and Kleen, Jonathan K. and Lucas, Ben A. and Mirro, Emily A. and Chang, Edward F.},
	urldate = {2021-06-01},
	date = {2017-06-01},
	langid = {english},
	keywords = {{ECoG}, Broca's area, Chronic electrocorticography, Human, {RNS} System, Wernicke's area},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\X8W9CCZK\\Rao et al. - 2017 - Chronic ambulatory electrocorticography from human.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\IK3G7AKQ\\S1053811917302975.html:text/html},
}

@incollection{crone_high-frequency_2006,
	title = {High-frequency gamma oscillations and human brain mapping with electrocorticography},
	volume = {159},
	url = {https://www.sciencedirect.com/science/article/pii/S0079612306590193},
	series = {Event-Related Dynamics of Brain Oscillations},
	abstract = {Invasive {EEG} recordings with depth and/or subdural electrodes are occasionally necessary for the surgical management of patients with epilepsy refractory to medications. In addition to their vital clinical utility, electrocorticographic ({ECoG}) recordings provide an unprecedented opportunity to study the electrophysiological correlates of functional brain activation in greater detail than non-invasive recordings. The proximity of {ECoG} electrodes to the cortical sources of {EEG} activity enhances their spatial resolution, as well as their sensitivity and signal-to-noise ratio, particularly for high-frequency {EEG} activity. {ECoG} recordings have, therefore, been used to study the event-related dynamics of brain oscillations in a variety of frequency ranges, and in a variety of functional-neuroanatomic systems, including somatosensory and somatomotor systems, visual and auditory perceptual systems, and cortical networks responsible for language. These {ECoG} studies have confirmed and extended the original non-invasive observations of {ERD}/{ERS} phenomena in lower frequencies, and have discovered novel event-related responses in gamma frequencies higher than those previously observed in non-invasive recordings. In particular, broadband event-related gamma responses greater than 60Hz, extending up to ∼200Hz, have been observed in a variety of functional brain systems. The observation of these “high gamma” responses requires a recording system with an adequate sampling rate and dynamic range (we use 1000Hz at 16-bit A/D resolution) and is facilitated by event-related time–frequency analyses of the recorded signals. The functional response properties of high-gamma activity are distinct from those of {ERD}/{ERS} phenomena in lower frequencies. In particular, the timing and spatial localization of high-gamma {ERS} often appear to be more specific to the putative timing and localization of functional brain activation than alpha or beta {ERD}/{ERS}. These findings are consistent with the proposed role of synchronized gamma oscillations in models of neural computation, which have in turn been inspired by observations of gamma activity in animal preparations, albeit at somewhat lower frequencies. Although {ECoG} recordings cannot directly measure the synchronization of action potentials among assemblies of neurons, they may demonstrate event-related interactions between gamma oscillations in macroscopic local field potentials ({LFP}) generated by different large-scale populations of neurons engaged by the same functional task. Indeed, preliminary studies suggest that such interactions do occur in gamma frequencies, including high-gamma frequencies, at latencies consistent with the timing of task performance. The neuronal mechanisms underlying high-gamma activity and its unique response properties in humans are still largely unknown, but their investigation through invasive methods is expected to facilitate and expand their potential clinical and research applications, including functional brain mapping, brain–computer interfaces, and neurophysiological studies of human cognition.},
	pages = {275--295},
	booktitle = {Progress in Brain Research},
	publisher = {Elsevier},
	author = {Crone, Nathan E. and Sinai, Alon and Korzeniewska, Anna},
	editor = {Neuper, Christa and Klimesch, Wolfgang},
	urldate = {2021-06-01},
	date = {2006-01-01},
	langid = {english},
	doi = {10.1016/S0079-6123(06)59019-3},
	keywords = {auditory cortex, electrocorticography, sensorimotor cortex, {ERD}/{ERS}, functional mapping, gamma, language},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\CRAJ66TT\\Crone et al. - 2006 - High-frequency gamma oscillations and human brain .pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\K4SX58CZ\\S0079612306590193.html:text/html},
}

@article{chen_when_2016,
	title = {The ‘when’ and ‘where’ of semantic coding in the anterior temporal lobe: Temporal representational similarity analysis of electrocorticogram data},
	volume = {79},
	issn = {0010-9452},
	url = {https://www.sciencedirect.com/science/article/pii/S0010945216300302},
	doi = {10.1016/j.cortex.2016.02.015},
	shorttitle = {The ‘when’ and ‘where’ of semantic coding in the anterior temporal lobe},
	abstract = {Electrocorticograms ({ECoG}) provide a unique opportunity to monitor neural activity directly at the cortical surface. Ten patients with subdural electrodes covering ventral and lateral anterior temporal regions ({ATL}) performed a picture naming task. Temporal representational similarity analysis ({RSA}) was used, for the first time, to compare spatio-temporal neural patterns from the {ATL} surface with pre-defined theoretical models. The results indicate that the neural activity in the ventral subregion of the {ATL} codes semantic representations from 250 msec after picture onset. The observed activation similarity was not related to the visual similarity of the pictures or the phonological similarity of their names. In keeping with convergent evidence for the importance of the {ATL} in semantic processing, these results provide the first direct evidence of semantic coding from the surface of the ventral {ATL} and its time-course.},
	pages = {1--13},
	journaltitle = {Cortex},
	shortjournal = {Cortex},
	author = {Chen, Y. and Shimotake, A. and Matsumoto, R. and Kunieda, T. and Kikuchi, T. and Miyamoto, S. and Fukuyama, H. and Takahashi, R. and Ikeda, A. and Lambon Ralph, M. A.},
	urldate = {2021-06-01},
	date = {2016-06-01},
	langid = {english},
	keywords = {Anterior temporal lobe, Multi-voxel pattern analysis, Representational similarity, Semantic representation},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\W5GHIUQN\\Chen et al. - 2016 - The ‘when’ and ‘where’ of semantic coding in the a.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\6UD3IYG6\\S0010945216300302.html:text/html},
}

@article{moses_neuroprosthesis_2021,
	title = {Neuroprosthesis for Decoding Speech in a Paralyzed Person with Anarthria},
	volume = {385},
	issn = {0028-4793},
	url = {https://doi.org/10.1056/NEJMoa2027540},
	doi = {10.1056/NEJMoa2027540},
	pages = {217--227},
	number = {3},
	journaltitle = {New England Journal of Medicine},
	author = {Moses, David A. and Metzger, Sean L. and Liu, Jessie R. and Anumanchipalli, Gopala K. and Makin, Joseph G. and Sun, Pengfei F. and Chartier, Josh and Dougherty, Maximilian E. and Liu, Patricia M. and Abrams, Gary M. and Tu-Chan, Adelyn and Ganguly, Karunesh and Chang, Edward F.},
	urldate = {2021-08-27},
	date = {2021-07-15},
	note = {Publisher: Massachusetts Medical Society
\_eprint: https://doi.org/10.1056/{NEJMoa}2027540},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\LVJEBT7X\\Moses et al. - 2021 - Neuroprosthesis for Decoding Speech in a Paralyzed.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\V9424CXV\\NEJMoa2027540.html:text/html},
}

@article{musk_integrated_2019,
	title = {An Integrated Brain-Machine Interface Platform With Thousands of Channels},
	volume = {21},
	url = {https://www.jmir.org/2019/10/e16194},
	doi = {10.2196/16194},
	abstract = {Brain-machine interfaces hold promise for the restoration of sensory and motor function and the treatment of neurological disorders, but clinical brain-machine interfaces have not yet been widely adopted, in part, because modest channel counts have limited their potential. In this white paper, we describe Neuralink’s first steps toward a scalable high-bandwidth brain-machine interface system. We have built arrays of small and flexible electrode “threads,” with as many as 3072 electrodes per array distributed across 96 threads. We have also built a neurosurgical robot capable of inserting six threads (192 electrodes) per minute. Each thread can be individually inserted into the brain with micron precision for avoidance of surface vasculature and targeting specific brain regions. The electrode array is packaged into a small implantable device that contains custom chips for low-power on-board amplification and digitization: The package for 3072 channels occupies less than 23×18.5×2 mm3. A single {USB}-C cable provides full-bandwidth data streaming from the device, recording from all channels simultaneously. This system has achieved a spiking yield of up to 70\% in chronically implanted electrodes. Neuralink’s approach to brain-machine interface has unprecedented packaging density and scalability in a clinically relevant package.},
	pages = {e16194},
	number = {10},
	journaltitle = {Journal of Medical Internet Research},
	author = {Musk, Elon and Neuralink},
	urldate = {2021-09-07},
	date = {2019-10-31},
	note = {Company: Journal of Medical Internet Research
Distributor: Journal of Medical Internet Research
Institution: Journal of Medical Internet Research
Label: Journal of Medical Internet Research
Publisher: {JMIR} Publications Inc., Toronto, Canada},
	file = {Full Text:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\ETV8MXJZ\\Musk and Neuralink - 2019 - An Integrated Brain-Machine Interface Platform Wit.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\T56M7IWA\\e16194.html:text/html},
}

@article{ray_neural_2008,
	title = {Neural Correlates of High-Gamma Oscillations (60–200 Hz) in Macaque Local Field Potentials and Their Potential Implications in Electrocorticography},
	volume = {28},
	rights = {Copyright © 2008 Society for Neuroscience 0270-6474/08/2811526-11\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/28/45/11526},
	doi = {10.1523/JNEUROSCI.2848-08.2008},
	abstract = {Recent studies using electrocorticographic ({ECoG}) recordings in humans have shown that functional activation of cortex is associated with an increase in power in the high-gamma frequency range (∼60–200 Hz). Here we investigate the neural correlates of this high-gamma activity in local field potential ({LFP}). Single units and {LFP} were recorded with microelectrodes from the hand region of macaque secondary somatosensory cortex while vibrotactile stimuli of varying intensities were presented to the hand. We found that high-gamma power in the {LFP} was strongly correlated with the average firing rate recorded by the microelectrodes, both temporally and on a trial-by-trial basis. In comparison, the correlation between firing rate and low-gamma power (40–80 Hz) was much smaller. To explore the potential effects of neuronal firing on {ECoG}, we developed a model to estimate {ECoG} power generated by different firing patterns of the underlying cortical population and studied how {ECoG} power varies with changes in firing rate versus the degree of synchronous firing between neurons in the population. Both an increase in firing rate and neuronal synchrony increased high-gamma power in the simulated {ECoG} data. However, {ECoG} high-gamma activity was much more sensitive to increases in neuronal synchrony than firing rate.},
	pages = {11526--11536},
	number = {45},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Ray, Supratim and Crone, Nathan E. and Niebur, Ernst and Franaszczuk, Piotr J. and Hsiao, Steven S.},
	urldate = {2021-09-07},
	date = {2008-11-05},
	langid = {english},
	pmid = {18987189},
	note = {Publisher: Society for Neuroscience
Section: Articles},
	keywords = {{ECoG}, gamma, high-gamma, local field potential, secondary somatosensory cortex, synchrony},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\HLB4SEN7\\Ray et al. - 2008 - Neural Correlates of High-Gamma Oscillations (60–2.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\RE4MSEE8\\11526.html:text/html},
}

@article{ray_effect_2008,
	title = {Effect of Stimulus Intensity on the Spike–Local Field Potential Relationship in the Secondary Somatosensory Cortex},
	volume = {28},
	rights = {Copyright © 2008 Society for Neuroscience 0270-6474/08/287334-10\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/28/29/7334},
	doi = {10.1523/JNEUROSCI.1588-08.2008},
	abstract = {Neuronal oscillations in the gamma frequency range have been reported in many cortical areas, but the role they play in cortical processing remains unclear. We tested a recently proposed hypothesis that the intensity of sensory input is coded in the timing of action potentials relative to the phase of gamma oscillations, thus converting amplitude information to a temporal code. We recorded spikes and local field potential ({LFP}) from secondary somatosensory ({SII}) cortex in awake monkeys while presenting a vibratory stimulus at different amplitudes. We developed a novel technique based on matching pursuit to study the interaction between the highly transient gamma oscillations and spikes with high time–frequency resolution. We found that spikes were weakly coupled to {LFP} oscillations in the gamma frequency range (40–80 Hz), and strongly coupled to oscillations in higher gamma frequencies. However, the phase relationship of neither low-gamma nor high-gamma oscillations changed with stimulus intensity, even with a 10-fold increase. We conclude that, in {SII}, gamma oscillations are synchronized with spikes, but their phase does not vary with stimulus intensity. Furthermore, high-gamma oscillations ({\textgreater}60 Hz) appear to be closely linked to the occurrence of action potentials, suggesting that {LFP} high-gamma power could be a sensitive index of the population firing rate near the microelectrode.},
	pages = {7334--7343},
	number = {29},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Ray, Supratim and Hsiao, Steven S. and Crone, Nathan E. and Franaszczuk, Piotr J. and Niebur, Ernst},
	urldate = {2021-09-07},
	date = {2008-07-16},
	langid = {english},
	pmid = {18632937},
	note = {Publisher: Society for Neuroscience
Section: Articles},
	keywords = {gamma, high-gamma, local field potential, secondary somatosensory cortex, matching pursuit, phase coding},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\7P2HWNPE\\Ray et al. - 2008 - Effect of Stimulus Intensity on the Spike–Local Fi.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\L4VQURWP\\7334.html:text/html},
}

@article{slutzky_optimal_2010,
	title = {Optimal spacing of surface electrode arrays for brain–machine interface applications},
	volume = {7},
	issn = {1741-2552},
	url = {https://doi.org/10.1088/1741-2560/7/2/026004},
	doi = {10.1088/1741-2560/7/2/026004},
	abstract = {Brain–machine interfaces ({BMIs}) use signals recorded directly from the brain to control an external device, such as a computer cursor or a prosthetic limb. These control signals have been recorded from different levels of the brain, from field potentials at the scalp or cortical surface to single neuron action potentials. At present, the more invasive recordings have better signal quality, but also lower stability over time. Recently, subdural field potentials have been proposed as a stable, good quality source of control signals, with the potential for higher spatial and temporal bandwidth than {EEG}. Here we used finite element modeling in rats and humans and spatial spectral analysis in rats to compare the spatial resolution of signals recorded epidurally (outside the dura), with those recorded from subdural and scalp locations. Resolution of epidural and subdural signals was very similar in rats and somewhat less so in human models. Both were substantially better than signals recorded at the scalp. Resolution of epidural and subdural signals in humans was much more similar when the cerebrospinal fluid layer thickness was reduced. This suggests that the less invasive epidural recordings may yield signals of similar quality to subdural recordings, and hence may be more attractive as a source of control signals for {BMIs}.},
	pages = {026004},
	number = {2},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Slutzky, Marc W. and Jordan, Luke R. and Krieg, Todd and Chen, Ming and Mogul, David J. and Miller, Lee E.},
	urldate = {2021-09-07},
	date = {2010-03},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\T8STKEI8\\Slutzky et al. - 2010 - Optimal spacing of surface electrode arrays for br.pdf:application/pdf},
}

@article{crone_cortical_2011,
	title = {Cortical gamma responses: Searching high and low},
	volume = {79},
	issn = {0167-8760},
	url = {https://www.sciencedirect.com/science/article/pii/S0167876010007385},
	doi = {10.1016/j.ijpsycho.2010.10.013},
	series = {Special Issue: Correlations between gamma-band oscillations and human behaviour},
	shorttitle = {Cortical gamma responses},
	abstract = {In this paper, a brief, preliminary attempt is made to frame a scientific debate about how functional responses at gamma frequencies in electrophysiological recordings ({EEG}, {MEG}, {ECoG}, and {LFP}) should be classified and interpreted. In general, are all gamma responses the same, or should they be divided into different classes according to criteria such as their spectral characteristics (frequency range and/or shape), their spatial–temporal patterns of occurrence, and/or their responsiveness under different task conditions? In particular, are the responses observed in intracranial {EEG} at a broad range of “high gamma” frequencies ({\textasciitilde}60–200Hz) different from gamma responses observed at lower frequencies ({\textasciitilde}30–80Hz), typically in narrower bands? And if they are different, how should they be interpreted? Does the broad spectral shape of high gamma responses arise from the summation of many different narrow-band oscillations, or does it reflect something completely different? If we are not sure, should we refer to high gamma activity as oscillations? A variety of theories have posited a mechanistic role for gamma activity in cortical function, often assuming narrow-band oscillations. These theories continue to influence the design of experiments and the interpretation of their results. Do these theories apply to all electrophysiological responses at gamma frequencies? Although no definitive answers to these questions are immediately anticipated, this paper will attempt to review the rationale for why they are worth asking and to point to some of the possible answers that have been proposed.},
	pages = {9--15},
	number = {1},
	journaltitle = {International Journal of Psychophysiology},
	shortjournal = {International Journal of Psychophysiology},
	author = {Crone, Nathan E. and Korzeniewska, Anna and Franaszczuk, Piotr J.},
	urldate = {2021-09-08},
	date = {2011-01-01},
	langid = {english},
	keywords = {{ERD}/{ERS}, Electrocorticography, Electroencephalography, Functional mapping, Gamma band, High gamma, Induced responses, Oscillations},
	file = {Accepted Version:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\7JSKWGRX\\Crone et al. - 2011 - Cortical gamma responses Searching high and low.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\Z4NS2TQ6\\S0167876010007385.html:text/html},
}

@article{bleichner_classification_2015,
	title = {Classification of mouth movements using 7 T {fMRI}},
	volume = {12},
	issn = {1741-2552},
	url = {https://doi.org/10.1088/1741-2560/12/6/066026},
	doi = {10.1088/1741-2560/12/6/066026},
	abstract = {Objective. A brain–computer interface ({BCI}) is an interface that uses signals from the brain to control a computer. {BCIs} will likely become important tools for severely paralyzed patients to restore interaction with the environment. The sensorimotor cortex is a promising target brain region for a {BCI} due to the detailed topography and minimal functional interference with other important brain processes. Previous studies have shown that attempted movements in paralyzed people generate neural activity that strongly resembles actual movements. Hence decodability for {BCI} applications can be studied in able-bodied volunteers with actual movements. Approach. In this study we tested whether mouth movements provide adequate signals in the sensorimotor cortex for a {BCI}. The study was executed using {fMRI} at 7 T to ensure relevance for {BCI} with cortical electrodes, as 7 T measurements have been shown to correlate well with electrocortical measurements. Twelve healthy volunteers executed four mouth movements (lip protrusion, tongue movement, teeth clenching, and the production of a larynx activating sound) while in the scanner. Subjects performed a training and a test run. Single trials were classified based on the Pearson correlation values between the activation patterns per trial type in the training run and single trials in the test run in a ‘winner-takes-all’ design. Main results. Single trial mouth movements could be classified with 90\% accuracy. The classification was based on an area with a volume of about 0.5 cc, located on the sensorimotor cortex. If voxels were limited to the surface, which is accessible for electrode grids, classification accuracy was still very high (82\%). Voxels located on the precentral cortex performed better (87\%) than the postcentral cortex (72\%). Significance. The high reliability of decoding mouth movements suggests that attempted mouth movements are a promising candidate for {BCI} in paralyzed people.},
	pages = {066026},
	number = {6},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Bleichner, M. G. and Jansma, J. M. and Salari, E. and Freudenburg, Z. V. and Raemaekers, M. and Ramsey, N. F.},
	urldate = {2021-09-08},
	date = {2015-11},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\7SXXB2MY\\Bleichner et al. - 2015 - Classification of mouth movements using 7 T fMRI.pdf:application/pdf},
}

@book{leon-carrion_brain_2006,
	title = {Brain Injury Treatment: Theories and Practices},
	isbn = {978-1-135-42072-7},
	shorttitle = {Brain Injury Treatment},
	abstract = {Brain Injury Treatment: Theories and Practices is a thorough and wide-ranging account of the rehabilitation of brain injury. Written from an international perspective, this book presents a detailed discussion of the basic science of brain injury. It explains the treatments used in brain injury rehabilitation and covers new methods of rehabilitation, including complementary medicine theories. It contains a wealth of information on different neurosurgical and neuropsychological treatments. It also includes a comprehensive reference to the theories underlying rehabilitation practices and chapters on community reentry and family dynamics following brain injury. It will be an invaluable tool to students from psychology, medicine, physical and occupational therapy studying the treatment and aftercare of people with brain injury.},
	pagetotal = {606},
	publisher = {Taylor \& Francis},
	author = {Leon-Carrion, Jose and Wild, Klaus R. H. von and Zitnay, George A.},
	date = {2006-09-27},
	langid = {english},
	note = {Google-Books-{ID}: {DV}16AgAAQBAJ},
	keywords = {Psychology / Clinical Psychology, Psychology / General, Psychology / Neuropsychology},
}

@book{chomsky_syntactic_2009,
	title = {Syntactic Structures},
	isbn = {978-3-11-021832-9},
	url = {https://www.degruyter.com/document/doi/10.1515/9783110218329/html},
	abstract = {Syntactic Structures by Noam Chomsky was published on September 24, 2009 by De Gruyter Mouton.},
	publisher = {De Gruyter Mouton},
	author = {Chomsky, Noam},
	urldate = {2021-10-21},
	date = {2009-09-24},
	langid = {english},
	doi = {10.1515/9783110218329},
	note = {Publication Title: Syntactic Structures},
}

@article{angrick_real-time_2021,
	title = {Real-time synthesis of imagined speech processes from minimally invasive recordings of neural activity},
	volume = {4},
	rights = {2021 The Author(s)},
	issn = {2399-3642},
	url = {https://www.nature.com/articles/s42003-021-02578-0},
	doi = {10.1038/s42003-021-02578-0},
	abstract = {Speech neuroprosthetics aim to provide a natural communication channel to individuals who are unable to speak due to physical or neurological impairments. Real-time synthesis of acoustic speech directly from measured neural activity could enable natural conversations and notably improve quality of life, particularly for individuals who have severely limited means of communication. Recent advances in decoding approaches have led to high quality reconstructions of acoustic speech from invasively measured neural activity. However, most prior research utilizes data collected during open-loop experiments of articulated speech, which might not directly translate to imagined speech processes. Here, we present an approach that synthesizes audible speech in real-time for both imagined and whispered speech conditions. Using a participant implanted with stereotactic depth electrodes, we were able to reliably generate audible speech in real-time. The decoding models rely predominately on frontal activity suggesting that speech processes have similar representations when vocalized, whispered, or imagined. While reconstructed audio is not yet intelligible, our real-time synthesis approach represents an essential step towards investigating how patients will learn to operate a closed-loop speech neuroprosthesis based on imagined speech.},
	pages = {1--10},
	number = {1},
	journaltitle = {Communications Biology},
	shortjournal = {Commun Biol},
	author = {Angrick, Miguel and Ottenhoff, Maarten C. and Diener, Lorenz and Ivucic, Darius and Ivucic, Gabriel and Goulis, Sophocles and Saal, Jeremy and Colon, Albert J. and Wagner, Louis and Krusienski, Dean J. and Kubben, Pieter L. and Schultz, Tanja and Herff, Christian},
	urldate = {2021-12-16},
	date = {2021-09-23},
	langid = {english},
	note = {Bandiera\_abtest: a
Cc\_license\_type: cc\_by
Cg\_type: Nature Research Journals
Number: 1
Primary\_atype: Research
Publisher: Nature Publishing Group
Subject\_term: Brain–machine interface;Neural decoding
Subject\_term\_id: brain-machine-interface;neural-decoding},
	keywords = {Neural decoding, Brain–machine interface},
	file = {Full Text:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\Q95S7QBH\\Angrick et al. - 2020 - Real-time Synthesis of Imagined Speech Processes f.pdf:application/pdf;Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\BZGUKJI2\\Angrick et al. - 2021 - Real-time synthesis of imagined speech processes f.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\67QMBFGQ\\2020.12.11.421149v1.html:text/html;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\P35EB5WY\\s42003-021-02578-0.html:text/html},
}

@inproceedings{sutskever_sequence_2014,
	title = {Sequence to Sequence Learning with Neural Networks},
	volume = {27},
	url = {https://proceedings.neurips.cc/paper/2014/hash/a14ac55a4f27472c5d894ec1c3c743d2-Abstract.html},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
	urldate = {2021-12-16},
	date = {2014},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\M6TGKH2T\\Sutskever et al. - 2014 - Sequence to Sequence Learning with Neural Networks.pdf:application/pdf},
}

@inproceedings{kalchbrenner_efficient_2018,
	title = {Efficient Neural Audio Synthesis},
	url = {https://proceedings.mlr.press/v80/kalchbrenner18a.html},
	abstract = {Sequential models achieve state-of-the-art results in audio, visual and textual domains with respect to both estimating the data distribution and generating desired samples. Efficient sampling for this class of models at the cost of little to no loss in quality has however remained an elusive problem. With a focus on text-to-speech synthesis, we describe a set of general techniques for reducing sampling time while maintaining high output quality. We first describe a single-layer recurrent neural network, the {WaveRNN}, with a dual softmax layer that matches the quality of the state-of-the-art {WaveNet} model. The compact form of the network makes it possible to generate 24 {kHz} 16-bit audio 4 times faster than real time on a {GPU}. Secondly, we apply a weight pruning technique to reduce the number of weights in the {WaveRNN}. We find that, for a constant number of parameters, large sparse networks perform better than small dense networks and this relationship holds past sparsity levels of more than 96\%. The small number of weights in a Sparse {WaveRNN} makes it possible to sample high-fidelity audio on a mobile phone {CPU} in real time. Finally, we describe a new dependency scheme for sampling that lets us trade a constant number of non-local, distant dependencies for the ability to generate samples in batches. The Batch {WaveRNN} produces 8 samples per step without loss of quality and offers orthogonal ways of further increasing sampling efficiency.},
	eventtitle = {International Conference on Machine Learning},
	pages = {2410--2419},
	booktitle = {Proceedings of the 35th International Conference on Machine Learning},
	publisher = {{PMLR}},
	author = {Kalchbrenner, Nal and Elsen, Erich and Simonyan, Karen and Noury, Seb and Casagrande, Norman and Lockhart, Edward and Stimberg, Florian and Oord, Aaron and Dieleman, Sander and Kavukcuoglu, Koray},
	urldate = {2021-12-16},
	date = {2018-07-03},
	langid = {english},
	note = {{ISSN}: 2640-3498},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\RZS7B9K2\\Kalchbrenner et al. - 2018 - Efficient Neural Audio Synthesis.pdf:application/pdf},
}

@inproceedings{prenger_waveglow_2019,
	title = {Waveglow: A Flow-based Generative Network for Speech Synthesis},
	doi = {10.1109/ICASSP.2019.8683143},
	shorttitle = {Waveglow},
	abstract = {In this paper we propose {WaveGlow}: a flow-based network capable of generating high quality speech from mel-spectrograms. {WaveGlow} combines insights from Glow [1] and {WaveNet} [2] in order to provide fast, efficient and high-quality audio synthesis, without the need for auto-regression. {WaveGlow} is implemented using only a single network, trained using only a single cost function: maximizing the likelihood of the training data, which makes the training procedure simple and stable. Our {PyTorch} implementation produces audio samples at a rate of more than 500 {kHz} on an {NVIDIA} V100 {GPU}. Mean Opinion Scores show that it delivers audio quality as good as the best publicly available {WaveNet} implementation. All code will be made publicly available online [3].},
	eventtitle = {{ICASSP} 2019 - 2019 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	pages = {3617--3621},
	booktitle = {{ICASSP} 2019 - 2019 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	author = {Prenger, Ryan and Valle, Rafael and Catanzaro, Bryan},
	date = {2019-05},
	note = {{ISSN}: 2379-190X},
	keywords = {Audio Synthesis, Deep Learning, Generative models, Text-to-speech},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\33VSMVFZ\\8683143.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\BS5HKCJB\\Prenger et al. - 2019 - Waveglow A Flow-based Generative Network for Spee.pdf:application/pdf},
}

@inproceedings{huang_densely_2017,
	title = {Densely Connected Convolutional Networks},
	doi = {10.1109/CVPR.2017.243},
	abstract = {Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network ({DenseNet}), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections-one between each layer and its subsequent layer-our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. {DenseNets} have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks ({CIFAR}-10, {CIFAR}-100, {SVHN}, and {ImageNet}). {DenseNets} obtain significant improvements over the state-of-the-art on most of them, whilst requiring less memory and computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/{DenseNet}.},
	eventtitle = {2017 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	pages = {2261--2269},
	booktitle = {2017 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	author = {Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q.},
	date = {2017-07},
	note = {{ISSN}: 1063-6919},
	keywords = {Neural networks, Convolution, Convolutional codes, Network architecture, Road transportation, Training},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\9I8ECCXS\\Huang et al. - 2017 - Densely Connected Convolutional Networks.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\UYRFS8L3\\8099726.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\2PZ3Q5XC\\Huang et al. - 2017 - Densely Connected Convolutional Networks.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\6VLYE8P7\\Huang_Densely_Connected_Convolutional_CVPR_2017_paper.html:text/html},
}

@inproceedings{gaddy_digital_2020,
	location = {Online},
	title = {Digital Voicing of Silent Speech},
	url = {https://aclanthology.org/2020.emnlp-main.445},
	doi = {10.18653/v1/2020.emnlp-main.445},
	abstract = {In this paper, we consider the task of digitally voicing silent speech, where silently mouthed words are converted to audible speech based on electromyography ({EMG}) sensor measurements that capture muscle impulses. While prior work has focused on training speech synthesis models from {EMG} collected during vocalized speech, we are the first to train from {EMG} collected during silently articulated speech. We introduce a method of training on silent {EMG} by transferring audio targets from vocalized to silent signals. Our method greatly improves intelligibility of audio generated from silent {EMG} compared to a baseline that only trains with vocalized data, decreasing transcription word error rate from 64\% to 4\% in one data condition and 88\% to 68\% in another. To spur further development on this task, we share our new dataset of silent and vocalized facial {EMG} measurements.},
	eventtitle = {{EMNLP} 2020},
	pages = {5521--5530},
	booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Gaddy, David and Klein, Dan},
	urldate = {2022-01-03},
	date = {2020-11},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\ADF7BX73\\Gaddy and Klein - 2020 - Digital Voicing of Silent Speech.pdf:application/pdf},
}

@article{pels_stability_2019,
	title = {Stability of a chronic implanted brain-computer interface in late-stage amyotrophic lateral sclerosis},
	volume = {130},
	issn = {1388-2457},
	url = {https://www.sciencedirect.com/science/article/pii/S1388245719311678},
	doi = {10.1016/j.clinph.2019.07.020},
	abstract = {Objective
We investigated the long-term functional stability and home use of a fully implanted electrocorticography ({ECoG})-based brain-computer interface ({BCI}) for communication by an individual with late-stage Amyotrophic Lateral Sclerosis ({ALS}).
Methods
Data recorded from the cortical surface of the motor and prefrontal cortex with an implanted brain-computer interface device was evaluated for 36 months after implantation of the system in an individual with late-stage {ALS}. In addition, electrode impedance and {BCI} control accuracy were assessed. Key measures included frequency of use of the system for communication, user and system performance, and electrical signal characteristics.
Results
User performance was high consistently over the three years. Power in the high frequency band, used for the control signal, declined slowly in the motor cortex, but control over the signal remained unaffected by time. Impedance increased until month 5, and then remained constant. Frequency of home use increased steadily, indicating adoption of the system by the user.
Conclusions
The implanted brain-computer interface proves to be robust in an individual with late-stage {ALS}, given stable performance and control signal for over 36 months.
Significance
These findings are relevant for the future of implantable brain-computer interfaces along with other brain-sensing technologies, such as responsive neurostimulation.},
	pages = {1798--1803},
	number = {10},
	journaltitle = {Clinical Neurophysiology},
	shortjournal = {Clinical Neurophysiology},
	author = {Pels, Elmar G. M. and Aarnoutse, Erik J. and Leinders, Sacha and Freudenburg, Zac V. and Branco, Mariana P. and van der Vijgh, Benny H. and Snijders, Tom J. and Denison, Timothy and Vansteensel, Mariska J. and Ramsey, Nick F.},
	urldate = {2022-01-03},
	date = {2019-10-01},
	langid = {english},
	keywords = {Brain-computer interface, Electrocorticography, Amyotrophic lateral sclerosis, Communication, Implant, Stability},
	file = {Full Text:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\GG4TNM4E\\Pels et al. - 2019 - Stability of a chronic implanted brain-computer in.pdf:application/pdf},
}

@article{kohler_synthesizing_2021,
	title = {Synthesizing Speech from Intracranial Depth Electrodes using an Encoder-Decoder Framework},
	url = {http://arxiv.org/abs/2111.01457},
	abstract = {Speech Neuroprostheses have the potential to enable communication for people with dysarthria or anarthria. Recent advances have demonstrated high-quality text decoding and speech synthesis from electrocorticographic grids placed on the cortical surface. Here, we investigate a less invasive measurement modality, namely stereotactic {EEG} ({sEEG}) that provides sparse sampling from multiple brain regions, including subcortical regions. To evaluate whether {sEEG} can also be used to synthesize high-quality audio from neural recordings, we employ a recurrent encoder-decoder framework based on modern deep learning methods. We demonstrate that high-quality speech can be reconstructed from these minimally invasive recordings, despite a limited amount of training data. Finally, we utilize variational feature dropout to successfully identify the most informative electrode contacts.},
	journaltitle = {{arXiv}:2111.01457 [cs]},
	author = {Kohler, Jonas and Ottenhoff, Maarten C. and Goulis, Sophocles and Angrick, Miguel and Colon, Albert J. and Wagner, Louis and Tousseyn, Simon and Kubben, Pieter L. and Herff, Christian},
	urldate = {2022-01-03},
	date = {2021-11-02},
	eprinttype = {arxiv},
	eprint = {2111.01457},
	keywords = {Computer Science - Sound, Computer Science - Machine Learning, Computer Science - Human-Computer Interaction},
	file = {arXiv Fulltext PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\L77CS7AD\\Kohler et al. - 2021 - Synthesizing Speech from Intracranial Depth Electr.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\THF6ZKXX\\2111.html:text/html},
}

@article{stavisky_neural_2019,
	title = {Neural ensemble dynamics in dorsal motor cortex during speech in people with paralysis},
	volume = {8},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.46015},
	doi = {10.7554/eLife.46015},
	abstract = {Speaking is a sensorimotor behavior whose neural basis is difficult to study with single neuron resolution due to the scarcity of human intracortical measurements. We used electrode arrays to record from the motor cortex ‘hand knob’ in two people with tetraplegia, an area not previously implicated in speech. Neurons modulated during speaking and during non-speaking movements of the tongue, lips, and jaw. This challenges whether the conventional model of a ‘motor homunculus’ division by major body regions extends to the single-neuron scale. Spoken words and syllables could be decoded from single trials, demonstrating the potential of intracortical recordings for brain-computer interfaces to restore speech. Two neural population dynamics features previously reported for arm movements were also present during speaking: a component that was mostly invariant across initiating different words, followed by rotatory dynamics during speaking. This suggests that common neural dynamical motifs may underlie movement of arm and speech articulators.},
	pages = {e46015},
	journaltitle = {{eLife}},
	author = {Stavisky, Sergey D and Willett, Francis R and Wilson, Guy H and Murphy, Brian A and Rezaii, Paymon and Avansino, Donald T and Memberg, William D and Miller, Jonathan P and Kirsch, Robert F and Hochberg, Leigh R and Ajiboye, A Bolu and Druckmann, Shaul and Shenoy, Krishna V and Henderson, Jaimie M},
	editor = {Makin, Tamar R and Shinn-Cunningham, Barbara G and Makin, Tamar R and Gallego, Juan Álvaro and Scott, Sophie K},
	urldate = {2022-01-03},
	date = {2019-12-10},
	note = {Publisher: {eLife} Sciences Publications, Ltd},
	keywords = {brain-computer interface, intracortical, motor control, motor cortex, neural dynamics, speech},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\RY7NCSGJ\\Stavisky et al. - 2019 - Neural ensemble dynamics in dorsal motor cortex du.pdf:application/pdf},
}

@article{wilson_decoding_2020,
	title = {Decoding spoken English from intracortical electrode arrays in dorsal precentral gyrus},
	volume = {17},
	issn = {1741-2552},
	url = {https://doi.org/10.1088/1741-2552/abbfef},
	doi = {10.1088/1741-2552/abbfef},
	abstract = {Objective. To evaluate the potential of intracortical electrode array signals for brain-computer interfaces ({BCIs}) to restore lost speech, we measured the performance of decoders trained to discriminate a comprehensive basis set of 39 English phonemes and to synthesize speech sounds via a neural pattern matching method. We decoded neural correlates of spoken-out-loud words in the ‘hand knob’ area of precentral gyrus, a step toward the eventual goal of decoding attempted speech from ventral speech areas in patients who are unable to speak. Approach. Neural and audio data were recorded while two {BrainGate}2 pilot clinical trial participants, each with two chronically-implanted 96-electrode arrays, spoke 420 different words that broadly sampled English phonemes. Phoneme onsets were identified from audio recordings, and their identities were then classified from neural features consisting of each electrode’s binned action potential counts or high-frequency local field potential power. Speech synthesis was performed using the ‘Brain-to-Speech’ pattern matching method. We also examined two potential confounds specific to decoding overt speech: acoustic contamination of neural signals and systematic differences in labeling different phonemes’ onset times. Main results. A linear decoder achieved up to 29.3\% classification accuracy (chance = 6\%) across 39 phonemes, while an {RNN} classifier achieved 33.9\% accuracy. Parameter sweeps indicated that performance did not saturate when adding more electrodes or more training data, and that accuracy improved when utilizing time-varying structure in the data. Microphonic contamination and phoneme onset differences modestly increased decoding accuracy, but could be mitigated by acoustic artifact subtraction and using a neural speech onset marker, respectively. Speech synthesis achieved r = 0.523 correlation between true and reconstructed audio. Significance. The ability to decode speech using intracortical electrode array signals from a nontraditional speech area suggests that placing electrode arrays in ventral speech areas is a promising direction for speech {BCIs}.},
	pages = {066007},
	number = {6},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Wilson, Guy H. and Stavisky, Sergey D. and Willett, Francis R. and Avansino, Donald T. and Kelemen, Jessica N. and Hochberg, Leigh R. and Henderson, Jaimie M. and Druckmann, Shaul and Shenoy, Krishna V.},
	urldate = {2022-01-03},
	date = {2020-11},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\7CJXDSTV\\Wilson et al. - 2020 - Decoding spoken English from intracortical electro.pdf:application/pdf},
}

@article{herff_potential_2020,
	title = {The Potential of Stereotactic-{EEG} for Brain-Computer Interfaces: Current Progress and Future Directions},
	volume = {14},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/article/10.3389/fnins.2020.00123},
	doi = {10.3389/fnins.2020.00123},
	shorttitle = {The Potential of Stereotactic-{EEG} for Brain-Computer Interfaces},
	abstract = {Stereotactic electroencephalogaphy ({sEEG}) utilizes localized, penetrating depth electrodes to measure electrophysiological brain activity. It is most commonly used in the identification of epileptogenic zones in cases of refractory epilepsy. The implanted electrodes generally provide a sparse sampling of a unique set of brain regions including deeper brain structures such as hippocampus, amygdala and insula that cannot be captured by superficial measurement modalities such as electrocorticography ({ECoG}). Despite the overlapping clinical application and recent progress in decoding of {ECoG} for Brain-Computer Interfaces ({BCIs}), {sEEG} has thus far received comparatively little attention for {BCI} decoding. Additionally, the success of the related deep-brain stimulation ({DBS}) implants bodes well for the potential for chronic {sEEG} applications. This article provides an overview of {sEEG} technology, {BCI}-related research, and prospective future directions of {sEEG} for long-term {BCI} applications.},
	pages = {123},
	journaltitle = {Frontiers in Neuroscience},
	author = {Herff, Christian and Krusienski, Dean J. and Kubben, Pieter},
	urldate = {2022-01-04},
	date = {2020},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\QP7JJJFV\\Herff et al. - 2020 - The Potential of Stereotactic-EEG for Brain-Comput.pdf:application/pdf},
}

@article{luo_brain-computer_2022,
	title = {Brain-Computer Interface: Applications to Speech Decoding and Synthesis to Augment Communication},
	rights = {All rights reserved},
	issn = {1878-7479},
	url = {https://doi.org/10.1007/s13311-022-01190-2},
	doi = {10.1007/s13311-022-01190-2},
	shorttitle = {Brain-Computer Interface},
	abstract = {Damage or degeneration of motor pathways necessary for speech and other movements, as in brainstem strokes or amyotrophic lateral sclerosis ({ALS}), can interfere with efficient communication without affecting brain structures responsible for language or cognition. In the worst-case scenario, this can result in the locked in syndrome ({LIS}), a condition in which individuals cannot initiate communication and can only express themselves by answering yes/no questions with eye blinks or other rudimentary movements. Existing augmentative and alternative communication ({AAC}) devices that rely on eye tracking can improve the quality of life for people with this condition, but brain-computer interfaces ({BCIs}) are also increasingly being investigated as {AAC} devices, particularly when eye tracking is too slow or unreliable. Moreover, with recent and ongoing advances in machine learning and neural recording technologies, {BCIs} may offer the only means to go beyond cursor control and text generation on a computer, to allow real-time synthesis of speech, which would arguably offer the most efficient and expressive channel for communication. The potential for {BCI} speech synthesis has only recently been realized because of seminal studies of the neuroanatomical and neurophysiological underpinnings of speech production using intracranial electrocorticographic ({ECoG}) recordings in patients undergoing epilepsy surgery. These studies have shown that cortical areas responsible for vocalization and articulation are distributed over a large area of ventral sensorimotor cortex, and that it is possible to decode speech and reconstruct its acoustics from {ECoG} if these areas are recorded with sufficiently dense and comprehensive electrode arrays. In this article, we review these advances, including the latest neural decoding strategies that range from deep learning models to the direct concatenation of speech units. We also discuss state-of-the-art vocoders that are integral in constructing natural-sounding audio waveforms for speech {BCIs}. Finally, this review outlines some of the challenges ahead in directly synthesizing speech for patients with {LIS}.},
	journaltitle = {Neurotherapeutics},
	shortjournal = {Neurotherapeutics},
	author = {Luo, Shiyu and Rabbani, Qinwan and Crone, Nathan E.},
	urldate = {2022-02-14},
	date = {2022-01-31},
	langid = {english},
	file = {Springer Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\KFNQNNJC\\Luo et al. - 2022 - Brain-Computer Interface Applications to Speech D.pdf:application/pdf},
}

@article{heydari_softadapt_2019,
	title = {{SoftAdapt}: Techniques for Adaptive Loss Weighting of Neural Networks with Multi-Part Loss Functions},
	url = {http://arxiv.org/abs/1912.12355},
	shorttitle = {{SoftAdapt}},
	abstract = {Adaptive loss function formulation is an active area of research and has gained a great deal of popularity in recent years, following the success of deep learning. However, existing frameworks of adaptive loss functions often suffer from slow convergence and poor choice of weights for the loss components. Traditionally, the elements of a multipart loss function are weighted equally or their weights are determined through heuristic approaches that yield nearoptimal (or sub-optimal) results. To address this problem, we propose a family of methods, called {SoftAdapt}, that dynamically change function weights for multi-part loss functions based on live performance statistics of the component losses. {SoftAdapt} is mathematically intuitive, computationally efﬁcient and straightforward to implement. In this paper, we present the mathematical formulation and pseudocode for {SoftAdapt}, along with results from applying our methods to image reconstruction (Sparse Autoencoders) and synthetic data generation (Introspective Variational Autoencoders).},
	journaltitle = {{arXiv}:1912.12355 [cs, math, stat]},
	author = {Heydari, A. Ali and Thompson, Craig A. and Mehmood, Asif},
	urldate = {2022-02-22},
	date = {2019-12-27},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1912.12355},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Optimization and Control},
	file = {Heydari et al. - 2019 - SoftAdapt Techniques for Adaptive Loss Weighting .pdf:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\JIQMXFTK\\Heydari et al. - 2019 - SoftAdapt Techniques for Adaptive Loss Weighting .pdf:application/pdf},
}

@article{brunton_pathophysiology_2016,
	title = {Pathophysiology of Type 2 Diabetes: The Evolution of Our Understanding},
	volume = {65},
	issn = {1533-7294},
	shorttitle = {Pathophysiology of Type 2 Diabetes},
	abstract = {This review article explores scientists' current understanding of type 2 diabetes as a complex disorder that involves not just the pancreas and insulin system but also the liver, kidneys, gut, muscle, fat cells, and even the brain. An appreciation of the complex pathophysiology of type 2 diabetes allows the primary care practitioner to best manage patients with this common and serious disorder.},
	pages = {supp\_az\_0416},
	number = {4},
	journaltitle = {The Journal of Family Practice},
	shortjournal = {J Fam Pract},
	author = {Brunton, Stephen},
	date = {2016-04},
	pmid = {27262256},
	keywords = {Humans, Diabetes Mellitus, Type 2, Disease Management, Hypoglycemic Agents},
}

@article{fawaz_inceptiontime_2020,
	title = {{InceptionTime}: Finding {AlexNet} for Time Series Classification},
	volume = {34},
	issn = {1384-5810, 1573-756X},
	url = {http://arxiv.org/abs/1909.04939},
	doi = {10.1007/s10618-020-00710-y},
	shorttitle = {{InceptionTime}},
	abstract = {This paper brings deep learning at the forefront of research into Time Series Classification ({TSC}). {TSC} is the area of machine learning tasked with the categorization (or labelling) of time series. The last few decades of work in this area have led to significant progress in the accuracy of classifiers, with the state of the art now represented by the {HIVE}-{COTE} algorithm. While extremely accurate, {HIVE}-{COTE} cannot be applied to many real-world datasets because of its high training time complexity in O(N2 * T4) for a dataset with N time series of length T. For example, it takes {HIVE}-{COTE} more than 8 days to learn from a small dataset with N = 1500 time series of short length T = 46. Meanwhile deep learning has received enormous attention because of its high accuracy and scalability. Recent approaches to deep learning for {TSC} have been scalable, but less accurate than {HIVE}-{COTE}. We introduce {InceptionTime} - an ensemble of deep Convolutional Neural Network ({CNN}) models, inspired by the Inception-v4 architecture. Our experiments show that {InceptionTime} is on par with {HIVE}-{COTE} in terms of accuracy while being much more scalable: not only can it learn from 1,500 time series in one hour but it can also learn from 8M time series in 13 hours, a quantity of data that is fully out of reach of {HIVE}-{COTE}.},
	pages = {1936--1962},
	number = {6},
	journaltitle = {Data Mining and Knowledge Discovery},
	shortjournal = {Data Min Knowl Disc},
	author = {Fawaz, Hassan Ismail and Lucas, Benjamin and Forestier, Germain and Pelletier, Charlotte and Schmidt, Daniel F. and Weber, Jonathan and Webb, Geoffrey I. and Idoumghar, Lhassane and Muller, Pierre-Alain and Petitjean, François},
	urldate = {2023-03-10},
	date = {2020-11},
	eprinttype = {arxiv},
	eprint = {1909.04939 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\XUKE49IH\\Fawaz et al. - 2020 - InceptionTime Finding AlexNet for Time Series Cla.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\9ELE63MH\\1909.html:text/html},
}

@article{metzger_generalizable_2022,
	title = {Generalizable spelling using a speech neuroprosthesis in an individual with severe limb and vocal paralysis},
	volume = {13},
	rights = {2022 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-022-33611-3},
	doi = {10.1038/s41467-022-33611-3},
	abstract = {Neuroprostheses have the potential to restore communication to people who cannot speak or type due to paralysis. However, it is unclear if silent attempts to speak can be used to control a communication neuroprosthesis. Here, we translated direct cortical signals in a clinical-trial participant ({ClinicalTrials}.gov; {NCT}03698149) with severe limb and vocal-tract paralysis into single letters to spell out full sentences in real time. We used deep-learning and language-modeling techniques to decode letter sequences as the participant attempted to silently spell using code words that represented the 26 English letters (e.g. “alpha” for “a”). We leveraged broad electrode coverage beyond speech-motor cortex to include supplemental control signals from hand cortex and complementary information from low- and high-frequency signal components to improve decoding accuracy. We decoded sentences using words from a 1,152-word vocabulary at a median character error rate of 6.13\% and speed of 29.4 characters per minute. In offline simulations, we showed that our approach generalized to large vocabularies containing over 9,000 words (median character error rate of 8.23\%). These results illustrate the clinical viability of a silently controlled speech neuroprosthesis to generate sentences from a large vocabulary through a spelling-based approach, complementing previous demonstrations of direct full-word decoding.},
	pages = {6510},
	number = {1},
	journaltitle = {Nature Communications},
	shortjournal = {Nat Commun},
	author = {Metzger, Sean L. and Liu, Jessie R. and Moses, David A. and Dougherty, Maximilian E. and Seaton, Margaret P. and Littlejohn, Kaylo T. and Chartier, Josh and Anumanchipalli, Gopala K. and Tu-Chan, Adelyn and Ganguly, Karunesh and Chang, Edward F.},
	urldate = {2023-03-13},
	date = {2022-11-08},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Stroke, Neural decoding, Brain–machine interface, Biomedical engineering, Translational research},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\LDRNCID2\\Metzger et al. - 2022 - Generalizable spelling using a speech neuroprosthe.pdf:application/pdf},
}

@article{shen_translational_2023,
	title = {Translational opportunities and challenges of invasive electrodes for neural interfaces},
	rights = {2023 Springer Nature Limited},
	issn = {2157-846X},
	url = {https://www.nature.com/articles/s41551-023-01021-5},
	doi = {10.1038/s41551-023-01021-5},
	abstract = {Invasive brain–machine interfaces can restore motor, sensory and cognitive functions. However, their clinical adoption has been hindered by the surgical risk of implantation and by suboptimal long-term reliability. In this Review, we highlight the opportunities and challenges of invasive technology for clinically relevant electrophysiology. Specifically, we discuss the characteristics of neural probes that are most likely to facilitate the clinical translation of invasive neural interfaces, describe the neural signals that can be acquired or produced by intracranial electrodes, the abiotic and biotic factors that contribute to their failure, and emerging neural-interface architectures.},
	pages = {1--19},
	journaltitle = {Nature Biomedical Engineering},
	shortjournal = {Nat. Biomed. Eng},
	author = {Shen, Konlin and Chen, Oliver and Edmunds, Jordan L. and Piech, David K. and Maharbiz, Michel M.},
	urldate = {2023-04-24},
	date = {2023-04-20},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Biomedical engineering, Translational research, Electrical and electronic engineering},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\RE2NIWVG\\Shen et al. - 2023 - Translational opportunities and challenges of inva.pdf:application/pdf},
}

@article{simonyan_deep_2014,
	title = {Deep inside convolutional networks: visualising image classification models and saliency maps},
	url = {https://ora.ox.ac.uk/objects/uuid:ea777387-538b-4a01-843b-41b2f05dd287},
	shorttitle = {Deep inside convolutional networks},
	abstract = {This paper addresses the visualisation of image classification models, learnt using deep Convolutional Networks ({ConvNets}). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The first one generates an image, which maximises the class score [5], thus visualising the notion of the class, captured by a {ConvNet}. The second technique computes a class saliency map, specific to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classification {ConvNets}. Finally, we establish the connection between the gradient-based {ConvNet} visualisation methods and deconvolutional networks [13].},
	journaltitle = {Proceedings of the International Conference on Learning Representations ({ICLR})},
	author = {Simonyan, K. and Vedaldi, A. and Zisserman, A.},
	urldate = {2023-05-01},
	date = {2014},
	langid = {english},
	note = {Publisher: {ICLR}},
	file = {Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\5I2TBE9J\\uuidea777387-538b-4a01-843b-41b2f05dd287.html:text/html},
}

@article{sussillo_making_2016,
	title = {Making brain–machine interfaces robust to future neural variability},
	volume = {7},
	rights = {2016 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/ncomms13749},
	doi = {10.1038/ncomms13749},
	abstract = {A major hurdle to clinical translation of brain–machine interfaces ({BMIs}) is that current decoders, which are trained from a small quantity of recent data, become ineffective when neural recording conditions subsequently change. We tested whether a decoder could be made more robust to future neural variability by training it to handle a variety of recording conditions sampled from months of previously collected data as well as synthetic training data perturbations. We developed a new multiplicative recurrent neural network {BMI} decoder that successfully learned a large variety of neural-to-kinematic mappings and became more robust with larger training data sets. Here we demonstrate that when tested with a non-human primate preclinical {BMI} model, this decoder is robust under conditions that disabled a state-of-the-art Kalman filter-based decoder. These results validate a new {BMI} strategy in which accumulated data history are effectively harnessed, and may facilitate reliable {BMI} use by reducing decoder retraining downtime.},
	pages = {13749},
	number = {1},
	journaltitle = {Nature Communications},
	shortjournal = {Nat Commun},
	author = {Sussillo, David and Stavisky, Sergey D. and Kao, Jonathan C. and Ryu, Stephen I. and Shenoy, Krishna V.},
	urldate = {2023-04-30},
	date = {2016-12-13},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Brain–machine interface, Biotechnology},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\28SH7LJW\\Sussillo et al. - 2016 - Making brain–machine interfaces robust to future n.pdf:application/pdf},
}

@article{jensen_long-term_2022,
	title = {Long-term stability of single neuron activity in the motor system},
	volume = {25},
	rights = {2022 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-022-01194-3},
	doi = {10.1038/s41593-022-01194-3},
	abstract = {How an established behavior is retained and consistently produced by a nervous system in constant flux remains a mystery. One possible solution to ensure long-term stability in motor output is to fix the activity patterns of single neurons in the relevant circuits. Alternatively, activity in single cells could drift over time provided that the population dynamics are constrained to produce the same behavior. To arbitrate between these possibilities, we recorded single-unit activity in motor cortex and striatum continuously for several weeks as rats performed stereotyped motor behaviors—both learned and innate. We found long-term stability in single neuron activity patterns across both brain regions. A small amount of drift in neural activity, observed over weeks of recording, could be explained by concomitant changes in task-irrelevant aspects of the behavior. These results suggest that long-term stable behaviors are generated by single neuron activity patterns that are themselves highly stable.},
	pages = {1664--1674},
	number = {12},
	journaltitle = {Nature Neuroscience},
	shortjournal = {Nat Neurosci},
	author = {Jensen, Kristopher T. and Kadmon Harpaz, Naama and Dhawale, Ashesh K. and Wolff, Steffen B. E. and Ölveczky, Bence P.},
	urldate = {2023-04-30},
	date = {2022-12},
	langid = {english},
	note = {Number: 12
Publisher: Nature Publishing Group},
	keywords = {Basal ganglia, Network models},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\YFEML5ZK\\Jensen et al. - 2022 - Long-term stability of single neuron activity in t.pdf:application/pdf},
}

@article{hong_novel_2019,
	title = {Novel electrode technologies for neural recordings},
	volume = {20},
	rights = {2019 Springer Nature Limited},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/s41583-019-0140-6},
	doi = {10.1038/s41583-019-0140-6},
	abstract = {Neural recording electrode technologies have contributed considerably to neuroscience by enabling the extracellular detection of low-frequency local field potential oscillations and high-frequency action potentials of single units. Nevertheless, several long-standing limitations exist, including low multiplexity, deleterious chronic immune responses and long-term recording instability. Driven by initiatives encouraging the generation of novel neurotechnologies and the maturation of technologies to fabricate high-density electronics, novel electrode technologies are emerging. Here, we provide an overview of recently developed neural recording electrode technologies with high spatial integration, long-term stability and multiple functionalities. We describe how these emergent neurotechnologies can approach the ultimate goal of illuminating chronic brain activity with minimal disruption of the neural environment, thereby providing unprecedented opportunities for neuroscience research in the future.},
	pages = {330--345},
	number = {6},
	journaltitle = {Nature Reviews Neuroscience},
	shortjournal = {Nat Rev Neurosci},
	author = {Hong, Guosong and Lieber, Charles M.},
	urldate = {2023-04-30},
	date = {2019-06},
	langid = {english},
	note = {Number: 6
Publisher: Nature Publishing Group},
	keywords = {Extracellular recording, Nanobiotechnology, Tetrode recording},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\UISXU7SJ\\Hong and Lieber - 2019 - Novel electrode technologies for neural recordings.pdf:application/pdf},
}

@article{gallego_long-term_2020,
	title = {Long-term stability of cortical population dynamics underlying consistent behavior},
	volume = {23},
	rights = {2020 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-019-0555-4},
	doi = {10.1038/s41593-019-0555-4},
	abstract = {Animals readily execute learned behaviors in a consistent manner over long periods of time, and yet no equally stable neural correlate has been demonstrated. How does the cortex achieve this stable control? Using the sensorimotor system as a model of cortical processing, we investigated the hypothesis that the dynamics of neural latent activity, which captures the dominant co-variation patterns within the neural population, must be preserved across time. We recorded from populations of neurons in premotor, primary motor and somatosensory cortices as monkeys performed a reaching task, for up to 2 years. Intriguingly, despite a steady turnover in the recorded neurons, the low-dimensional latent dynamics remained stable. The stability allowed reliable decoding of behavioral features for the entire timespan, while fixed decoders based directly on the recorded neural activity degraded substantially. We posit that stable latent cortical dynamics within the manifold are the fundamental building blocks underlying consistent behavioral execution.},
	pages = {260--270},
	number = {2},
	journaltitle = {Nature Neuroscience},
	shortjournal = {Nat Neurosci},
	author = {Gallego, Juan A. and Perich, Matthew G. and Chowdhury, Raeed H. and Solla, Sara A. and Miller, Lee E.},
	urldate = {2023-04-30},
	date = {2020-02},
	langid = {english},
	note = {Number: 2
Publisher: Nature Publishing Group},
	keywords = {Computational neuroscience, Neuroscience},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\HSKLM2FH\\Gallego et al. - 2020 - Long-term stability of cortical population dynamic.pdf:application/pdf},
}

@article{buzsaki_origin_2012,
	title = {The origin of extracellular fields and currents — {EEG}, {ECoG}, {LFP} and spikes},
	volume = {13},
	rights = {2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/nrn3241},
	doi = {10.1038/nrn3241},
	abstract = {All currents in the brain superimpose to yield an 'electric field' at any given point in space. The current sources and sinks form dipoles or higher-order n-poles.Extracellular currents arise from many sources, including synaptic currents, fast action potentials and their afterpotentials, calcium spikes and voltage-dependent intrinsic currents.The magnitude of extracellular currents depends critically on two factors: the cytoarchitectural organization of a network and the temporal synchrony of the various current sinks and sources.Depending on the recording method, neuroscientists distinguish between electroencephalogram ({EEG}), electrocorticogram ({ECoG}) and local field potential ({LFP}; also known as micro-, depth or intracranial {EEG}), although all of these measures refer to the same biophysical process.The electric field is the force 'felt' by an electric charge, and can be transmitted through brain volume. The extent of volume conduction depends on the relationships between the current dipole and the features of the conductive medium.High-density sampling of the extracellular field with contemporary methods enables the calculation of current source density, and therefore the localization of current sinks and sources.The voltage gradients generated by highly synchronous activity of neuronal groups can affect the transmembrane potential of the member neurons and alter their excitability through ephaptic coupling.Synchronous spiking of nearby neurons is the main source of the high-frequency components of the local field.There is a discernable relationship between the temporal evolution of cell assemblies and the time-dependent changes of the spatially distributed currents. High-density, wide-band recordings of the local field can therefore provide access to both afferent inputs and the spiking output of neurons.},
	pages = {407--420},
	number = {6},
	journaltitle = {Nature Reviews Neuroscience},
	shortjournal = {Nat Rev Neurosci},
	author = {Buzsáki, György and Anastassiou, Costas A. and Koch, Christof},
	urldate = {2023-04-30},
	date = {2012-06},
	langid = {english},
	note = {Number: 6
Publisher: Nature Publishing Group},
	keywords = {Computational neuroscience, Cellular neuroscience, Extracellular signalling molecules, Ion channels, Synaptic transmission},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\HI4SHDP5\\Buzsáki et al. - 2012 - The origin of extracellular fields and currents — .pdf:application/pdf},
}

@article{marder_multiple_2011,
	title = {Multiple models to capture the variability in biological neurons and networks},
	volume = {14},
	rights = {2011 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.2735},
	doi = {10.1038/nn.2735},
	abstract = {Experimental work suggests that synaptic and intrinsic neuronal properties vary considerably across identified neurons in different animals. The authors propose that instead of building a single model that captures the average behavior of a neuron or circuit, one could construct a population of models with different underlying structure and similar behaviors, as a way of investigating compensatory mechanisms that contribute to neuron and network function.},
	pages = {133--138},
	number = {2},
	journaltitle = {Nature Neuroscience},
	shortjournal = {Nat Neurosci},
	author = {Marder, Eve and Taylor, Adam L.},
	urldate = {2023-05-01},
	date = {2011-02},
	langid = {english},
	note = {Number: 2
Publisher: Nature Publishing Group},
	keywords = {Computational neuroscience},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\I4UTL837\\Marder and Taylor - 2011 - Multiple models to capture the variability in biol.pdf:application/pdf},
}

@article{moly_adaptive_2022,
	title = {An adaptive closed-loop {ECoG} decoder for long-term and stable bimanual control of an exoskeleton by a tetraplegic},
	volume = {19},
	issn = {1741-2552},
	url = {https://dx.doi.org/10.1088/1741-2552/ac59a0},
	doi = {10.1088/1741-2552/ac59a0},
	abstract = {Objective. The article aims at addressing 2 challenges to step motor brain-computer interface ({BCI}) out of laboratories: asynchronous control of complex bimanual effectors with large numbers of degrees of freedom, using chronic and safe recorders, and the decoding performance stability over time without frequent decoder recalibration. Approach. Closed-loop adaptive/incremental decoder training is one strategy to create a model stable over time. Adaptive decoders update their parameters with new incoming data, optimizing the model parameters in real time. It allows cross-session training with multiple recording conditions during closed loop {BCI} experiments. In the article, an adaptive tensor-based recursive exponentially weighted Markov-switching multi-linear model ({REW}-{MSLM}) decoder is proposed. {REW}-{MSLM} uses a mixture of expert ({ME}) architecture, mixing or switching independent decoders (experts) according to the probability estimated by a ‘gating’ model. A Hidden Markov model approach is employed as gating model to improve the decoding robustness and to provide strong idle state support. The {ME} architecture fits the multi-limb paradigm associating an expert to a particular limb or action. Main results. Asynchronous control of an exoskeleton by a tetraplegic patient using a chronically implanted epidural electrocorticography ({EpiCoG}) recorder is reported. The stable over a period of six months (without decoder recalibration) eight-dimensional alternative bimanual control of the exoskeleton and its virtual avatar is demonstrated. Significance. Based on the long-term ({\textgreater}36 months) chronic bilateral {EpiCoG} recordings in a tetraplegic ({ClinicalTrials}.gov, {NCT}02550522), we addressed the poorly explored field of asynchronous bimanual {BCI}. The new decoder was designed to meet to several challenges: the high-dimensional control of a complex effector in experiments closer to real-world behavior (point-to-point pursuit versus conventional center-out tasks), with the ability of the {BCI} system to act as a stand-alone device switching between idle and control states, and a stable performance over a long period of time without decoder recalibration.},
	pages = {026021},
	number = {2},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Moly, Alexandre and Costecalde, Thomas and Martel, Félix and Martin, Matthieu and Larzabal, Christelle and Karakas, Serpil and Verney, Alexandre and Charvet, Guillaume and Chabardes, Stephan and Benabid, Alim Louis and Aksenova, Tetiana},
	urldate = {2023-05-01},
	date = {2022-03},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\TDYFMRNV\\Moly et al. - 2022 - An adaptive closed-loop ECoG decoder for long-term.pdf:application/pdf},
}

@article{anumanchipalli_speech_2019,
	title = {Speech synthesis from neural decoding of spoken sentences},
	volume = {568},
	rights = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-019-1119-1},
	doi = {10.1038/s41586-019-1119-1},
	abstract = {Technology that translates neural activity into speech would be transformative for people who are unable to communicate as a result of neurological impairments. Decoding speech from neural activity is challenging because speaking requires very precise and rapid multi-dimensional control of vocal tract articulators. Here we designed a neural decoder that explicitly leverages kinematic and sound representations encoded in human cortical activity to synthesize audible speech. Recurrent neural networks first decoded directly recorded cortical activity into representations of articulatory movement, and then transformed these representations into speech acoustics. In closed vocabulary tests, listeners could readily identify and transcribe speech synthesized from cortical activity. Intermediate articulatory dynamics enhanced performance even with limited data. Decoded articulatory representations were highly conserved across speakers, enabling a component of the decoder to be transferrable across participants. Furthermore, the decoder could synthesize speech when a participant silently mimed sentences. These findings advance the clinical viability of using speech neuroprosthetic technology to restore spoken communication.},
	pages = {493--498},
	number = {7753},
	journaltitle = {Nature},
	author = {Anumanchipalli, Gopala K. and Chartier, Josh and Chang, Edward F.},
	urldate = {2023-05-01},
	date = {2019-04},
	langid = {english},
	note = {Number: 7753
Publisher: Nature Publishing Group},
	keywords = {Brain–machine interface, Sensorimotor processing},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\4A7CD4XW\\Anumanchipalli et al. - 2019 - Speech synthesis from neural decoding of spoken se.pdf:application/pdf},
}

@article{tang_semantic_2023,
	title = {Semantic reconstruction of continuous language from non-invasive brain recordings},
	rights = {2023 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-023-01304-9},
	doi = {10.1038/s41593-023-01304-9},
	abstract = {A brain–computer interface that decodes continuous language from non-invasive recordings would have many scientific and practical applications. Currently, however, non-invasive language decoders can only identify stimuli from among a small set of words or phrases. Here we introduce a non-invasive decoder that reconstructs continuous language from cortical semantic representations recorded using functional magnetic resonance imaging ({fMRI}). Given novel brain recordings, this decoder generates intelligible word sequences that recover the meaning of perceived speech, imagined speech and even silent videos, demonstrating that a single decoder can be applied to a range of tasks. We tested the decoder across cortex and found that continuous language can be separately decoded from multiple regions. As brain–computer interfaces should respect mental privacy, we tested whether successful decoding requires subject cooperation and found that subject cooperation is required both to train and to apply the decoder. Our findings demonstrate the viability of non-invasive language brain–computer interfaces.},
	pages = {1--9},
	journaltitle = {Nature Neuroscience},
	shortjournal = {Nat Neurosci},
	author = {Tang, Jerry and {LeBel}, Amanda and Jain, Shailee and Huth, Alexander G.},
	urldate = {2023-05-01},
	date = {2023-05-01},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Language, Neural decoding, Functional magnetic resonance imaging},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\XMTLCA6Q\\Tang et al. - 2023 - Semantic reconstruction of continuous language fro.pdf:application/pdf},
}

@article{gwilliams_neural_2022,
	title = {Neural dynamics of phoneme sequences reveal position-invariant code for content and order},
	volume = {13},
	rights = {2022 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-022-34326-1},
	doi = {10.1038/s41467-022-34326-1},
	abstract = {Speech consists of a continuously-varying acoustic signal. Yet human listeners experience it as sequences of discrete speech sounds, which are used to recognise discrete words. To examine how the human brain appropriately sequences the speech signal, we recorded two-hour magnetoencephalograms from 21 participants listening to short narratives. Our analyses show that the brain continuously encodes the three most recently heard speech sounds in parallel, and maintains this information long past its dissipation from the sensory input. Each speech sound representation evolves over time, jointly encoding both its phonetic features and the amount of time elapsed since onset. As a result, this dynamic neural pattern encodes both the relative order and phonetic content of the speech sequence. These representations are active earlier when phonemes are more predictable, and are sustained longer when lexical identity is uncertain. Our results show how phonetic sequences in natural speech are represented at the level of populations of neurons, providing insight into what intermediary representations exist between the sensory input and sub-lexical units. The flexibility in the dynamics of these representations paves the way for further understanding of how such sequences may be used to interface with higher order structure such as lexical identity.},
	pages = {6606},
	number = {1},
	journaltitle = {Nature Communications},
	shortjournal = {Nat Commun},
	author = {Gwilliams, Laura and King, Jean-Remi and Marantz, Alec and Poeppel, David},
	urldate = {2023-05-03},
	date = {2022-11-03},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Language, Neural decoding, Cortex, Perception},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\UILHHRRX\\Gwilliams et al. - 2022 - Neural dynamics of phoneme sequences reveal positi.pdf:application/pdf},
}

@inproceedings{szegedy_going_2015,
	title = {Going deeper with convolutions},
	doi = {10.1109/CVPR.2015.7298594},
	abstract = {We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the {ImageNet} Large-Scale Visual Recognition Challenge 2014 ({ILSVRC}14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for {ILSVRC}14 is called {GoogLeNet}, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
	eventtitle = {2015 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	pages = {1--9},
	booktitle = {2015 {IEEE} Conference on Computer Vision and Pattern Recognition ({CVPR})},
	author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	date = {2015-06},
	note = {{ISSN}: 1063-6919},
	keywords = {Neural networks, Sparse matrices, Convolutional codes, Computer architecture, Computer vision, Object detection, Visualization},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\BCZDDGXE\\7298594.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\NNANQEJE\\Szegedy et al. - 2015 - Going deeper with convolutions.pdf:application/pdf},
}

@article{schwemmer_meeting_2018,
	title = {Meeting brain–computer interface user performance expectations using a deep neural network decoding framework},
	volume = {24},
	rights = {2018 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-170X},
	url = {https://www.nature.com/articles/s41591-018-0171-y},
	doi = {10.1038/s41591-018-0171-y},
	abstract = {Brain–computer interface ({BCI}) neurotechnology has the potential to reduce disability associated with paralysis by translating neural activity into control of assistive devices1–9. Surveys of potential end-users have identified key {BCI} system features10–14, including high accuracy, minimal daily setup, rapid response times, and multifunctionality. These performance characteristics are primarily influenced by the {BCI}’s neural decoding algorithm1,15, which is trained to associate neural activation patterns with intended user actions. Here, we introduce a new deep neural network16 decoding framework for {BCI} systems enabling discrete movements that addresses these four key performance characteristics. Using intracortical data from a participant with tetraplegia, we provide offline results demonstrating that our decoder is highly accurate, sustains this performance beyond a year without explicit daily retraining by combining it with an unsupervised updating procedure3,17–20, responds faster than competing methods8, and can increase functionality with minimal retraining by using a technique known as transfer learning21. We then show that our participant can use the decoder in real-time to reanimate his paralyzed forearm with functional electrical stimulation ({FES}), enabling accurate manipulation of three objects from the grasp and release test ({GRT})22. These results demonstrate that deep neural network decoders can advance the clinical translation of {BCI} technology.},
	pages = {1669--1676},
	number = {11},
	journaltitle = {Nature Medicine},
	shortjournal = {Nat Med},
	author = {Schwemmer, Michael A. and Skomrock, Nicholas D. and Sederberg, Per B. and Ting, Jordyn E. and Sharma, Gaurav and Bockbrader, Marcia A. and Friedenberg, David A.},
	urldate = {2023-05-05},
	date = {2018-11},
	langid = {english},
	note = {Number: 11
Publisher: Nature Publishing Group},
	keywords = {Machine learning, Neural decoding, Brain–machine interface, Translational research},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\5BCC9ALG\\Schwemmer et al. - 2018 - Meeting brain–computer interface user performance .pdf:application/pdf},
}

@article{fischl_freesurfer_2012,
	title = {{FreeSurfer}},
	volume = {62},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811912000389},
	doi = {10.1016/j.neuroimage.2012.01.021},
	series = {20 {YEARS} {OF} {fMRI}},
	abstract = {{FreeSurfer} is a suite of tools for the analysis of neuroimaging data that provides an array of algorithms to quantify the functional, connectional and structural properties of the human brain. It has evolved from a package primarily aimed at generating surface representations of the cerebral cortex into one that automatically creates models of most macroscopically visible structures in the human brain given any reasonable T1-weighted input image. It is freely available, runs on a wide variety of hardware and software platforms, and is open source.},
	pages = {774--781},
	number = {2},
	journaltitle = {{NeuroImage}},
	shortjournal = {{NeuroImage}},
	author = {Fischl, Bruce},
	urldate = {2023-05-09},
	date = {2012-08-15},
	langid = {english},
	keywords = {Morphometry, {MRI}, Registration, Segmentation},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\UIFJEI8E\\Fischl - 2012 - FreeSurfer.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\2JWXTYLW\\S1053811912000389.html:text/html},
}

@article{bush_differentiation_2022,
	title = {Differentiation of speech-induced artifacts from physiological high gamma activity in intracranial recordings},
	volume = {250},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S105381192200091X},
	doi = {10.1016/j.neuroimage.2022.118962},
	abstract = {There is great interest in identifying the neurophysiological underpinnings of speech production. Deep brain stimulation ({DBS}) surgery is unique in that it allows intracranial recordings from both cortical and subcortical regions in patients who are awake and speaking. The quality of these recordings, however, may be affected to various degrees by mechanical forces resulting from speech itself. Here we describe the presence of speech-induced artifacts in local-field potential ({LFP}) recordings obtained from mapping electrodes, {DBS} leads, and cortical electrodes. In addition to expected physiological increases in high gamma (60–200 Hz) activity during speech production, time-frequency analysis in many channels revealed a narrowband gamma component that exhibited a pattern similar to that observed in the speech audio spectrogram. This component was present to different degrees in multiple types of neural recordings. We show that this component tracks the fundamental frequency of the participant's voice, correlates with the power spectrum of speech and has coherence with the produced speech audio. A vibration sensor attached to the stereotactic frame recorded speech-induced vibrations with the same pattern observed in the {LFPs}. No corresponding component was identified in any neural channel during the listening epoch of a syllable repetition task. These observations demonstrate how speech-induced vibrations can create artifacts in the primary frequency band of interest. Identifying and accounting for these artifacts is crucial for establishing the validity and reproducibility of speech-related data obtained from intracranial recordings during {DBS} surgery.},
	pages = {118962},
	journaltitle = {{NeuroImage}},
	shortjournal = {{NeuroImage}},
	author = {Bush, Alan and Chrabaszcz, Anna and Peterson, Victoria and Saravanan, Varun and Dastolfo-Hromack, Christina and Lipski, Witold J. and Richardson, R. Mark},
	urldate = {2023-05-09},
	date = {2022-04-15},
	langid = {english},
	keywords = {Deep brain stimulation, Speech, Electrocorticography, High gamma, Artifact, Intracranial recordings, Intraoperative research, Local field potentials},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\3X6AFR9Q\\Bush et al. - 2022 - Differentiation of speech-induced artifacts from p.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\FDWW4KMV\\S105381192200091X.html:text/html},
}

@article{greenberg_patent_2021,
	title = {Patent landscape of brain–machine interface technology},
	volume = {39},
	rights = {2021 Springer Nature America, Inc.},
	issn = {1546-1696},
	url = {https://www.nature.com/articles/s41587-021-01071-7},
	doi = {10.1038/s41587-021-01071-7},
	abstract = {A study of the brain–machine interface patent landscape suggests that the technology is in its early stages of development, but patent applications have been increasing exponentially in recent years.},
	pages = {1194--1199},
	number = {10},
	journaltitle = {Nature Biotechnology},
	shortjournal = {Nat Biotechnol},
	author = {Greenberg, Anastasia and Cohen, Alexis and Grewal, Monica},
	urldate = {2023-05-15},
	date = {2021-10},
	langid = {english},
	note = {Number: 10
Publisher: Nature Publishing Group},
	keywords = {Computational neuroscience, Neuroscience},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\8W62WN8Q\\Greenberg et al. - 2021 - Patent landscape of brain–machine interface techno.pdf:application/pdf},
}

@article{kashyap_automated_2020,
	title = {Automated Topographic Prominence based quantitative assessment of speech timing in Cerebellar Ataxia},
	volume = {57},
	issn = {1746-8094},
	url = {https://www.sciencedirect.com/science/article/pii/S1746809419303404},
	doi = {10.1016/j.bspc.2019.101759},
	abstract = {Clinical assessment of speech abnormalities in Cerebellar Ataxia ({CA}) is subjective and prone to intra- and inter-clinician inconsistencies. This paper presents an automated objective method based on a single syllable repetition task to detect and quantify speech-timing anomalies in ataxic speech. Such a technique is non-invasive, reliable, fast, cost-effective and can be used in the comfort of home without any professional assistance. A mathematically inclined topographic prominence-based algorithm with an extensive outlier detection mechanism is designed for the automatic detection of syllables in the captured speech data. Six acoustic features and eleven corresponding speech timing and vocal stability measurements were extracted during the topographical prominence analysis. These features are used to classify {CA} from normal speakers and objectively identify the {CA} speakers based on their severity. The effectiveness of the proposed algorithm is experimentally evaluated through a clinical study involving 63 patients diagnosed with {CA} (to varying degrees of dysarthria) and 28 age-matched normal speakers. In syllable detection, our proposed automated algorithm achieved an accuracy of 95.6\% and 99.1\% for ataxic and normal speech respectively. These speech samples were clinically rated using the Scale for the Assessment and Rating of Ataxia ({SARA}). {SVM} classifier achieved a classification accuracy of 84.7\% (area under {ROC}=0.91) in healthy-{CA} discrimination and 74.7\% (average area under {ROC}=0.82) in the modified 4-level {CA} severity estimation based on {SARA} ratings. The strong classification ability of selected features and the {SVM} model supports suitability of this scheme to monitor speech motor abnormalities in persons suffering from {CA}.},
	pages = {101759},
	journaltitle = {Biomedical Signal Processing and Control},
	shortjournal = {Biomedical Signal Processing and Control},
	author = {Kashyap, Bipasha and Horne, Malcolm and Pathirana, Pubudu N. and Power, Laura and Szmulewicz, David},
	urldate = {2023-05-17},
	date = {2020-03-01},
	langid = {english},
	keywords = {Speech analysis, Cerebellar ataxia, Repeated syllable, {ROC} (Receiver Operating Characteristic), {SVM} (Support Vector Machine), Topographic prominence},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\NET425FT\\Kashyap et al. - 2020 - Automated Topographic Prominence based quantitativ.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\9HPVNDCZ\\S1746809419303404.html:text/html},
}

@article{lorach_walking_2023,
	title = {Walking naturally after spinal cord injury using a brain–spine interface},
	rights = {2023 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-023-06094-5},
	doi = {10.1038/s41586-023-06094-5},
	abstract = {A spinal cord injury interrupts the communication between the brain and the region of the spinal cord that produces walking, leading to paralysis1,2. Here, we restored this communication with a digital bridge between the brain and spinal cord that enabled an individual with chronic tetraplegia to stand and walk naturally in community settings. This brain–spine interface ({BSI}) consists of fully implanted recording and stimulation systems that establish a direct link between cortical signals3 and the analogue modulation of epidural electrical stimulation targeting the spinal cord regions involved in the production of walking4–6. A highly reliable {BSI} is calibrated within a few minutes. This reliability has remained stable over one year, including during independent use at home. The participant reports that the {BSI} enables natural control over the movements of his legs to stand, walk, climb stairs and even traverse complex terrains. Moreover, neurorehabilitation supported by the {BSI} improved neurological recovery. The participant regained the ability to walk with crutches overground even when the {BSI} was switched off. This digital bridge establishes a framework to restore natural control of movement after paralysis.},
	pages = {1--8},
	journaltitle = {Nature},
	author = {Lorach, Henri and Galvez, Andrea and Spagnolo, Valeria and Martel, Felix and Karakas, Serpil and Intering, Nadine and Vat, Molywan and Faivre, Olivier and Harte, Cathal and Komi, Salif and Ravier, Jimmy and Collin, Thibault and Coquoz, Laure and Sakr, Icare and Baaklini, Edeny and Hernandez-Charpak, Sergio Daniel and Dumont, Gregory and Buschman, Rik and Buse, Nicholas and Denison, Tim and van Nes, Ilse and Asboth, Leonie and Watrin, Anne and Struber, Lucas and Sauter-Starace, Fabien and Langar, Lilia and Auboiroux, Vincent and Carda, Stefano and Chabardes, Stephan and Aksenova, Tetiana and Demesmaeker, Robin and Charvet, Guillaume and Bloch, Jocelyne and Courtine, Grégoire},
	urldate = {2023-05-24},
	date = {2023-05-24},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Brain–machine interface, Spinal cord, Spinal cord diseases},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\J5N2E2N8\\Lorach et al. - 2023 - Walking naturally after spinal cord injury using a.pdf:application/pdf},
}

@online{noauthor_scipystatspearsonr_nodate,
	title = {scipy.stats.pearsonr — {SciPy} v1.10.1 Manual},
	url = {https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html#r8c6348c62346-3},
	urldate = {2023-05-26},
	file = {scipy.stats.pearsonr — SciPy v1.10.1 Manual:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\VMMQ74LB\\scipy.stats.pearsonr.html:text/html},
}

@report{melnikov_websocket_2011,
	title = {The {WebSocket} Protocol},
	url = {https://datatracker.ietf.org/doc/rfc6455},
	abstract = {The {WebSocket} Protocol enables two-way communication between a client running untrusted code in a controlled environment to a remote host that has opted-in to communications from that code. The security model used for this is the origin-based security model commonly used by web browsers. The protocol consists of an opening handshake followed by basic message framing, layered over {TCP}. The goal of this technology is to provide a mechanism for browser-based applications that need two-way communication with servers that does not rely on opening multiple {HTTP} connections (e.g., using {XMLHttpRequest} or {\textbackslash}textlessiframe{\textbackslash}textgreaters and long polling). [{STANDARDS}-{TRACK}]},
	number = {{RFC} 6455},
	institution = {Internet Engineering Task Force},
	type = {Request for Comments},
	author = {Melnikov, Alexey and Fette, Ian},
	urldate = {2023-05-31},
	date = {2011-12},
	doi = {10.17487/RFC6455},
	note = {Num Pages: 71},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\PJG554I5\\Melnikov and Fette - 2011 - The WebSocket Protocol.pdf:application/pdf},
}

@article{huggins_what_2011,
	title = {What would brain-computer interface users want? Opinions and priorities of potential users with amyotrophic lateral sclerosis},
	volume = {12},
	issn = {1748-2968},
	url = {https://doi.org/10.3109/17482968.2011.572978},
	doi = {10.3109/17482968.2011.572978},
	shorttitle = {What would brain-computer interface users want?},
	abstract = {Universal design principles advocate inclusion of end users in every design stage, including research and development. Brain-computer interfaces ({BCIs}) have long been described as potential tools to enable people with amyotrophic lateral sclerosis ({ALS}) to operate technology without moving. Therefore the objective of the current study is to determine the opinions and priorities of people with {ALS} regarding {BCI} design. This information will guide {BCIs} in development to meet end-user needs. A telephone survey was undertaken of 61 people with {ALS} from the University of Michigan's Motor Neuron Disease Clinic. With regard to {BCI} design, participants prioritized accuracy of command identification of at least 90\% (satisfying 84\% of respondents), speed of operation comparable to at least 15–19 letters per minute (satisfying 72\%), and accidental exits from a standby mode not more than once every 2–4 h (satisfying 84\%). While 84\% of respondents would accept using an electrode cap, 72\% were willing to undergo outpatient surgery and 41\% to undergo surgery with a short hospital stay in order to obtain a {BCI}. In conclusion, people with {ALS} expressed a strong interest in obtaining {BCIs}, but current {BCIs} do not yet provide desired {BCI} performance.},
	pages = {318--324},
	number = {5},
	journaltitle = {Amyotrophic Lateral Sclerosis},
	author = {Huggins, Jane E. and Wren, Patricia A. and Gruis, Kirsten L.},
	urldate = {2023-06-01},
	date = {2011-09-01},
	pmid = {21534845},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.3109/17482968.2011.572978},
	keywords = {Female, Humans, Male, Middle Aged, Aged, Amyotrophic Lateral Sclerosis, Communication Aids for Disabled, Data Collection, Follow-Up Studies, Patient Satisfaction, Reaction Time, User-Computer Interface, Brain-computer interface ({BCI}), performance criteria, standards},
	file = {Accepted Version:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\9X9QLPBS\\Huggins et al. - 2011 - What would brain-computer interface users want Op.pdf:application/pdf;Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\XPH23ZVX\\Huggins et al. - 2011 - What would brain-computer interface users want Op.pdf:application/pdf},
}

@article{degenhart_stabilization_2020,
	title = {Stabilization of a brain–computer interface via the alignment of low-dimensional spaces of neural activity},
	volume = {4},
	rights = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2157-846X},
	url = {https://www.nature.com/articles/s41551-020-0542-9},
	doi = {10.1038/s41551-020-0542-9},
	abstract = {The instability of neural recordings can render clinical brain–computer interfaces ({BCIs}) uncontrollable. Here, we show that the alignment of low-dimensional neural manifolds (low-dimensional spaces that describe specific correlation patterns between neurons) can be used to stabilize neural activity, thereby maintaining {BCI} performance in the presence of recording instabilities. We evaluated the stabilizer with non-human primates during online cursor control via intracortical {BCIs} in the presence of severe and abrupt recording instabilities. The stabilized {BCIs} recovered proficient control under different instability conditions and across multiple days. The stabilizer does not require knowledge of user intent and can outperform supervised recalibration. It stabilized {BCIs} even when neural activity contained little information about the direction of cursor movement. The stabilizer may be applicable to other neural interfaces and may improve the clinical viability of {BCIs}.},
	pages = {672--685},
	number = {7},
	journaltitle = {Nature Biomedical Engineering},
	shortjournal = {Nat Biomed Eng},
	author = {Degenhart, Alan D. and Bishop, William E. and Oby, Emily R. and Tyler-Kabara, Elizabeth C. and Chase, Steven M. and Batista, Aaron P. and Yu, Byron M.},
	urldate = {2023-06-05},
	date = {2020-07},
	langid = {english},
	note = {Number: 7
Publisher: Nature Publishing Group},
	keywords = {Brain–machine interface, Motor cortex},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\MGIQCF3H\\Degenhart et al. - 2020 - Stabilization of a brain–computer interface via th.pdf:application/pdf},
}

@article{proix_imagined_2022,
	title = {Imagined speech can be decoded from low- and cross-frequency intracranial {EEG} features},
	volume = {13},
	rights = {2022 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-27725-3},
	doi = {10.1038/s41467-021-27725-3},
	abstract = {Reconstructing intended speech from neural activity using brain-computer interfaces holds great promises for people with severe speech production deficits. While decoding overt speech has progressed, decoding imagined speech has met limited success, mainly because the associated neural signals are weak and variable compared to overt speech, hence difficult to decode by learning algorithms. We obtained three electrocorticography datasets from 13 patients, with electrodes implanted for epilepsy evaluation, who performed overt and imagined speech production tasks. Based on recent theories of speech neural processing, we extracted consistent and specific neural features usable for future brain computer interfaces, and assessed their performance to discriminate speech items in articulatory, phonetic, and vocalic representation spaces. While high-frequency activity provided the best signal for overt speech, both low- and higher-frequency power and local cross-frequency contributed to imagined speech decoding, in particular in phonetic and vocalic, i.e. perceptual, spaces. These findings show that low-frequency power and cross-frequency dynamics contain key information for imagined speech decoding.},
	pages = {48},
	number = {1},
	journaltitle = {Nature Communications},
	shortjournal = {Nat Commun},
	author = {Proix, Timothée and Delgado Saa, Jaime and Christen, Andy and Martin, Stephanie and Pasley, Brian N. and Knight, Robert T. and Tian, Xing and Poeppel, David and Doyle, Werner K. and Devinsky, Orrin and Arnal, Luc H. and Mégevand, Pierre and Giraud, Anne-Lise},
	urldate = {2023-06-05},
	date = {2022-01-10},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Language, Neuroscience},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\6SYN9AFA\\Proix et al. - 2021 - Imagined speech can be decoded from low- and cross.pdf:application/pdf;Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\QKALP358\\Proix et al. - 2022 - Imagined speech can be decoded from low- and cross.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\K6DK9HXV\\2021.01.26.html:text/html},
}

@article{kudithipudi_biological_2022,
	title = {Biological underpinnings for lifelong learning machines},
	volume = {4},
	rights = {2022 Springer Nature Limited},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-022-00452-0},
	doi = {10.1038/s42256-022-00452-0},
	abstract = {Biological organisms learn from interactions with their environment throughout their lifetime. For artificial systems to successfully act and adapt in the real world, it is desirable to similarly be able to learn on a continual basis. This challenge is known as lifelong learning, and remains to a large extent unsolved. In this Perspective article, we identify a set of key capabilities that artificial systems will need to achieve lifelong learning. We describe a number of biological mechanisms, both neuronal and non-neuronal, that help explain how organisms solve these challenges, and present examples of biologically inspired models and biologically plausible mechanisms that have been applied to artificial systems in the quest towards development of lifelong learning machines. We discuss opportunities to further our understanding and advance the state of the art in lifelong learning, aiming to bridge the gap between natural and artificial intelligence.},
	pages = {196--210},
	number = {3},
	journaltitle = {Nature Machine Intelligence},
	shortjournal = {Nat Mach Intell},
	author = {Kudithipudi, Dhireesha and Aguilar-Simon, Mario and Babb, Jonathan and Bazhenov, Maxim and Blackiston, Douglas and Bongard, Josh and Brna, Andrew P. and Chakravarthi Raja, Suraj and Cheney, Nick and Clune, Jeff and Daram, Anurag and Fusi, Stefano and Helfer, Peter and Kay, Leslie and Ketz, Nicholas and Kira, Zsolt and Kolouri, Soheil and Krichmar, Jeffrey L. and Kriegman, Sam and Levin, Michael and Madireddy, Sandeep and Manicka, Santosh and Marjaninejad, Ali and {McNaughton}, Bruce and Miikkulainen, Risto and Navratilova, Zaneta and Pandit, Tej and Parker, Alice and Pilly, Praveen K. and Risi, Sebastian and Sejnowski, Terrence J. and Soltoggio, Andrea and Soures, Nicholas and Tolias, Andreas S. and Urbina-Meléndez, Darío and Valero-Cuevas, Francisco J. and van de Ven, Gido M. and Vogelstein, Joshua T. and Wang, Felix and Weiss, Ron and Yanguas-Gil, Angel and Zou, Xinyun and Siegelmann, Hava},
	urldate = {2023-06-19},
	date = {2022-03},
	langid = {english},
	note = {Number: 3
Publisher: Nature Publishing Group},
	keywords = {Computer science, Intelligence, Learning algorithms},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\4AFCQEDQ\\Kudithipudi et al. - 2022 - Biological underpinnings for lifelong learning mac.pdf:application/pdf},
}

@inproceedings{rannen_encoder_2017,
	location = {Venice},
	title = {Encoder Based Lifelong Learning},
	isbn = {978-1-5386-1032-9},
	url = {http://ieeexplore.ieee.org/document/8237410/},
	doi = {10.1109/ICCV.2017.148},
	abstract = {This paper introduces a new lifelong learning solution where a single model is trained for a sequence of tasks. The main challenge that vision systems face in this context is catastrophic forgetting: as they tend to adapt to the most recently seen task, they lose performance on the tasks that were learned previously. Our method aims at preserving the knowledge of the previous tasks while learning a new one by using autoencoders. For each task, an under-complete autoencoder is learned, capturing the features that are crucial for its achievement. When a new task is presented to the system, we prevent the reconstructions of the features with these autoencoders from changing, which has the effect of preserving the information on which the previous tasks are mainly relying. At the same time, the features are given space to adjust to the most recent environment as only their projection into a low dimension submanifold is controlled. The proposed system is evaluated on image classiﬁcation tasks and shows a reduction of forgetting over the state-ofthe-art.},
	eventtitle = {2017 {IEEE} International Conference on Computer Vision ({ICCV})},
	pages = {1329--1337},
	booktitle = {2017 {IEEE} International Conference on Computer Vision ({ICCV})},
	publisher = {{IEEE}},
	author = {Rannen, Amal and Aljundi, Rahaf and Blaschko, Matthew B. and Tuytelaars, Tinne},
	urldate = {2023-06-26},
	date = {2017-10},
	langid = {english},
	file = {Rannen et al. - 2017 - Encoder Based Lifelong Learning.pdf:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\JXTN2CZ9\\Rannen et al. - 2017 - Encoder Based Lifelong Learning.pdf:application/pdf},
}

@misc{zhou_deep_2023,
	title = {Deep Class-Incremental Learning: A Survey},
	url = {http://arxiv.org/abs/2302.03648},
	shorttitle = {Deep Class-Incremental Learning},
	abstract = {Deep models, e.g., {CNNs} and Vision Transformers, have achieved impressive achievements in many vision tasks in the closed world. However, novel classes emerge from time to time in our ever-changing world, requiring a learning system to acquire new knowledge continually. For example, a robot needs to understand new instructions, and an opinion monitoring system should analyze emerging topics every day. Class-Incremental Learning ({CIL}) enables the learner to incorporate the knowledge of new classes incrementally and build a universal classifier among all seen classes. Correspondingly, when directly training the model with new class instances, a fatal problem occurs -- the model tends to catastrophically forget the characteristics of former ones, and its performance drastically degrades. There have been numerous efforts to tackle catastrophic forgetting in the machine learning community. In this paper, we survey comprehensively recent advances in deep class-incremental learning and summarize these methods from three aspects, i.e., data-centric, model-centric, and algorithm-centric. We also provide a rigorous and unified evaluation of 16 methods in benchmark image classification tasks to find out the characteristics of different algorithms empirically. Furthermore, we notice that the current comparison protocol ignores the influence of memory budget in model storage, which may result in unfair comparison and biased results. Hence, we advocate fair comparison by aligning the memory budget in evaluation, as well as several memory-agnostic performance measures. The source code to reproduce these evaluations is available at https://github.com/zhoudw-zdw/{CIL}\_Survey/},
	number = {{arXiv}:2302.03648},
	publisher = {{arXiv}},
	author = {Zhou, Da-Wei and Wang, Qi-Wei and Qi, Zhi-Hong and Ye, Han-Jia and Zhan, De-Chuan and Liu, Ziwei},
	urldate = {2023-06-26},
	date = {2023-02-07},
	eprinttype = {arxiv},
	eprint = {2302.03648 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv.org Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\6L8T2G3B\\2302.html:text/html;Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\S23CKJDB\\Zhou et al. - 2023 - Deep Class-Incremental Learning A Survey.pdf:application/pdf},
}

@article{van_de_ven_brain-inspired_2020,
	title = {Brain-inspired replay for continual learning with artificial neural networks},
	volume = {11},
	rights = {2020 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-020-17866-2},
	doi = {10.1038/s41467-020-17866-2},
	abstract = {Artificial neural networks suffer from catastrophic forgetting. Unlike humans, when these networks are trained on something new, they rapidly forget what was learned before. In the brain, a mechanism thought to be important for protecting memories is the reactivation of neuronal activity patterns representing those memories. In artificial neural networks, such memory replay can be implemented as ‘generative replay’, which can successfully – and surprisingly efficiently – prevent catastrophic forgetting on toy examples even in a class-incremental learning scenario. However, scaling up generative replay to complicated problems with many tasks or complex inputs is challenging. We propose a new, brain-inspired variant of replay in which internal or hidden representations are replayed that are generated by the network’s own, context-modulated feedback connections. Our method achieves state-of-the-art performance on challenging continual learning benchmarks (e.g., class-incremental learning on {CIFAR}-100) without storing data, and it provides a novel model for replay in the brain.},
	pages = {4069},
	number = {1},
	journaltitle = {Nature Communications},
	shortjournal = {Nat Commun},
	author = {van de Ven, Gido M. and Siegelmann, Hava T. and Tolias, Andreas S.},
	urldate = {2023-06-26},
	date = {2020-08-13},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Computational neuroscience, Computer science, Learning and memory},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\W47VMPFE\\van de Ven et al. - 2020 - Brain-inspired replay for continual learning with .pdf:application/pdf},
}

@article{van_de_ven_three_2022,
	title = {Three types of incremental learning},
	volume = {4},
	rights = {2022 The Author(s)},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-022-00568-3},
	doi = {10.1038/s42256-022-00568-3},
	abstract = {Incrementally learning new information from a non-stationary stream of data, referred to as ‘continual learning’, is a key feature of natural intelligence, but a challenging problem for deep neural networks. In recent years, numerous deep learning methods for continual learning have been proposed, but comparing their performances is difficult due to the lack of a common framework. To help address this, we describe three fundamental types, or ‘scenarios’, of continual learning: task-incremental, domain-incremental and class-incremental learning. Each of these scenarios has its own set of challenges. To illustrate this, we provide a comprehensive empirical comparison of currently used continual learning strategies, by performing the Split {MNIST} and Split {CIFAR}-100 protocols according to each scenario. We demonstrate substantial differences between the three scenarios in terms of difficulty and in terms of the effectiveness of different strategies. The proposed categorization aims to structure the continual learning field, by forming a key foundation for clearly defining benchmark problems.},
	pages = {1185--1197},
	number = {12},
	journaltitle = {Nature Machine Intelligence},
	shortjournal = {Nat Mach Intell},
	author = {van de Ven, Gido M. and Tuytelaars, Tinne and Tolias, Andreas S.},
	urldate = {2023-06-26},
	date = {2022-12},
	langid = {english},
	note = {Number: 12
Publisher: Nature Publishing Group},
	keywords = {Computer science, Learning algorithms, Software},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\97HTIUSR\\van de Ven et al. - 2022 - Three types of incremental learning.pdf:application/pdf},
}

@misc{vogelstein_representation_2023,
	title = {Representation Ensembling for Synergistic Lifelong Learning with Quasilinear Complexity},
	url = {http://arxiv.org/abs/2004.12908},
	abstract = {In lifelong learning, data are used to improve performance not only on the current task, but also on previously encountered, and as yet unencountered tasks. In contrast, classical machine learning, which we define as, starts from a blank slate, or tabula rasa and uses data only for the single task at hand. While typical transfer learning algorithms can improve performance on future tasks, their performance on prior tasks degrades upon learning new tasks (called forgetting). Many recent approaches for continual or lifelong learning have attempted to maintain performance on old tasks given new tasks. But striving to avoid forgetting sets the goal unnecessarily low. The goal of lifelong learning should be not only to improve performance on future tasks (forward transfer) but also on past tasks (backward transfer) with any new data. Our key insight is that we can synergistically ensemble representations -- that were learned independently on disparate tasks -- to enable both forward and backward transfer. This generalizes ensembling decisions (like in decision forests) and complements ensembling dependently learned representations (like in multitask learning). Moreover, we can ensemble representations in quasilinear space and time. We demonstrate this insight with two algorithms: representation ensembles of (1) trees and (2) networks. Both algorithms demonstrate forward and backward transfer in a variety of simulated and benchmark data scenarios, including tabular, image, and spoken, and adversarial tasks. This is in stark contrast to the reference algorithms we compared to, most of which failed to transfer either forward or backward, or both, despite that many of them require quadratic space or time complexity.},
	number = {{arXiv}:2004.12908},
	publisher = {{arXiv}},
	author = {Vogelstein, Joshua T. and Dey, Jayanta and Helm, Hayden S. and {LeVine}, Will and Mehta, Ronak D. and Tomita, Tyler M. and Xu, Haoyin and Geisa, Ali and Wang, Qingyang and van de Ven, Gido M. and Gao, Chenyu and Yang, Weiwei and Tower, Bryan and Larson, Jonathan and White, Christopher M. and Priebe, Carey E.},
	urldate = {2023-06-26},
	date = {2023-03-22},
	eprinttype = {arxiv},
	eprint = {2004.12908 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv.org Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\TRZBP2KI\\2004.html:text/html;Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\WLMLC322\\Vogelstein et al. - 2023 - Representation Ensembling for Synergistic Lifelong.pdf:application/pdf},
}

@article{stanley_designing_2019,
	title = {Designing neural networks through neuroevolution},
	volume = {1},
	rights = {2019 Springer Nature Limited},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-018-0006-z},
	doi = {10.1038/s42256-018-0006-z},
	abstract = {Much of recent machine learning has focused on deep learning, in which neural network weights are trained through variants of stochastic gradient descent. An alternative approach comes from the field of neuroevolution, which harnesses evolutionary algorithms to optimize neural networks, inspired by the fact that natural brains themselves are the products of an evolutionary process. Neuroevolution enables important capabilities that are typically unavailable to gradient-based approaches, including learning neural network building blocks (for example activation functions), hyperparameters, architectures and even the algorithms for learning themselves. Neuroevolution also differs from deep learning (and deep reinforcement learning) by maintaining a population of solutions during search, enabling extreme exploration and massive parallelization. Finally, because neuroevolution research has (until recently) developed largely in isolation from gradient-based neural network research, it has developed many unique and effective techniques that should be effective in other machine learning areas too. This Review looks at several key aspects of modern neuroevolution, including large-scale computing, the benefits of novelty and diversity, the power of indirect encoding, and the field’s contributions to meta-learning and architecture search. Our hope is to inspire renewed interest in the field as it meets the potential of the increasing computation available today, to highlight how many of its ideas can provide an exciting resource for inspiration and hybridization to the deep learning, deep reinforcement learning and machine learning communities, and to explain how neuroevolution could prove to be a critical tool in the long-term pursuit of artificial general intelligence.},
	pages = {24--35},
	number = {1},
	journaltitle = {Nature Machine Intelligence},
	shortjournal = {Nat Mach Intell},
	author = {Stanley, Kenneth O. and Clune, Jeff and Lehman, Joel and Miikkulainen, Risto},
	urldate = {2023-06-26},
	date = {2019-01},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Computer science, Software},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\T59JUYPC\\Stanley et al. - 2019 - Designing neural networks through neuroevolution.pdf:application/pdf},
}

@inproceedings{shin_continual_2017,
	title = {Continual Learning with Deep Generative Replay},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper_files/paper/2017/hash/0efbe98067c6c73dba1250d2beaa81f9-Abstract.html},
	abstract = {Attempts to train a comprehensive artificial intelligence capable of solving multiple tasks have been impeded by a chronic problem called catastrophic forgetting. Although simply replaying all previous data alleviates the problem, it requires large memory and even worse, often infeasible in real world applications where the access to past data is limited. Inspired by the generative nature of the hippocampus as a short-term memory system in primate brain, we propose the Deep Generative Replay, a novel framework with a cooperative dual model architecture consisting of a deep generative model (“generator”) and a task solving model (“solver”). With only these two models, training data for previous tasks can easily be sampled and interleaved with those for a new task. We test our methods in several sequential learning settings involving image classification tasks.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Shin, Hanul and Lee, Jung Kwon and Kim, Jaehong and Kim, Jiwon},
	urldate = {2023-06-26},
	date = {2017},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\WIIAZDRS\\Shin et al. - 2017 - Continual Learning with Deep Generative Replay.pdf:application/pdf},
}

@article{kumosa_commonly_2023,
	title = {Commonly Overlooked Factors in Biocompatibility Studies of Neural Implants},
	volume = {10},
	rights = {© 2023 The Authors. Advanced Science published by Wiley-{VCH} {GmbH}},
	issn = {2198-3844},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/advs.202205095},
	doi = {10.1002/advs.202205095},
	abstract = {Biocompatibility of cutting-edge neural implants, surgical tools and techniques, and therapeutic technologies is a challenging concept that can be easily misjudged. For example, neural interfaces are routinely gauged on how effectively they determine active neurons near their recording sites. Tissue integration and toxicity of neural interfaces are frequently assessed histologically in animal models to determine tissue morphological and cellular changes in response to surgical implantation and chronic presence. A disconnect between histological and efficacious biocompatibility exists, however, as neuronal numbers frequently observed near electrodes do not match recorded neuronal spiking activity. The downstream effects of the myriad surgical and experimental factors involved in such studies are rarely examined when deciding whether a technology or surgical process is biocompatible. Such surgical factors as anesthesia, temperature excursions, bleed incidence, mechanical forces generated, and metabolic conditions are known to have strong systemic and thus local cellular and extracellular consequences. Many tissue markers are extremely sensitive to the physiological state of cells and tissues, thus significantly impacting histological accuracy. This review aims to shed light on commonly overlooked factors that can have a strong impact on the assessment of neural biocompatibility and to address the mismatch between results stemming from functional and histological methods.},
	pages = {2205095},
	number = {6},
	journaltitle = {Advanced Science},
	author = {Kumosa, Lucas S.},
	urldate = {2023-07-03},
	date = {2023},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/advs.202205095},
	keywords = {biocompatibility, neural implants, neural interfaces},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\XWUFYAVK\\Kumosa - 2023 - Commonly Overlooked Factors in Biocompatibility St.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\W8553WEY\\advs.html:text/html},
}

@article{darley_diagnostic_nodate,
	title = {Diagnostic methods in speech pathology},
	url = {https://cir.nii.ac.jp/crid/1130000793933255936},
	journaltitle = {(No Title)},
	author = {Darley, Frederic L.},
	urldate = {2023-09-08},
	langid = {english},
	file = {Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\KVP5C64Y\\1130000793933255936.html:text/html},
}

@book{darley_diagnostic_1978,
	location = {New York, {NY}},
	edition = {2nd},
	title = {Diagnostic methods in speech pathology (2nd Ed)},
	url = {https://cir.nii.ac.jp/crid/1130000793933255936},
	publisher = {Harper and Row},
	author = {Darley, {FL} and Spriesterback, {DC}},
	urldate = {2023-09-08},
	date = {1978},
	file = {Diagnostic methods in speech pathology | CiNii Research:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\7U6SY9Q2\\1130000793933255936.html:text/html},
}

@article{kent_maximum_1987,
	title = {Maximum Performance Tests of Speech Production},
	volume = {52},
	url = {https://pubs.asha.org/doi/abs/10.1044/jshd.5204.367},
	doi = {10.1044/jshd.5204.367},
	abstract = {The maximum performance tests of speech production are those tests that examine the upper limits of performance for selected speech tasks. Among the most commonly used maximum performance tests are the following: maximum duration of phonation, maximum fricative duration, maximum phonation volume, maximum expiratory pressure, fundamental frequency range, maximum sound pressure level, maximum occluding force of the articulators, and diadochokinetic (maximum repetition) rate. Many clinicians use at least some of these tasks as part of an assessment protocol. These tests are analogous to strength, range, or speed tests in clinical neurology. Given the widespread use of these tests and a rather scattered literature on normative values obtained for them, a survey of the data base seemed in order. This paper summarizes the published normative data, discusses the adequacy of these data for clinical application, and recommends interpretive guidelines to enhance the usefulness of maximum performance tests.},
	pages = {367--387},
	number = {4},
	journaltitle = {Journal of Speech and Hearing Disorders},
	author = {Kent, Ray D. and Kent, Jane F. and Rosenbek, John C.},
	urldate = {2023-09-08},
	date = {1987-11},
	note = {Publisher: American Speech-Language-Hearing Association},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\9HIAUAJK\\Kent et al. - 1987 - Maximum Performance Tests of Speech Production.pdf:application/pdf},
}

@article{pierce_alternating_2013,
	title = {Alternating and sequential motion rates in older adults},
	volume = {48},
	rights = {© 2013 Royal College of Speech and Language Therapists},
	issn = {1460-6984},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1460-6984.12001},
	doi = {10.1111/1460-6984.12001},
	abstract = {Background Alternating motion rate ({AMR}) and sequential motion rate ({SMR}) are tests of articulatory diadochokinesis that are widely used in the evaluation of motor speech. However, there are no quality normative data available for adults aged 65 years and older. Aims There were two aims: (1) to obtain a representative, normative dataset of diadochokinetic rates from adults aged 65 years and older; and (2) to examine the effects of age and gender on those rates. Methods \& Procedures Seventy-six healthy adults (65–86 years) were recruited; 45 females and 31 males. Participants were divided across two age groups (65–74 and 75–86 years) and audio-recorded while undertaking {AMR} (/pa/, /ta/ and /ka/) and {SMR} (/pataka/). The rate of the first nine syllables for each task was measured using acoustic analysis software, and age and gender effects were examined using a series of generalized linear models. The effect of age on rate variability between groups was also assessed. Outcomes \& Results Normative data were obtained for both age groups and across gender. Age was not a significant factor for any task. Males had significantly higher {AMR} than females (/pa/ p = 0.001, /ta/ p = 0.001, /ka/ p = 0.010). No such gender difference was found for {SMR}. There was no significant difference in rate variability between the age groups. Conclusions \& Implications Normative values for {AMR} and {SMR} in both genders and across two older age groups were acquired. Diadochokinetic rates outside such values cannot be attributed to normal ageing, so will merit further clinical investigation.},
	pages = {257--264},
	number = {3},
	journaltitle = {International Journal of Language \& Communication Disorders},
	author = {Pierce, John E. and Cotton, Susan and Perry, Alison},
	urldate = {2023-09-08},
	date = {2013},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1460-6984.12001},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\QZGFWAMF\\Pierce et al. - 2013 - Alternating and sequential motion rates in older a.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\2FLH3V4M\\1460-6984.html:text/html},
}

@article{branco_gridloc_2018,
	title = {{GridLoc}: An automatic and unsupervised localization method for high-density {ECoG} grids},
	volume = {179},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811918305573},
	doi = {10.1016/j.neuroimage.2018.06.050},
	shorttitle = {{GridLoc}},
	abstract = {Precise localization of electrodes is essential in the field of high-density ({HD}) electrocorticography ({ECoG}) brain signal analysis in order to accurately interpret the recorded activity in relation to functional anatomy. Current localization methods for subchronically implanted {HD} electrode grids involve post-operative imaging. However, for situations where post-operative imaging is not available, such as during acute measurements in awake surgery, electrode localization is complicated. Intra-operative photographs may be informative, but not for electrode grids positioned partially or fully under the skull. Here we present an automatic and unsupervised method to localize {HD} electrode grids that does not require post-operative imaging. The localization method, named {GridLoc}, is based on the hypothesis that the anatomical and vascular brain structures under the {ECoG} electrodes have an effect on the amplitude of the recorded {ECoG} signal. More specifically, we hypothesize that the spatial match between resting-state high-frequency band power (45–120 Hz) patterns over the grid and the anatomical features of the brain under the electrodes, such as the presence of sulci and larger blood vessels, can be used for adequate {HD} grid localization. We validate this hypothesis and compare the {GridLoc} results with electrode locations determined with post-operative imaging and/or photographs in 8 patients implanted with {HD}-{ECoG} grids. Locations agreed with an average difference of 1.94 ± 0.11 mm, which is comparable to differences reported earlier between post-operative imaging and photograph methods. The results suggest that resting-state high-frequency band activity can be used for accurate localization of {HD} grid electrodes on a pre-operative {MRI} scan and that {GridLoc} provides a convenient alternative to methods that rely on post-operative imaging or intra-operative photographs.},
	pages = {225--234},
	journaltitle = {{NeuroImage}},
	shortjournal = {{NeuroImage}},
	author = {Branco, Mariana P. and Leibbrand, Michael and Vansteensel, Mariska J. and Freudenburg, Zachary V. and Ramsey, Nick F.},
	urldate = {2023-09-14},
	date = {2018-10-01},
	keywords = {Electrocorticography, Angiogram, Cortical distance, Electrode localization, High-density, High-frequency band, Resting-state, Unsupervised},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\HAHMIXRI\\Branco et al. - 2018 - GridLoc An automatic and unsupervised localizatio.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\MAVYK2XL\\S1053811918305573.html:text/html},
}

@article{jensen_motor_2023,
	title = {A motor association area in the depths of the central sulcus},
	volume = {26},
	rights = {2023 The Author(s)},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-023-01346-z},
	doi = {10.1038/s41593-023-01346-z},
	abstract = {Cells in the precentral gyrus directly send signals to the periphery to generate movement and are principally organized as a topological map of the body. We find that movement-induced electrophysiological responses from depth electrodes extend this map three-dimensionally throughout the gyrus. Unexpectedly, this organization is interrupted by a previously undescribed motor association area in the depths of the midlateral aspect of the central sulcus. This ‘Rolandic motor association’ ({RMA}) area is active during movements of different body parts from both sides of the body and may be important for coordinating complex behaviors.},
	pages = {1165--1169},
	number = {7},
	journaltitle = {Nature Neuroscience},
	shortjournal = {Nat Neurosci},
	author = {Jensen, Michael A. and Huang, Harvey and Valencia, Gabriela Ojeda and Klassen, Bryan T. and van den Boom, Max A. and Kaufmann, Timothy J. and Schalk, Gerwin and Brunner, Peter and Worrell, Gregory A. and Hermes, Dora and Miller, Kai J.},
	urldate = {2023-09-15},
	date = {2023-07},
	langid = {english},
	note = {Number: 7
Publisher: Nature Publishing Group},
	keywords = {Motor cortex, Sensorimotor processing, Motor control},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\E9XNSW8R\\Jensen et al. - 2023 - A motor association area in the depths of the cent.pdf:application/pdf},
}

@article{wolpaw_independent_2018,
	title = {Independent home use of a brain-computer interface by people with amyotrophic lateral sclerosis},
	volume = {91},
	rights = {© 2018 American Academy of Neurology},
	issn = {0028-3878, 1526-632X},
	url = {https://n.neurology.org/content/91/3/e258},
	doi = {10.1212/WNL.0000000000005812},
	abstract = {Objective To assess the reliability and usefulness of an {EEG}-based brain-computer interface ({BCI}) for patients with advanced amyotrophic lateral sclerosis ({ALS}) who used it independently at home for up to 18 months.
Methods Of 42 patients consented, 39 (93\%) met the study criteria, and 37 (88\%) were assessed for use of the Wadsworth {BCI}. Nine (21\%) could not use the {BCI}. Of the other 28, 27 (men, age 28–79 years) (64\%) had the {BCI} placed in their homes, and they and their caregivers were trained to use it. Use data were collected by Internet. Periodic visits evaluated {BCI} benefit and burden and quality of life.
Results Over subsequent months, 12 (29\% of the original 42) left the study because of death or rapid disease progression and 6 (14\%) left because of decreased interest. Fourteen (33\%) completed training and used the {BCI} independently, mainly for communication. Technical problems were rare. Patient and caregiver ratings indicated that {BCI} benefit exceeded burden. Quality of life remained stable. Of those not lost to the disease, half completed the study; all but 1 patient kept the {BCI} for further use.
Conclusion The Wadsworth {BCI} home system can function reliably and usefully when operated by patients in their homes. {BCIs} that support communication are at present most suitable for people who are severely disabled but are otherwise in stable health. Improvements in {BCI} convenience and performance, including some now underway, should increase the number of people who find them useful and the extent to which they are used.},
	pages = {e258--e267},
	number = {3},
	journaltitle = {Neurology},
	author = {Wolpaw, Jonathan R. and Bedlack, Richard S. and Reda, Domenic J. and Ringer, Robert J. and Banks, Patricia G. and Vaughan, Theresa M. and Heckman, Susan M. and {McCane}, Lynn M. and Carmack, Charles S. and Winden, Stefan and {McFarland}, Dennis J. and Sellers, Eric W. and Shi, Hairong and Paine, Tamara and Higgins, Donald S. and Lo, Albert C. and Patwa, Huned S. and Hill, Katherine J. and Huang, Grant D. and Ruff, Robert L.},
	urldate = {2023-09-19},
	date = {2018-07-17},
	langid = {english},
	pmid = {29950436},
	note = {Publisher: Wolters Kluwer Health, Inc. on behalf of the American Academy of Neurology
Section: Article},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\8STFIDYL\\Wolpaw et al. - 2018 - Independent home use of a brain-computer interface.pdf:application/pdf;Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\CERIVQC2\\Wolpaw et al. - 2018 - Independent home use of a brain-computer interface.pdf:application/pdf},
}

@article{herff_generating_2019,
	title = {Generating Natural, Intelligible Speech From Brain Activity in Motor, Premotor, and Inferior Frontal Cortices},
	volume = {13},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2019.01267},
	abstract = {Neural interfaces that directly produce intelligible speech from brain activity would allow people with severe impairment from neurological disorders to communicate more naturally. Here, we record neural population activity in motor, premotor and inferior frontal cortices during speech production using electrocorticography ({ECoG}) and show that {ECoG} signals alone can be used to generate intelligible speech output that can preserve conversational cues. To produce speech directly from neural data, we adapted a method from the field of speech synthesis called unit selection, in which units of speech are concatenated to form audible output. In our approach, which we call Brain-To-Speech, we chose subsequent units of speech based on the measured {ECoG} activity to generate audio waveforms directly from the neural recordings. Brain-To-Speech employed the user's own voice to generate speech that sounded very natural and included features such as prosody and accentuation. By investigating the brain areas involved in speech production separately, we found that speech motor cortex provided more information for the reconstruction process than the other cortical areas.},
	pages = {1267},
	journaltitle = {Frontiers in Neuroscience},
	author = {Herff, Christian and Diener, Lorenz and Angrick, Miguel and Mugler, Emily and Tate, Matthew C. and Goldrick, Matthew A. and Krusienski, Dean J. and Slutzky, Marc W. and Schultz, Tanja},
	urldate = {2023-09-26},
	date = {2019},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\DM6M8HHG\\Herff et al. - 2019 - Generating Natural, Intelligible Speech From Brain.pdf:application/pdf},
}

@article{herff_brain--text_2015,
	title = {Brain-to-text: decoding spoken phrases from phone representations in the brain},
	volume = {8},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2015.00217},
	shorttitle = {Brain-to-text},
	abstract = {It has long been speculated whether communication between humans and machines based on natural speech related cortical activity is possible. Over the past decade, studies have suggested that it is feasible to recognize isolated aspects of speech from neural signals, such as auditory features, phones or one of a few isolated words. However, until now it remained an unsolved challenge to decode continuously spoken speech from the neural substrate associated with speech and language processing. Here, we show for the first time that continuously spoken speech can be decoded into the expressed words from intracranial electrocorticographic ({ECoG}) recordings.Specifically, we implemented a system, which we call Brain-To-Text that models single phones, employs techniques from automatic speech recognition ({ASR}), and thereby transforms brain activity while speaking into the corresponding textual representation. Our results demonstrate that our system can achieve word error rates as low as 25\% and phone error rates below 50\%. Additionally, our approach contributes to the current understanding of the neural basis of continuous speech production by identifying those cortical regions that hold substantial information about individual phones. In conclusion, the Brain-To-Text system described in this paper represents an important step toward human-machine communication based on imagined speech.},
	journaltitle = {Frontiers in Neuroscience},
	author = {Herff, Christian and Heger, Dominic and de Pesters, Adriana and Telaar, Dominic and Brunner, Peter and Schalk, Gerwin and Schultz, Tanja},
	urldate = {2023-09-26},
	date = {2015},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\97N3L76K\\Herff et al. - 2015 - Brain-to-text decoding spoken phrases from phone .pdf:application/pdf},
}

@article{chao_long-term_2010,
	title = {Long-term asynchronous decoding of arm motion using electrocorticographic signals in monkey},
	volume = {3},
	issn = {1662-6443},
	url = {https://www.frontiersin.org/articles/10.3389/fneng.2010.00003},
	abstract = {Brain–machine interfaces ({BMIs}) employ the electrical activity generated by cortical neurons directly for controlling external devices and have been conceived as a means for restoring human cognitive or sensory-motor functions. The dominant approach in {BMI} research has been to decode motor variables based on single-unit activity ({SUA}). Unfortunately, this approach suffers from poor long-term stability and daily recalibration is normally required to maintain reliable performance. A possible alternative is {BMIs} based on electrocorticograms ({ECoGs}), which measure population activity and may provide more durable and stable recording. However, the level of long-term stability that {ECoG}-based decoding can offer remains unclear. Here we propose a novel {ECoG}-based decoding paradigm and show that we have successfully decoded hand positions and arm joint angles during an asynchronous food-reaching task in monkeys when explicit cues prompting the onset of movement were not required. Performance using our {ECoG}-based decoder was comparable to existing {SUA}-based systems while evincing far superior stability and durability. In addition, the same decoder could be used for months without any drift in accuracy or recalibration. These results were achieved by incorporating the spatio-spectro-temporal integration of activity across multiple cortical areas to compensate for the lower fidelity of {ECoG} signals. These results show the feasibility of high-performance, chronic and versatile {ECoG}-based neuroprosthetic devices for real-life applications. This new method provides a stable platform for investigating cortical correlates for understanding motor control, sensory perception, and high-level cognitive processes.},
	pages = {3},
	journaltitle = {Frontiers in Neuroengineering},
	author = {Chao, Zenas and Nagasaka, Yasuo and Fujii, Naotaka},
	urldate = {2023-09-26},
	date = {2010},
	keywords = {Decoding, {ECoG}, brain-machine interface, Arm, asynchronous, {BMI}, electrocorticogram, Long-term},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\39NP3SAI\\Chao et al. - 2010 - Long-term asynchronous decoding of arm motion usin.pdf:application/pdf},
}

@book{hintjens_zeromq_2013,
	title = {{ZeroMQ}: Messaging for Many Applications},
	isbn = {978-1-4493-3444-4},
	shorttitle = {{ZeroMQ}},
	abstract = {Dive into Ø{MQ} (aka {ZeroMQ}), the smart socket library that gives you fast, easy, message-based concurrency for your applications. With this quick-paced guide, you’ll learn hands-on how to use this scalable, lightweight, and highly flexible networking tool for exchanging messages among clusters, the cloud, and other multi-system environments.Ø{MQ} maintainer Pieter Hintjens takes you on a tour of real-world applications, using extended examples in C to help you work with Ø{MQ}’s {API}, sockets, and patterns. Learn how to use specific Ø{MQ} programming techniques, build multithreaded applications, and create your own messaging architectures. You’ll discover how Ø{MQ} works with several programming languages and most operating systems—with little or no cost.Learn Ø{MQ}’s main patterns: request-reply, publish-subscribe, and {pipelineWork} with Ø{MQ} sockets and patterns by building several small {applicationsExplore} advanced uses of Ø{MQ}’s request-reply pattern through working {examplesBuild} reliable request-reply patterns that keep working when code or hardware {failsExtend} Ø{MQ}’s core pub-sub patterns for performance, reliability, state distribution, and {monitoringLearn} techniques for building a distributed architecture with Ø{MQDiscover} what’s required to build a general-purpose framework for distributed applications},
	pagetotal = {516},
	publisher = {O'Reilly Media, Inc.},
	author = {Hintjens, Pieter},
	date = {2013-03-12},
	langid = {english},
	note = {Google-Books-{ID}: {TxHgtl}\_sFmgC},
	keywords = {Computers / Internet / Web Services \& {APIs}, Computers / Languages / C},
}

@article{willett_high-performance_2023,
	title = {A high-performance speech neuroprosthesis},
	volume = {620},
	rights = {2023 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-023-06377-x},
	doi = {10.1038/s41586-023-06377-x},
	abstract = {Speech brain–computer interfaces ({BCIs}) have the potential to restore rapid communication to people with paralysis by decoding neural activity evoked by attempted speech into text1,2 or sound3,4. Early demonstrations, although promising, have not yet achieved accuracies sufficiently high for communication of unconstrained sentences from a large vocabulary1–7. Here we demonstrate a speech-to-text {BCI} that records spiking activity from intracortical microelectrode arrays. Enabled by these high-resolution recordings, our study participant—who can no longer speak intelligibly owing to amyotrophic lateral sclerosis—achieved a 9.1\% word error rate on a 50-word vocabulary (2.7 times fewer errors than the previous state-of-the-art speech {BCI}2) and a 23.8\% word error rate on a 125,000-word vocabulary (the first successful demonstration, to our knowledge, of large-vocabulary decoding). Our participant’s attempted speech was decoded  at 62 words per minute, which is 3.4 times as fast as the previous record8 and begins to approach the speed of natural conversation (160 words per minute9). Finally, we highlight two aspects of the neural code for speech that are encouraging for speech {BCIs}: spatially intermixed tuning to speech articulators that makes accurate decoding possible from only a small region of cortex, and a detailed articulatory representation of phonemes that persists years after paralysis. These results show a feasible path forward for restoring rapid communication to people with paralysis who can no longer speak.},
	pages = {1031--1036},
	number = {7976},
	journaltitle = {Nature},
	author = {Willett, Francis R. and Kunz, Erin M. and Fan, Chaofei and Avansino, Donald T. and Wilson, Guy H. and Choi, Eun Young and Kamdar, Foram and Glasser, Matthew F. and Hochberg, Leigh R. and Druckmann, Shaul and Shenoy, Krishna V. and Henderson, Jaimie M.},
	urldate = {2023-09-26},
	date = {2023-08},
	langid = {english},
	note = {Number: 7976
Publisher: Nature Publishing Group},
	keywords = {Neural decoding, Brain–machine interface},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\7RRA6QF9\\Willett et al. - 2023 - A high-performance speech neuroprosthesis.pdf:application/pdf},
}

@article{metzger_high-performance_2023,
	title = {A high-performance neuroprosthesis for speech decoding and avatar control},
	volume = {620},
	rights = {2023 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-023-06443-4},
	doi = {10.1038/s41586-023-06443-4},
	abstract = {Speech neuroprostheses have the potential to restore communication to people living with paralysis, but naturalistic speed and expressivity are elusive1. Here we use high-density surface recordings of the speech cortex in a clinical-trial participant with severe limb and vocal paralysis to achieve high-performance real-time decoding across three complementary speech-related output modalities: text, speech audio and facial-avatar animation. We trained and evaluated deep-learning models using neural data collected as the participant attempted to silently speak sentences. For text, we demonstrate accurate and rapid large-vocabulary decoding with a median rate of 78 words per minute and median word error rate of 25\%. For speech audio, we demonstrate intelligible and rapid speech synthesis and personalization to the participant’s pre-injury voice. For facial-avatar animation, we demonstrate the control of virtual orofacial movements for speech and non-speech communicative gestures. The decoders reached high performance with less than two weeks of training. Our findings introduce a multimodal speech-neuroprosthetic approach that has substantial promise to restore full, embodied communication to people living with severe paralysis.},
	pages = {1037--1046},
	number = {7976},
	journaltitle = {Nature},
	author = {Metzger, Sean L. and Littlejohn, Kaylo T. and Silva, Alexander B. and Moses, David A. and Seaton, Margaret P. and Wang, Ran and Dougherty, Maximilian E. and Liu, Jessie R. and Wu, Peter and Berger, Michael A. and Zhuravleva, Inga and Tu-Chan, Adelyn and Ganguly, Karunesh and Anumanchipalli, Gopala K. and Chang, Edward F.},
	urldate = {2023-09-26},
	date = {2023-08},
	langid = {english},
	note = {Number: 7976
Publisher: Nature Publishing Group},
	keywords = {Stroke, Brain–machine interface, Motor cortex, Electrical and electronic engineering, Neurophysiology},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\4GED4KHJ\\Metzger et al. - 2023 - A high-performance neuroprosthesis for speech deco.pdf:application/pdf},
}

@article{flesher_intracortical_2016,
	title = {Intracortical microstimulation of human somatosensory cortex},
	volume = {8},
	url = {https://www.science.org/doi/full/10.1126/scitranslmed.aaf8083},
	doi = {10.1126/scitranslmed.aaf8083},
	abstract = {Intracortical microstimulation of the somatosensory cortex offers the potential for creating a sensory neuroprosthesis to restore tactile sensation. Whereas animal studies have suggested that both cutaneous and proprioceptive percepts can be evoked using this approach, the perceptual quality of the stimuli cannot be measured in these experiments. We show that microstimulation within the hand area of the somatosensory cortex of a person with long-term spinal cord injury evokes tactile sensations perceived as originating from locations on the hand and that cortical stimulation sites are organized according to expected somatotopic principles. Many of these percepts exhibit naturalistic characteristics (including feelings of pressure), can be evoked at low stimulation amplitudes, and remain stable for months. Further, modulating the stimulus amplitude grades the perceptual intensity of the stimuli, suggesting that intracortical microstimulation could be used to convey information about the contact location and pressure necessary to perform dexterous hand movements associated with object manipulation.},
	pages = {361ra141--361ra141},
	number = {361},
	journaltitle = {Science Translational Medicine},
	author = {Flesher, Sharlene N. and Collinger, Jennifer L. and Foldes, Stephen T. and Weiss, Jeffrey M. and Downey, John E. and Tyler-Kabara, Elizabeth C. and Bensmaia, Sliman J. and Schwartz, Andrew B. and Boninger, Michael L. and Gaunt, Robert A.},
	urldate = {2023-09-26},
	date = {2016-10-19},
	note = {Publisher: American Association for the Advancement of Science},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\EZUXYGUY\\Flesher et al. - 2016 - Intracortical microstimulation of human somatosens.pdf:application/pdf},
}

@article{flesher_brain-computer_2021,
	title = {A brain-computer interface that evokes tactile sensations improves robotic arm control},
	volume = {372},
	url = {https://www.science.org/doi/10.1126/science.abd0380},
	doi = {10.1126/science.abd0380},
	abstract = {Prosthetic arms controlled by a brain-computer interface can enable people with tetraplegia to perform functional movements. However, vision provides limited feedback because information about grasping objects is best relayed through tactile feedback. We supplemented vision with tactile percepts evoked using a bidirectional brain-computer interface that records neural activity from the motor cortex and generates tactile sensations through intracortical microstimulation of the somatosensory cortex. This enabled a person with tetraplegia to substantially improve performance with a robotic limb; trial times on a clinical upper-limb assessment were reduced by half, from a median time of 20.9 to 10.2 seconds. Faster times were primarily due to less time spent attempting to grasp objects, revealing that mimicking known biological control principles results in task performance that is closer to able-bodied human abilities.},
	pages = {831--836},
	number = {6544},
	journaltitle = {Science},
	author = {Flesher, Sharlene N. and Downey, John E. and Weiss, Jeffrey M. and Hughes, Christopher L. and Herrera, Angelica J. and Tyler-Kabara, Elizabeth C. and Boninger, Michael L. and Collinger, Jennifer L. and Gaunt, Robert A.},
	urldate = {2023-09-26},
	date = {2021-05-21},
	note = {Publisher: American Association for the Advancement of Science},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\W4KSQDEN\\Flesher et al. - 2021 - A brain-computer interface that evokes tactile sen.pdf:application/pdf},
}

@article{downey_intracortical_2018,
	title = {Intracortical recording stability in human brain–computer interface users},
	volume = {15},
	issn = {1741-2552},
	url = {https://dx.doi.org/10.1088/1741-2552/aab7a0},
	doi = {10.1088/1741-2552/aab7a0},
	abstract = {Objective. Intracortical brain–computer interfaces ({BCIs}) are being developed to assist people with motor disabilities in communicating and interacting with the world around them. This technology relies on recordings from the primary motor cortex, which may vary from day to day. Approach. Here we quantify, in two long-term {BCI} subjects, the length of time that action potentials from the same neuron, or group of neurons, can be recorded from the motor cortex. Main results. These action potentials are identified by their extracellular waveforms and may change within a single day, although some of these identified units can be identified consistently for weeks and even months. Features of the extracellular waveforms allowed us to predict whether a specific unit was more or less likely to remain stable over a prolonged period. Significance. A greater understanding of unit stability and instability can aid the development of motor {BCIs}, where the goal is to maintain a high level of performance despite changes in the recorded population. {BCIs} should be able to be operated without technician intervention for hours, and hopefully days, to provide the most benefit to the end-users of this technology.},
	pages = {046016},
	number = {4},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Downey, John E. and Schwed, Nathaniel and Chase, Steven M. and Schwartz, Andrew B. and Collinger, Jennifer L.},
	urldate = {2023-09-26},
	date = {2018-05},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\375F3FFF\\Downey et al. - 2018 - Intracortical recording stability in human brain–c.pdf:application/pdf},
}

@article{chestek_long-term_2011,
	title = {Long-term stability of neural prosthetic control signals from silicon cortical arrays in rhesus macaque motor cortex},
	volume = {8},
	issn = {1741-2552},
	url = {https://dx.doi.org/10.1088/1741-2560/8/4/045005},
	doi = {10.1088/1741-2560/8/4/045005},
	abstract = {Cortically-controlled prosthetic systems aim to help disabled patients by translating neural signals from the brain into control signals for guiding prosthetic devices. Recent reports have demonstrated reasonably high levels of performance and control of computer cursors and prosthetic limbs, but to achieve true clinical viability, the long-term operation of these systems must be better understood. In particular, the quality and stability of the electrically-recorded neural signals require further characterization. Here, we quantify action potential changes and offline neural decoder performance over 382 days of recording from four intracortical arrays in three animals. Action potential amplitude decreased by 2.4\% per month on average over the course of 9.4, 10.4, and 31.7 months in three animals. During most time periods, decoder performance was not well correlated with action potential amplitude (p {\textgreater} 0.05 for three of four arrays). In two arrays from one animal, action potential amplitude declined by an average of 37\% over the first 2 months after implant. However, when using simple threshold-crossing events rather than well-isolated action potentials, no corresponding performance loss was observed during this time using an offline decoder. One of these arrays was effectively used for online prosthetic experiments over the following year. Substantial short-term variations in waveforms were quantified using a wireless system for contiguous recording in one animal, and compared within and between days for all three animals. Overall, this study suggests that action potential amplitude declines more slowly than previously supposed, and performance can be maintained over the course of multiple years when decoding from threshold-crossing events rather than isolated action potentials. This suggests that neural prosthetic systems may provide high performance over multiple years in human clinical trials.},
	pages = {045005},
	number = {4},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Chestek, Cynthia A. and Gilja, Vikash and Nuyujukian, Paul and Foster, Justin D. and Fan, Joline M. and Kaufman, Matthew T. and Churchland, Mark M. and Rivera-Alvidrez, Zuley and Cunningham, John P. and Ryu, Stephen I. and Shenoy, Krishna V.},
	urldate = {2023-10-05},
	date = {2011-07},
	langid = {english},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\AN6TWZPB\\Chestek et al. - 2011 - Long-term stability of neural prosthetic control s.pdf:application/pdf},
}

@article{khanna_neural_2015,
	title = {Neural oscillations: beta band activity across motor networks},
	volume = {32},
	issn = {0959-4388},
	url = {https://www.sciencedirect.com/science/article/pii/S0959438814002360},
	doi = {10.1016/j.conb.2014.11.010},
	series = {Large-Scale Recording Technology (32)},
	shorttitle = {Neural oscillations},
	abstract = {Local field potential ({LFP}) activity in motor cortical and basal ganglia regions exhibits prominent beta (15–40Hz) oscillations during reaching and grasping, muscular contraction, and attention tasks. While in vitro and computational work has revealed specific mechanisms that may give rise to the frequency and duration of this oscillation, there is still controversy about what behavioral processes ultimately drive it. Here, simultaneous behavioral and large-scale neural recording experiments from non-human primate and human subjects are reviewed in the context of specific hypotheses about how beta band activity is generated. Finally, a new experimental paradigm utilizing operant conditioning combined with motor tasks is proposed as a way to further investigate this oscillation.},
	pages = {60--67},
	journaltitle = {Current Opinion in Neurobiology},
	shortjournal = {Current Opinion in Neurobiology},
	author = {Khanna, Preeya and Carmena, Jose M},
	urldate = {2023-10-05},
	date = {2015-06-01},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\DIIZQUG7\\Khanna and Carmena - 2015 - Neural oscillations beta band activity across mot.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\HUVWU2RW\\S0959438814002360.html:text/html;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\I2NMWIYK\\S0959438814002360.html:text/html},
}

@article{khanna_beta_2017,
	title = {Beta band oscillations in motor cortex reflect neural population signals that delay movement onset},
	volume = {6},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.24573},
	doi = {10.7554/eLife.24573},
	abstract = {Motor cortical beta oscillations have been reported for decades, yet their behavioral correlates remain unresolved. Some studies link beta oscillations to changes in underlying neural activity, but the specific behavioral manifestations of these reported changes remain elusive. To investigate how changes in population neural activity, beta oscillations, and behavior are linked, we recorded multi-scale neural activity from motor cortex while three macaques performed a novel neurofeedback task. Subjects volitionally brought their beta oscillatory power to an instructed state and subsequently executed an arm reach. Reaches preceded by a reduction in beta power exhibited significantly faster movement onset times than reaches preceded by an increase in beta power. Further, population neural activity was found to shift farther from a movement onset state during beta oscillations that were neurofeedback-induced or naturally occurring during reaching tasks. This finding establishes a population neural basis for slowed movement onset following periods of beta oscillatory activity.},
	pages = {e24573},
	journaltitle = {{eLife}},
	author = {Khanna, Preeya and Carmena, Jose M},
	editor = {Fries, Pascal},
	urldate = {2023-10-05},
	date = {2017-05-03},
	note = {Publisher: {eLife} Sciences Publications, Ltd},
	keywords = {beta oscillation, movement, neuroscience},
	file = {Full Text:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\Y5K3MR6Y\\Khanna and Carmena - 2017 - Beta band oscillations in motor cortex reflect neu.pdf:application/pdf},
}

@article{chaudhary_spelling_2022,
	title = {Spelling interface using intracortical signals in a completely locked-in patient enabled via auditory neurofeedback training},
	volume = {13},
	rights = {2022 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-022-28859-8},
	doi = {10.1038/s41467-022-28859-8},
	abstract = {Patients with amyotrophic lateral sclerosis ({ALS}) can lose all muscle-based routes of communication as motor neuron degeneration progresses, and ultimately, they may be left without any means of communication. While others have evaluated communication in people with remaining muscle control, to the best of our knowledge, it is not known whether neural-based communication remains possible in a completely locked-in state. Here, we implanted two 64 microelectrode arrays in the supplementary and primary motor cortex of a patient in a completely locked-in state with {ALS}. The patient modulated neural firing rates based on auditory feedback and he used this strategy to select letters one at a time to form words and phrases to communicate his needs and experiences. This case study provides evidence that brain-based volitional communication is possible even in a completely locked-in state.},
	pages = {1236},
	number = {1},
	journaltitle = {Nature Communications},
	shortjournal = {Nat Commun},
	author = {Chaudhary, Ujwal and Vlachos, Ioannis and Zimmermann, Jonas B. and Espinosa, Arnau and Tonin, Alessandro and Jaramillo-Gonzalez, Andres and Khalili-Ardali, Majid and Topka, Helge and Lehmberg, Jens and Friehs, Gerhard M. and Woodtli, Alain and Donoghue, John P. and Birbaumer, Niels},
	urldate = {2023-10-10},
	date = {2022-03-22},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Amyotrophic lateral sclerosis, Quality of life, Single-channel recording},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\9S3VI3K8\\Chaudhary et al. - 2022 - Spelling interface using intracortical signals in .pdf:application/pdf},
}

@article{masina_investigating_2020,
	title = {Investigating the Accessibility of Voice Assistants With Impaired Users: Mixed Methods Study},
	volume = {22},
	issn = {1439-4456},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7547392/},
	doi = {10.2196/18431},
	shorttitle = {Investigating the Accessibility of Voice Assistants With Impaired Users},
	abstract = {Background
Voice assistants allow users to control appliances and functions of a smart home by simply uttering a few words. Such systems hold the potential to significantly help users with motor and cognitive disabilities who currently depend on their caregiver even for basic needs (eg, opening a door). The research on voice assistants is mainly dedicated to able-bodied users, and studies evaluating the accessibility of such systems are still sparse and fail to account for the participants’ actual motor, linguistic, and cognitive abilities.

Objective
The aim of this work is to investigate whether cognitive and/or linguistic functions could predict user performance in operating an off-the-shelf voice assistant (Google Home).

Methods
A group of users with disabilities (n=16) was invited to a living laboratory and asked to interact with the system. Besides collecting data on their performance and experience with the system, their cognitive and linguistic skills were assessed using standardized inventories. The identification of predictors (cognitive and/or linguistic) capable of accounting for an efficient interaction with the voice assistant was investigated by performing multiple linear regression models. The best model was identified by adopting a selection strategy based on the Akaike information criterion ({AIC}).

Results
For users with disabilities, the effectiveness of interacting with a voice assistant is predicted by the Mini-Mental State Examination ({MMSE}) and the Robertson Dysarthria Profile (specifically, the ability to repeat sentences), as the best model shows ({AIC}=130.11).

Conclusions
Users with motor, linguistic, and cognitive impairments can effectively interact with voice assistants, given specific levels of residual cognitive and linguistic skills. More specifically, our paper advances practical indicators to predict the level of accessibility of speech-based interactive systems. Finally, accessibility design guidelines are introduced based on the performance results observed in users with disabilities.},
	pages = {e18431},
	number = {9},
	journaltitle = {Journal of Medical Internet Research},
	shortjournal = {J Med Internet Res},
	author = {Masina, Fabio and Orso, Valeria and Pluchino, Patrik and Dainese, Giulia and Volpato, Stefania and Nelini, Cristian and Mapelli, Daniela and Spagnolli, Anna and Gamberini, Luciano},
	urldate = {2023-10-10},
	date = {2020-09-25},
	pmid = {32975525},
	pmcid = {PMC7547392},
	file = {Full Text:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\UQNL8YT6\\Masina et al. - 2020 - Investigating the Accessibility of Voice Assistant.pdf:application/pdf},
}

@inproceedings{pradhan_accessibility_2018,
	location = {New York, {NY}, {USA}},
	title = {"Accessibility Came by Accident": Use of Voice-Controlled Intelligent Personal Assistants by People with Disabilities},
	isbn = {978-1-4503-5620-6},
	url = {https://dl.acm.org/doi/10.1145/3173574.3174033},
	doi = {10.1145/3173574.3174033},
	series = {{CHI} '18},
	shorttitle = {"Accessibility Came by Accident"},
	abstract = {From an accessibility perspective, voice-controlled, home-based intelligent personal assistants ({IPAs}) have the potential to greatly expand speech interaction beyond dictation and screen reader output. To examine the accessibility of off-the-shelf {IPAs} (e.g., Amazon Echo) and to understand how users with disabilities are making use of these devices, we conducted two exploratory studies. The first, broader study is a content analysis of 346 Amazon Echo reviews that include users with disabilities, while the second study more specifically focuses on users with visual impairments, through interviews with 16 current users of home-based {IPAs}. Findings show that, although some accessibility challenges exist, users with a range of disabilities are using the Amazon Echo, including for unexpected cases such as speech therapy and support for caregivers. Richer voice-based applications and solutions to support discoverability would be particularly useful to users with visual impairments. These findings should inform future work on accessible voice-based {IPAs}.},
	pages = {1--13},
	booktitle = {Proceedings of the 2018 {CHI} Conference on Human Factors in Computing Systems},
	publisher = {Association for Computing Machinery},
	author = {Pradhan, Alisha and Mehta, Kanika and Findlater, Leah},
	urldate = {2023-10-10},
	date = {2018-04-21},
	keywords = {speech, accessibility, conversational interfaces, disability, intelligent personal assistants},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\JB9IWS29\\Pradhan et al. - 2018 - Accessibility Came by Accident Use of Voice-Con.pdf:application/pdf},
}

@article{sahel_partial_2021,
	title = {Partial recovery of visual function in a blind patient after optogenetic therapy},
	volume = {27},
	rights = {2021 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-170X},
	url = {https://www.nature.com/articles/s41591-021-01351-4},
	doi = {10.1038/s41591-021-01351-4},
	abstract = {Optogenetics may enable mutation-independent, circuit-specific restoration of neuronal function in neurological diseases. Retinitis pigmentosa is a neurodegenerative eye disease where loss of photoreceptors can lead to complete blindness. In a blind patient, we combined intraocular injection of an adeno-associated viral vector encoding {ChrimsonR} with light stimulation via engineered goggles. The goggles detect local changes in light intensity and project corresponding light pulses onto the retina in real time to activate optogenetically transduced retinal ganglion cells. The patient perceived, located, counted and touched different objects using the vector-treated eye alone while wearing the goggles. During visual perception, multichannel electroencephalographic recordings revealed object-related activity above the visual cortex. The patient could not visually detect any objects before injection with or without the goggles or after injection without the goggles. This is the first reported case of partial functional recovery in a neurodegenerative disease after optogenetic therapy.},
	pages = {1223--1229},
	number = {7},
	journaltitle = {Nature Medicine},
	shortjournal = {Nat Med},
	author = {Sahel, José-Alain and Boulanger-Scemama, Elise and Pagot, Chloé and Arleo, Angelo and Galluppi, Francesco and Martel, Joseph N. and Esposti, Simona Degli and Delaux, Alexandre and de Saint Aubert, Jean-Baptiste and de Montleau, Caroline and Gutman, Emmanuel and Audo, Isabelle and Duebel, Jens and Picaud, Serge and Dalkara, Deniz and Blouin, Laure and Taiel, Magali and Roska, Botond},
	urldate = {2023-10-12},
	date = {2021-07},
	langid = {english},
	note = {Number: 7
Publisher: Nature Publishing Group},
	keywords = {Translational research, Visual system},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\GTF3H6PR\\Sahel et al. - 2021 - Partial recovery of visual function in a blind pat.pdf:application/pdf},
}

@article{sankaran_recommendations_2023,
	title = {Recommendations for promoting user agency in the design of speech neuroprostheses},
	volume = {17},
	issn = {1662-5161},
	url = {https://www.frontiersin.org/articles/10.3389/fnhum.2023.1298129},
	abstract = {Brain-computer interfaces ({BCI}) that directly decode speech from brain activity aim to restore communication in people with paralysis who cannot speak. Despite recent advances, neural inference of speech remains imperfect, limiting the ability for speech {BCIs} to enable experiences such as fluent conversation that promote agency – that is, the ability for users to author and transmit messages enacting their intentions. Here, we make recommendations for promoting agency based on existing and emerging strategies in neural engineering. The focus is on achieving fast, accurate, and reliable performance while ensuring volitional control over when a decoder is engaged, what exactly is decoded, and how messages are expressed. Additionally, alongside neuroscientific progress within controlled experimental settings, we argue that a parallel line of research must consider how to translate experimental successes into real-world environments. While such research will ultimately require input from prospective users, here we identify and describe design choices inspired by human-factors work conducted in existing fields of assistive technology, which address practical issues likely to emerge in future real-world speech {BCI} applications.},
	journaltitle = {Frontiers in Human Neuroscience},
	author = {Sankaran, Narayan and Moses, David and Chiong, Winston and Chang, Edward F.},
	urldate = {2023-10-20},
	date = {2023},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\AW5V97N5\\Sankaran et al. - 2023 - Recommendations for promoting user agency in the d.pdf:application/pdf},
}

@article{oganian_vowel_2023,
	title = {Vowel and formant representation in the human auditory speech cortex},
	volume = {111},
	issn = {0896-6273},
	url = {https://www.cell.com/neuron/abstract/S0896-6273(23)00266-0},
	doi = {10.1016/j.neuron.2023.04.004},
	pages = {2105--2118.e4},
	number = {13},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Oganian, Yulia and Bhaya-Grossman, Ilina and Johnson, Keith and Chang, Edward F.},
	urldate = {2023-10-24},
	date = {2023-07-05},
	pmid = {37105171},
	note = {Publisher: Elsevier},
	keywords = {language, speech, auditory perception, intracranial electrophysiology, speech normalization, vowel formants},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\IWUTBWCJ\\Oganian et al. - 2023 - Vowel and formant representation in the human audi.pdf:application/pdf},
}

@article{li_dissecting_2023,
	title = {Dissecting neural computations in the human auditory pathway using deep neural networks for speech},
	rights = {2023 The Author(s).},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-023-01468-4},
	doi = {10.1038/s41593-023-01468-4},
	abstract = {The human auditory system extracts rich linguistic abstractions from speech signals. Traditional approaches to understanding this complex process have used linear feature-encoding models, with limited success. Artificial neural networks excel in speech recognition tasks and offer promising computational models of speech processing. We used speech representations in state-of-the-art deep neural network ({DNN}) models to investigate neural coding from the auditory nerve to the speech cortex. Representations in hierarchical layers of the {DNN} correlated well with the neural activity throughout the ascending auditory system. Unsupervised speech models performed at least as well as other purely supervised or fine-tuned models. Deeper {DNN} layers were better correlated with the neural activity in the higher-order auditory cortex, with computations aligned with phonemic and syllabic structures in speech. Accordingly, {DNN} models trained on either English or Mandarin predicted cortical responses in native speakers of each language. These results reveal convergence between {DNN} model representations and the biological auditory pathway, offering new approaches for modeling neural coding in the auditory cortex.},
	pages = {1--13},
	journaltitle = {Nature Neuroscience},
	shortjournal = {Nat Neurosci},
	author = {Li, Yuanning and Anumanchipalli, Gopala K. and Mohamed, Abdelrahman and Chen, Peili and Carney, Laurel H. and Lu, Junfeng and Wu, Jinsong and Chang, Edward F.},
	urldate = {2023-11-16},
	date = {2023-10-30},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Language, Cortex, Auditory system, Midbrain, Neural encoding},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\TG4CAXRA\\Li et al. - 2023 - Dissecting neural computations in the human audito.pdf:application/pdf},
}

@article{griggs_decoding_2023,
	title = {Decoding motor plans using a closed-loop ultrasonic brain–machine interface},
	rights = {2023 The Author(s)},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/s41593-023-01500-7},
	doi = {10.1038/s41593-023-01500-7},
	abstract = {Brain–machine interfaces ({BMIs}) enable people living with chronic paralysis to control computers, robots and more with nothing but thought. Existing {BMIs} have trade-offs across invasiveness, performance, spatial coverage and spatiotemporal resolution. Functional ultrasound ({fUS}) neuroimaging is an emerging technology that balances these attributes and may complement existing {BMI} recording technologies. In this study, we use {fUS} to demonstrate a successful implementation of a closed-loop ultrasonic {BMI}. We streamed {fUS} data from the posterior parietal cortex of two rhesus macaque monkeys while they performed eye and hand movements. After training, the monkeys controlled up to eight movement directions using the {BMI}. We also developed a method for pretraining the {BMI} using data from previous sessions. This enabled immediate control on subsequent days, even those that occurred months apart, without requiring extensive recalibration. These findings establish the feasibility of ultrasonic {BMIs}, paving the way for a new class of less-invasive (epidural) interfaces that generalize across extended time periods and promise to restore function to people with neurological impairments.},
	pages = {1--12},
	journaltitle = {Nature Neuroscience},
	shortjournal = {Nat Neurosci},
	author = {Griggs, Whitney S. and Norman, Sumner L. and Deffieux, Thomas and Segura, Florian and Osmanski, Bruno-Félix and Chau, Geeling and Christopoulos, Vasileios and Liu, Charles and Tanter, Mickael and Shapiro, Mikhail G. and Andersen, Richard A.},
	urldate = {2023-12-03},
	date = {2023-11-30},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Neural decoding, Brain–machine interface, Motor control, Ultrasound},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\VI5SMABS\\Griggs et al. - 2023 - Decoding motor plans using a closed-loop ultrasoni.pdf:application/pdf},
}

@article{meng_continuous_2023,
	title = {Continuous synthesis of artificial speech sounds from human cortical surface recordings during silent speech production},
	volume = {20},
	issn = {1741-2560, 1741-2552},
	url = {https://iopscience.iop.org/article/10.1088/1741-2552/ace7f6},
	doi = {10.1088/1741-2552/ace7f6},
	abstract = {Objective. Brain–computer interfaces can restore various forms of communication in paralyzed patients who have lost their ability to articulate intelligible speech. This study aimed to demonstrate the feasibility of closed-loop synthesis of artificial speech sounds from human cortical surface recordings during silent speech production. Approach. Ten participants with intractable epilepsy were temporarily implanted with intracranial electrode arrays over cortical surfaces. A decoding model that predicted audible outputs directly from patient-specific neural feature inputs was trained during overt word reading and immediately tested with overt, mimed and imagined word reading. Predicted outputs were later assessed objectively against corresponding voice recordings and subjectively through human perceptual judgments. Main results. Artificial speech sounds were successfully synthesized during overt and mimed utterances by two participants with some coverage of the precentral gyrus. About a third of these sounds were correctly identified by naïve listeners in two-alternative forced-choice tasks. A similar outcome could not be achieved during imagined utterances by any of the participants. However, neural feature contribution analyses suggested the presence of exploitable activation patterns during imagined speech in the postcentral gyrus and the superior temporal gyrus. In future work, a more comprehensive coverage of cortical surfaces, including posterior parts of the middle frontal gyrus and the inferior frontal gyrus, could improve synthesis performance during imagined speech. Significance. As the field of speech neuroprostheses is rapidly moving toward clinical trials, this study addressed important considerations about task instructions and brain coverage when conducting research on silent speech with non-target participants.},
	pages = {046019},
	number = {4},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Meng, Kevin and Goodarzy, Farhad and Kim, {EuiYoung} and Park, Ye Jin and Kim, June Sic and Cook, Mark J and Chung, Chun Kee and Grayden, David B},
	urldate = {2023-12-03},
	date = {2023-08-01},
	langid = {english},
	file = {Meng et al. - 2023 - Continuous synthesis of artificial speech sounds f.pdf:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\UPPMNQIH\\Meng et al. - 2023 - Continuous synthesis of artificial speech sounds f.pdf:application/pdf},
}

@article{abbaspourazad_dynamical_2023,
	title = {Dynamical flexible inference of nonlinear latent factors and structures in neural population activity},
	rights = {2023 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2157-846X},
	url = {https://www.nature.com/articles/s41551-023-01106-1},
	doi = {10.1038/s41551-023-01106-1},
	abstract = {Modelling the spatiotemporal dynamics in the activity of neural populations while also enabling their flexible inference is hindered by the complexity and noisiness of neural observations. Here we show that the lower-dimensional nonlinear latent factors and latent structures can be computationally modelled in a manner that allows for flexible inference causally, non-causally and in the presence of missing neural observations. To enable flexible inference, we developed a neural network that separates the model into jointly trained manifold and dynamic latent factors such that nonlinearity is captured through the manifold factors and the dynamics can be modelled in tractable linear form on this nonlinear manifold. We show that the model, which we named ‘{DFINE}’ (for ‘dynamical flexible inference for nonlinear embeddings’) achieves flexible inference in simulations of nonlinear dynamics and across neural datasets representing a diversity of brain regions and behaviours. Compared with earlier neural-network models, {DFINE} enables flexible inference, better predicts neural activity and behaviour, and better captures the latent neural manifold structure. {DFINE} may advance the development of neurotechnology and investigations in neuroscience.},
	pages = {1--24},
	journaltitle = {Nature Biomedical Engineering},
	shortjournal = {Nat. Biomed. Eng},
	author = {Abbaspourazad, Hamidreza and Erturk, Eray and Pesaran, Bijan and Shanechi, Maryam M.},
	urldate = {2023-12-12},
	date = {2023-12-11},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Biomedical engineering, Computational neuroscience, Motor control, Computational science},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\3JV9HYY7\\Abbaspourazad et al. - 2023 - Dynamical flexible inference of nonlinear latent f.pdf:application/pdf},
}

@article{angrick_online_2023,
	title = {Online speech synthesis using a chronically implanted brain-computer interface in an individual with {ALS}},
	rights = {All rights reserved},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10327279/},
	doi = {10.1101/2023.06.30.23291352},
	abstract = {Recent studies have shown that speech can be reconstructed and synthesized using only brain activity recorded with intracranial electrodes, but until now this has only been done using retrospective analyses of recordings from able-bodied patients temporarily implanted with electrodes for epilepsy surgery. Here, we report online synthesis of intelligible words using a chronically implanted brain-computer interface ({BCI}) in a clinical trial participant ({ClinicalTrials}.gov, {NCT}03567213) with dysarthria due to amyotrophic lateral sclerosis ({ALS}). We demonstrate a reliable {BCI} that synthesizes commands freely chosen and spoken by the user from a vocabulary of 6 keywords originally designed to allow intuitive selection of items on a communication board. Our results show for the first time that a speech-impaired individual with {ALS} can use a chronically implanted {BCI} to reliably produce synthesized words that are intelligible to human listeners while preserving the participants voice profile.},
	pages = {2023.06.30.23291352},
	journaltitle = {{medRxiv}},
	shortjournal = {{medRxiv}},
	author = {Angrick, Miguel and Luo, Shiyu and Rabbani, Qinwan and Candrea, Daniel N. and Shah, Samyak and Milsap, Griffin W. and Anderson, William S. and Gordon, Chad R. and Rosenblatt, Kathryn R. and Clawson, Lora and Maragakis, Nicholas and Tenore, Francesco V. and Fifer, Matthew S. and Hermansky, Hynek and Ramsey, Nick F. and Crone, Nathan E.},
	urldate = {2024-01-05},
	date = {2023-07-01},
	pmid = {37425721},
	pmcid = {PMC10327279},
	file = {PubMed Central Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\CP8CYEC9\\Angrick et al. - 2023 - Online speech synthesis using a chronically implan.pdf:application/pdf},
}

@inproceedings{isyanto_design_2020,
	title = {Design and Implementation of {IoT}-Based Smart Home Voice Commands for disabled people using Google Assistant},
	url = {https://ieeexplore.ieee.org/abstract/document/9079344},
	doi = {10.1109/ICoSTA48221.2020.1570613925},
	abstract = {The development of the Internet of Things ({IoT}) technology has a positive impact on human life. A smart home is one of the {IoT} technology applications that facilitate human activities. The problem of physical abnormalities is a matter of limited activities for disabled people. This paper proposes a design of {IoT}-based smart home application with a remote control device that developed using voice commands for disabled people. Smart home control systems help disabled people to control their home electrical devices such as television ({TV}), lights, and fans using only voice commands without moving to turn on or turn off electrical equipment. The voice recognition on electrical equipment is using the Google Assistant's application on smartphones. The Google Assistant application will accept voice commands when the pronunciation is correct. Voice commands on {IoT}-based Smart Home are more simple to apply, without typing text messages. Users get convenience compared to using text. The signal strength of an Internet connection will create a useful performance device at the Response Time of Google Assistant, Response Time of System Processing, activating and deactivating Electrical Equipment. We expect that this device could be more useful to help disabled people interact with their environment by utilizing {IoT} technology facilities.},
	eventtitle = {2020 International Conference on Smart Technology and Applications ({ICoSTA})},
	pages = {1--6},
	booktitle = {2020 International Conference on Smart Technology and Applications ({ICoSTA})},
	author = {Isyanto, Haris and Arifin, Ajib Setyo and Suryanegara, Muhammad},
	urldate = {2024-01-05},
	date = {2020-02},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\DZ9FZTHF\\9079344.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\PDDZ5WSY\\Isyanto et al. - 2020 - Design and Implementation of IoT-Based Smart Home .pdf:application/pdf},
}

@article{luo_stable_2023,
	title = {Stable Decoding from a Speech {BCI} Enables Control for an Individual with {ALS} without Recalibration for 3 Months},
	volume = {10},
	rights = {© 2023 The Authors. Advanced Science published by Wiley-{VCH} {GmbH}},
	issn = {2198-3844},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/advs.202304853},
	doi = {10.1002/advs.202304853},
	abstract = {Brain-computer interfaces ({BCIs}) can be used to control assistive devices by patients with neurological disorders like amyotrophic lateral sclerosis ({ALS}) that limit speech and movement. For assistive control, it is desirable for {BCI} systems to be accurate and reliable, preferably with minimal setup time. In this study, a participant with severe dysarthria due to {ALS} operates computer applications with six intuitive speech commands via a chronic electrocorticographic ({ECoG}) implant over the ventral sensorimotor cortex. Speech commands are accurately detected and decoded (median accuracy: 90.59\%) throughout a 3-month study period without model retraining or recalibration. Use of the {BCI} does not require exogenous timing cues, enabling the participant to issue self-paced commands at will. These results demonstrate that a chronically implanted {ECoG}-based speech {BCI} can reliably control assistive devices over long time periods with only initial model training and calibration, supporting the feasibility of unassisted home use.},
	pages = {2304853},
	number = {35},
	journaltitle = {Advanced Science},
	author = {Luo, Shiyu and Angrick, Miguel and Coogan, Christopher and Candrea, Daniel N. and Wyse-Sookoo, Kimberley and Shah, Samyak and Rabbani, Qinwan and Milsap, Griffin W. and Weiss, Alexander R. and Anderson, William S. and Tippett, Donna C. and Maragakis, Nicholas J. and Clawson, Lora L. and Vansteensel, Mariska J. and Wester, Brock A. and Tenore, Francesco V. and Hermansky, Hynek and Fifer, Matthew S. and Ramsey, Nick F. and Crone, Nathan E.},
	urldate = {2024-01-05},
	date = {2023},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/advs.202304853},
	keywords = {neural decoding, amyotrophic lateral sclerosis ({ALS}), brain-computer interfaces, speech brain-computer interface ({BCI})},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\2AG8V2MF\\Luo et al. - 2023 - Stable Decoding from a Speech BCI Enables Control .pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\M3Y5M9XT\\advs.html:text/html},
}

@article{leonard_large-scale_2023,
	title = {Large-scale single-neuron speech sound encoding across the depth of human cortex},
	rights = {2023 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-023-06839-2},
	doi = {10.1038/s41586-023-06839-2},
	abstract = {Understanding the neural basis of speech perception requires that we study the human brain both at the scale of the fundamental computational unit of neurons and in their organization across the depth of cortex. Here we used high-density Neuropixels arrays1–3 to record from 685 neurons across cortical layers at nine sites in a high-level auditory region that is critical for speech, the superior temporal gyrus4,5, while participants listened to spoken sentences. Single neurons encoded a wide range of speech sound cues, including features of consonants and vowels, relative vocal pitch, onsets, amplitude envelope and sequence statistics. Neurons at each cross-laminar recording exhibited dominant tuning to a primary speech feature while also containing a substantial proportion of neurons that encoded other features contributing to heterogeneous selectivity. Spatially, neurons at similar cortical depths tended to encode similar speech features. Activity across all cortical layers was predictive of high-frequency field potentials (electrocorticography), providing a neuronal origin for macroelectrode recordings from the cortical surface. Together, these results establish single-neuron tuning across the cortical laminae as an important dimension of speech encoding in human superior temporal gyrus.},
	pages = {1--10},
	journaltitle = {Nature},
	author = {Leonard, Matthew K. and Gwilliams, Laura and Sellers, Kristin K. and Chung, Jason E. and Xu, Duo and Mischler, Gavin and Mesgarani, Nima and Welkenhuysen, Marleen and Dutta, Barundeb and Chang, Edward F.},
	urldate = {2024-01-10},
	date = {2023-12-13},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Language, Cortex},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\YKAWGY36\\Leonard et al. - 2023 - Large-scale single-neuron speech sound encoding ac.pdf:application/pdf},
}

@incollection{laureys_locked-syndrome_2005,
	title = {The locked-in syndrome : what is it like to be conscious but paralyzed and voiceless?},
	volume = {150},
	url = {https://www.sciencedirect.com/science/article/pii/S0079612305500347},
	series = {The Boundaries of Consciousness: Neurobiology and Neuropathology},
	shorttitle = {The locked-in syndrome},
	abstract = {The locked-in syndrome (pseudocoma) describes patients who are awake and conscious but selectively deefferented, i.e., have no means of producing speech, limb or facial movements. Acute ventral pontine lesions are its most common cause. People with such brainstem lesions often remain comatose for some days or weeks, needing artificial respiration and then gradually wake up, but remaining paralyzed and voiceless, superficially resembling patients in a vegetative state or akinetic mutism. In acute locked-in syndrome ({LIS}), eye-coded communication and evaluation of cognitive and emotional functioning is very limited because vigilance is fluctuating and eye movements may be inconsistent, very small, and easily exhausted. It has been shown that more than half of the time it is the family and not the physician who first realized that the patient was aware. Distressingly, recent studies reported that the diagnosis of {LIS} on average takes over 2.5 months. In some cases it took 4–6 years before aware and sensitive patients, locked in an immobile body, were recognized as being conscious. Once a {LIS} patient becomes medically stable, and given appropriate medical care, life expectancy increases to several decades. Even if the chances of good motor recovery are very limited, existing eye-controlled, computer-based communication technology currently allow the patient to control his environment, use a word processor coupled to a speech synthesizer, and access the worldwide net. Healthy individuals and medical professionals sometimes assume that the quality of life of an {LIS} patient is so poor that it is not worth living. On the contrary, chronic {LIS} patients typically self-report meaningful quality of life and their demand for euthanasia is surprisingly infrequent. Biased clinicians might provide less aggressive medical treatment and influence the family in inappropriate ways. It is important to stress that only the medically stabilized, informed {LIS} patient is competent to consent to or refuse life-sustaining treatment. Patients suffering from {LIS} should not be denied the right to die — and to die with dignity — but also, and more importantly, they should not be denied the right to live — and to live with dignity and the best possible revalidation, and pain and symptom management. In our opinion, there is an urgent need for a renewed ethical and medicolegal framework for our care of locked-in patients.},
	pages = {495--611},
	booktitle = {Progress in Brain Research},
	publisher = {Elsevier},
	author = {Laureys, Steven and Pellas, Frédéric and Van Eeckhout, Philippe and Ghorbel, Sofiane and Schnakers, Caroline and Perrin, Fabien and Berré, Jacques and Faymonville, Marie-Elisabeth and Pantke, Karl-Heinz and Damas, Francois and Lamy, Maurice and Moonen, Gustave and Goldman, Serge},
	editor = {Laureys, Steven},
	urldate = {2024-02-19},
	date = {2005-01-01},
	doi = {10.1016/S0079-6123(05)50034-7},
	file = {ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\B734ARUX\\S0079612305500347.html:text/html},
}

@article{halan_locked-syndrome_nodate,
	title = {Locked-In Syndrome: A Systematic Review of Long-Term Management and Prognosis},
	volume = {13},
	issn = {2168-8184},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8402869/},
	doi = {10.7759/cureus.16727},
	shorttitle = {Locked-In Syndrome},
	abstract = {Locked-in syndrome ({LIS}) is a neurological disorder in which there is damage to the ventral pons and caudal midbrain. An ischemic cause, such as basilar artery occlusion, can often lead to {LIS}. {LIS} has three subtypes: classical, partial, and total. There is loss of motion in the four extremities in classical {LIS}, loss of horizontal gaze, and aphasia. In partial {LIS}, the patient still has some motor function. Complete {LIS} has the worst outcome because patients cannot blink or have vertical gaze, thus rendering them incapable of communicating. Most cases of {LIS} occur due to ischemic infarcts. These patients require a great deal of physical rehabilitation to regain partial motor ability and a means to communicate. While the clinical features and pathophysiology are known, the prognosis and long-term treatment remain unknown., We conducted a systematic review using the Meta-Analysis Of Observational Studies in Epidemiology ({MOOSE}) protocol. We use an advanced {PubMed} strategy using the inclusion criteria of observational studies or clinical trials conducted in the last 20 years, written in English, and conducted on humans. We excluded systematic reviews, literature reviews, metanalysis, and studies that did not meet the outcomes of our objectives., The prognosis of {LIS} is not good, and most patients remain locked in, with poor quality of life, especially motor functions. Respiratory failure and depression are big comorbidities. In the acute setting, patients benefit from rapid intervention. The subacute treatment needs to manage aggressively to improve functional scores best. The long-term treatment focus is on the quality of life and managing comorbidities.},
	pages = {e16727},
	number = {7},
	journaltitle = {Cureus},
	shortjournal = {Cureus},
	author = {Halan, Taras and Ortiz, Juan Fernando and Reddy, Dinesh and Altamimi, Abbas and Ajibowo, Abimbola O and Fabara, Stephanie P},
	urldate = {2024-02-19},
	pmid = {34471579},
	pmcid = {PMC8402869},
	file = {PubMed Central Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\CR4A28EY\\Halan et al. - Locked-In Syndrome A Systematic Review of Long-Te.pdf:application/pdf},
}

@article{rippon_observational_2006,
	title = {An Observational Study of Cognitive Impairment in Amyotrophic Lateral Sclerosis},
	volume = {63},
	issn = {0003-9942},
	url = {https://doi.org/10.1001/archneur.63.3.345},
	doi = {10.1001/archneur.63.3.345},
	abstract = {Cognitive impairment is increasingly recognized in patients with amyotrophic lateral sclerosis ({ALS}). Clinical and pathologic features overlap in frontotemporal lobar dementia and {ALS}. Demographics, respiratory status, bulbar site of onset, and disease severity are potential risk factors for cognitive impairment in {ALS}.To further delineate the frequency, nature, and implications of cognitive impairment in {ALS} and to assess previously identified risk factors.Case-control and retrospective cohort study.Academic referral center.Forty consecutive patients with {ALS} underwent baseline neurologic and neuropsychologic examinations. Cognitive test performance was compared in patients with {ALS} and matched controls. An exploratory analysis of the relationship between cognitive performance and {ALS} survival was performed.Neuropsychologic test performance, {ALS} severity, and survival.Twelve patients (30\%) showed evidence of cognitive impairment, including 9 (23\%) who met the neuropsychologic criteria for dementia. No statistically significant differences were found between demented and nondemented {ALS} groups regarding demographics, family history, site of onset, bulbar dysfunction, or {ALS} severity. Only 1 patient with dementia had bulbar-onset disease. An association was observed between increasing {ALS} severity and declining verbal fluency performance. Demented patients with {ALS} showed predominant impairment in free recall, executive function, and naming, with relative preservation of attention, psychomotor speed, and visuospatial function. No association was observed between cognition and survival, controlling for {ALS} severity.Nearly a third of the patients with {ALS} showed evidence of cognitive impairment in a pattern consistent with frontotemporal lobar dementia. Cognitive performance was not related to site of onset or survival.Arch Neurol. 2006;63:345-352 --{\textgreater}},
	pages = {345--352},
	number = {3},
	journaltitle = {Archives of Neurology},
	shortjournal = {Archives of Neurology},
	author = {Rippon, Gregory A. and Scarmeas, Nikolaos and Gordon, Paul H. and Murphy, Peregrine L. and Albert, Steven M. and Mitsumoto, Hiroshi and Marder, Karen and Rowland, Lewis P. and Stern, Yaakov},
	urldate = {2024-02-19},
	date = {2006-03-01},
	file = {Full Text:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\JAL4W8CP\\Rippon et al. - 2006 - An Observational Study of Cognitive Impairment in .pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\Q3USWNYE\\790778.html:text/html},
}

@report{card_accurate_2023,
	title = {An accurate and rapidly calibrating speech neuroprosthesis},
	url = {http://medrxiv.org/lookup/doi/10.1101/2023.12.26.23300110},
	abstract = {Brain-computer interfaces ({BCIs}) can provide a rapid, intuitive way for people with paralysis to communicate by transforming the cortical activity associated with attempted speech into text. Despite recent advances, communication with {BCIs} has been restricted by requiring many weeks of training data, and by inadequate decoding accuracy. Here we report a speech {BCI} that decodes neural activity from 256 microelectrodes in the left precentral gyrus of a person with {ALS} and severe dysarthria. This system achieves daily word error rates as low as 1\% (2.66\% average; 9 times fewer errors than previous state-of-the-art speech {BCIs}) using a comprehensive 125,000-word vocabulary. On the first day of system use, following only 30 minutes of attempted speech training data, the {BCI} achieved 99.6\% word accuracy with a 50 word vocabulary. On the second day of use, we increased the vocabulary size to 125,000 words and after an additional 1.4 hours of training data, the {BCI} achieved 90.2\% word accuracy. At the beginning of subsequent days of use, the {BCI} reliably achieved 95\% word accuracy, and adaptive online fine-tuning continuously improved this accuracy throughout the day. Our participant used the speech {BCI} in self-paced conversation for over 32 hours to communicate with friends, family, and colleagues (both in-person and over video chat). These results indicate that speech {BCIs} have reached a level of performance suitable to restore naturalistic communication to people living with severe dysarthria.},
	institution = {Neurology},
	type = {preprint},
	author = {Card, Nicholas S. and Wairagkar, Maitreyee and Iacobacci, Carrina and Hou, Xianda and Singer-Clark, Tyler and Willett, Francis R. and Kunz, Erin M. and Fan, Chaofei and Vahdati Nia, Maryam and Deo, Darrel R. and Choi, Eun Young and Glasser, Matthew F. and Hochberg, Leigh R. and Henderson, Jaimie M. and Shahlaie, Kiarash and Brandman, David M. and Stavisky, Sergey D.},
	urldate = {2024-03-13},
	date = {2023-12-26},
	langid = {english},
	doi = {10.1101/2023.12.26.23300110},
	file = {Card et al. - 2023 - An accurate and rapidly calibrating speech neuropr.pdf:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\ICGIRAA5\\Card et al. - 2023 - An accurate and rapidly calibrating speech neuropr.pdf:application/pdf},
}

@article{defossez_decoding_2023,
	title = {Decoding speech perception from non-invasive brain recordings},
	volume = {5},
	rights = {2023 The Author(s)},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-023-00714-5},
	doi = {10.1038/s42256-023-00714-5},
	abstract = {Decoding speech from brain activity is a long-awaited goal in both healthcare and neuroscience. Invasive devices have recently led to major milestones in this regard: deep-learning algorithms trained on intracranial recordings can now start to decode elementary linguistic features such as letters, words and audio-spectrograms. However, extending this approach to natural speech and non-invasive brain recordings remains a major challenge. Here we introduce a model trained with contrastive learning to decode self-supervised representations of perceived speech from the non-invasive recordings of a large cohort of healthy individuals. To evaluate this approach, we curate and integrate four public datasets, encompassing 175 volunteers recorded with magneto-encephalography or electro-encephalography while they listened to short stories and isolated sentences. The results show that our model can identify, from 3 seconds of magneto-encephalography signals, the corresponding speech segment with up to 41\% accuracy out of more than 1,000 distinct possibilities on average across participants, and with up to 80\% in the best participants—a performance that allows the decoding of words and phrases absent from the training set. The comparison of our model with a variety of baselines highlights the importance of a contrastive objective, pretrained representations of speech and a common convolutional architecture simultaneously trained across multiple participants. Finally, the analysis of the decoder’s predictions suggests that they primarily depend on lexical and contextual semantic representations. Overall, this effective decoding of perceived speech from non-invasive recordings delineates a promising path to decode language from brain activity, without putting patients at risk of brain surgery.},
	pages = {1097--1107},
	number = {10},
	journaltitle = {Nature Machine Intelligence},
	shortjournal = {Nat Mach Intell},
	author = {Défossez, Alexandre and Caucheteux, Charlotte and Rapin, Jérémy and Kabeli, Ori and King, Jean-Rémi},
	urldate = {2024-03-18},
	date = {2023-10},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Language, Brain imaging, Computational science, Electroencephalography – {EEG}},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\S6YTCR6W\\Défossez et al. - 2023 - Decoding speech perception from non-invasive brain.pdf:application/pdf},
}

@article{bellier_music_2023,
	title = {Music can be reconstructed from human auditory cortex activity using nonlinear decoding models},
	volume = {21},
	issn = {1545-7885},
	url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3002176},
	doi = {10.1371/journal.pbio.3002176},
	abstract = {Music is core to human experience, yet the precise neural dynamics underlying music perception remain unknown. We analyzed a unique intracranial electroencephalography ({iEEG}) dataset of 29 patients who listened to a Pink Floyd song and applied a stimulus reconstruction approach previously used in the speech domain. We successfully reconstructed a recognizable song from direct neural recordings and quantified the impact of different factors on decoding accuracy. Combining encoding and decoding analyses, we found a right-hemisphere dominance for music perception with a primary role of the superior temporal gyrus ({STG}), evidenced a new {STG} subregion tuned to musical rhythm, and defined an anterior–posterior {STG} organization exhibiting sustained and onset responses to musical elements. Our findings show the feasibility of applying predictive modeling on short datasets acquired in single patients, paving the way for adding musical elements to brain–computer interface ({BCI}) applications.},
	pages = {e3002176},
	number = {8},
	journaltitle = {{PLOS} Biology},
	shortjournal = {{PLOS} Biology},
	author = {Bellier, Ludovic and Llorens, Anaïs and Marciano, Déborah and Gunduz, Aysegul and Schalk, Gerwin and Brunner, Peter and Knight, Robert T.},
	urldate = {2024-03-18},
	date = {2023-08-15},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Acoustics, Speech, Bioacoustics, Left hemisphere, Music cognition, Music perception, Right hemisphere, Sensory perception},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\KE24S8KT\\Bellier et al. - 2023 - Music can be reconstructed from human auditory cor.pdf:application/pdf},
}

@article{wandelt_decoding_2022,
	title = {Decoding grasp and speech signals from the cortical grasp circuit in a tetraplegic human},
	volume = {110},
	issn = {0896-6273},
	url = {https://www.sciencedirect.com/science/article/pii/S0896627322002458},
	doi = {10.1016/j.neuron.2022.03.009},
	abstract = {The cortical grasp network encodes planning and execution of grasps and processes spoken and written aspects of language. High-level cortical areas within this network are attractive implant sites for brain-machine interfaces ({BMIs}). While a tetraplegic patient performed grasp motor imagery and vocalized speech, neural activity was recorded from the supramarginal gyrus ({SMG}), ventral premotor cortex ({PMv}), and somatosensory cortex (S1). In {SMG} and {PMv}, five imagined grasps were well represented by firing rates of neuronal populations during visual cue presentation. During motor imagery, these grasps were significantly decodable from all brain areas. During speech production, {SMG} encoded both spoken grasp types and the names of five colors. Whereas {PMv} neurons significantly modulated their activity during grasping, {SMG}’s neural population broadly encoded features of both motor imagery and speech. Together, these results indicate that brain signals from high-level areas of the human cortex could be used for grasping and speech {BMI} applications.},
	pages = {1777--1787.e3},
	number = {11},
	journaltitle = {Neuron},
	shortjournal = {Neuron},
	author = {Wandelt, Sarah K. and Kellis, Spencer and Bjånes, David A. and Pejsa, Kelsie and Lee, Brian and Liu, Charles and Andersen, Richard A.},
	urldate = {2024-03-25},
	date = {2022-06-01},
	keywords = {somatosensory cortex, brain-machine interfaces, grasp decoding, single-unit recording, speech decoding, supramarginal gyrus, ventral premotor cortex},
	file = {Full Text:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\CL387Q6W\\Wandelt et al. - 2022 - Decoding grasp and speech signals from the cortica.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\SGZNINFZ\\S0896627322002458.html:text/html},
}

@article{cook_prediction_2013,
	title = {Prediction of seizure likelihood with a long-term, implanted seizure advisory system in patients with drug-resistant epilepsy: a first-in-man study},
	volume = {12},
	issn = {1474-4422, 1474-4465},
	url = {https://www.thelancet.com/journals/laneur/article/PIIS1474-4422(13)70075-9/fulltext#%20},
	doi = {10.1016/S1474-4422(13)70075-9},
	shorttitle = {Prediction of seizure likelihood with a long-term, implanted seizure advisory system in patients with drug-resistant epilepsy},
	pages = {563--571},
	number = {6},
	journaltitle = {The Lancet Neurology},
	shortjournal = {The Lancet Neurology},
	author = {Cook, Mark J. and O'Brien, Terence J. and Berkovic, Samuel F. and Murphy, Michael and Morokoff, Andrew and Fabinyi, Gavin and D'Souza, Wendyl and Yerra, Raju and Archer, John and Litewka, Lucas and Hosking, Sean and Lightfoot, Paul and Ruedebusch, Vanessa and Sheffield, W. Douglas and Snyder, David and Leyde, Kent and Himes, David},
	urldate = {2024-03-28},
	date = {2013-06-01},
	note = {Publisher: Elsevier},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\VAB9UGYU\\Cook et al. - 2013 - Prediction of seizure likelihood with a long-term,.pdf:application/pdf},
}

@article{rolston_major_2016,
	title = {Major and minor complications in extraoperative electrocorticography: A review of a national database},
	volume = {122},
	issn = {0920-1211},
	url = {https://www.sciencedirect.com/science/article/pii/S0920121116300146},
	doi = {10.1016/j.eplepsyres.2016.02.004},
	shorttitle = {Major and minor complications in extraoperative electrocorticography},
	abstract = {The risk profile of extraoperative electrocorticography ({ECoG}) is documented almost exclusively by case series from a limited number of academic medical centers. These studies tend to underreport minor complications, like urinary tract infections ({UTIs}) and deep venous thromboses ({DVTs}), that nevertheless affect hospital cost, length of stay, and the patient's quality of life. Herein, we used data from the American College of Surgeons ({ACS}) National Surgical Quality Improvement Program ({NSQIP}) to estimate the rate of adverse events in extraoperative {ECoG} surgeries. {NSQIP} is a validated dataset containing nearly 3 million procedures from over 600 North American hospitals, and uses strict criteria for the documentation of complications. Major complications occurred in 3.4\% of 177 extraoperative {ECoG} cases, while minor complications occurred in 9.6\%. The most common minor complication was bleeding requiring a transfusion in 3.4\% of cases, followed by sepsis, {DVT}, and {UTI} each in 2.3\% of cases. No mortality was reported. Overall, in a national database containing a heterogeneous population of hospitals, major complications of extraoperative {ECoG} were rare (3.4\%). Complications such as {UTI} and {DVT} tend to be underreported in retrospective case series, yet make up a majority of minor complications for {ECoG} patients in this dataset.},
	pages = {26--29},
	journaltitle = {Epilepsy Research},
	shortjournal = {Epilepsy Research},
	author = {Rolston, John D. and Englot, Dario J. and Cornes, Susannah and Chang, Edward F.},
	urldate = {2024-03-28},
	date = {2016-05-01},
	keywords = {{ECoG}, Adverse events, Complications, Epilepsy, Patient safety, Seizures},
	file = {Accepted Version:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\GYMKK2YS\\Rolston et al. - 2016 - Major and minor complications in extraoperative el.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\IQJVX3NM\\S0920121116300146.html:text/html},
}

@article{nair_nine-year_2020,
	title = {Nine-year prospective efficacy and safety of brain-responsive neurostimulation for focal epilepsy},
	volume = {95},
	url = {https://www.neurology.org/doi/full/10.1212/WNL.0000000000010154},
	doi = {10.1212/WNL.0000000000010154},
	abstract = {Objective
To prospectively evaluate safety and efficacy of brain-responsive neurostimulation in adults with medically intractable focal onset seizures ({FOS}) over 9 years.
Methods
Adults treated with brain-responsive neurostimulation in 2-year feasibility or randomized controlled trials were enrolled in a long-term prospective open label trial ({LTT}) to assess safety, efficacy, and quality of life ({QOL}) over an additional 7 years. Safety was assessed as adverse events ({AEs}), efficacy as median percent change in seizure frequency and responder rate, and {QOL} with the Quality of Life in Epilepsy ({QOLIE}-89) inventory.
Results
Of 256 patients treated in the initial trials, 230 participated in the {LTT}. At 9 years, the median percent reduction in seizure frequency was 75\% (p {\textless} 0.0001, Wilcoxon signed rank), responder rate was 73\%, and 35\% had a ≥90\% reduction in seizure frequency. We found that 18.4\% (47 of 256) experienced ≥1 year of seizure freedom, with 62\% (29 of 47) seizure-free at the last follow-up and an average seizure-free period of 3.2 years (range 1.04–9.6 years). Overall {QOL} and epilepsy-targeted and cognitive domains of {QOLIE}-89 remained significantly improved (p {\textless} 0.05). There were no serious {AEs} related to stimulation, and the sudden unexplained death in epilepsy ({SUDEP}) rate was significantly lower than predefined comparators (p {\textless} 0.05, 1-tailed χ2).
Conclusions
Adjunctive brain-responsive neurostimulation provides significant and sustained reductions in the frequency of {FOS} with improved {QOL}. Stimulation was well tolerated; implantation-related {AEs} were typical of other neurostimulation devices; and {SUDEP} rates were low.
{ClinicalTrials}.gov identifier
{NCT}00572195.
Classification of evidence
This study provides Class {IV} evidence that brain-responsive neurostimulation significantly reduces focal seizures with acceptable safety over 9 years.},
	pages = {e1244--e1256},
	number = {9},
	journaltitle = {Neurology},
	author = {Nair, Dileep R. and Laxer, Kenneth D. and Weber, Peter B. and Murro, Anthony M. and Park, Yong D. and Barkley, Gregory L. and Smith, Brien J. and Gwinn, Ryder P. and Doherty, Michael J. and Noe, Katherine H. and Zimmerman, Richard S. and Bergey, Gregory K. and Anderson, William S. and Heck, Christianne and Liu, Charles Y. and Lee, Ricky W. and Sadler, Toni and Duckrow, Robert B. and Hirsch, Lawrence J. and Wharen, Robert E. and Tatum, William and Srinivasan, Shraddha and McKhann, Guy M. and Agostini, Mark A. and Alexopoulos, Andreas V. and Jobst, Barbara C. and Roberts, David W. and Salanova, Vicenta and Witt, Thomas C. and Cash, Sydney S. and Cole, Andrew J. and Worrell, Gregory A. and Lundstrom, Brian N. and Edwards, Jonathan C. and Halford, Jonathan J. and Spencer, David C. and Ernst, Lia and Skidmore, Christopher T. and Sperling, Michael R. and Miller, Ian and Geller, Eric B. and Berg, Michel J. and Fessler, A. James and Rutecki, Paul and Goldman, Alica M. and Mizrahi, Eli M. and Gross, Robert E. and Shields, Donald C. and Schwartz, Theodore H. and Labar, Douglas R. and Fountain, Nathan B. and Elias, W. Jeff and Olejniczak, Piotr W. and Villemarette-Pittman, Nicole R. and Eisenschenk, Stephan and Roper, Steven N. and Boggs, Jane G. and Courtney, Tracy A. and Sun, Felice T. and Seale, Cairn G. and Miller, Kathy L. and Skarpaas, Tara L. and Morrell, Martha J. and {on behalf of the RNS System LTT Study}},
	urldate = {2024-03-28},
	date = {2020-09},
	note = {Publisher: Wolters Kluwer},
	file = {Full Text:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\KIH5DJVU\\Nair et al. - 2020 - Nine-year prospective efficacy and safety of brain.pdf:application/pdf},
}

@article{wong_risk_2009,
	title = {Risk factors for complications during intracranial electrode recording in presurgical evaluation of drug resistant partial epilepsy},
	volume = {151},
	issn = {0942-0940},
	url = {https://doi.org/10.1007/s00701-008-0171-7},
	doi = {10.1007/s00701-008-0171-7},
	abstract = {Intracranial electrode monitoring is still required in epilepsy surgery; however, it is associated with significant morbidity.},
	pages = {37--50},
	number = {1},
	journaltitle = {Acta Neurochirurgica},
	shortjournal = {Acta Neurochir (Wien)},
	author = {Wong, Chong H. and Birkett, Julie and Byth, Karen and Dexter, Mark and Somerville, Ernest and Gill, Deepak and Chaseling, Ray and Fearnside, Michael and Bleasel, Andrew},
	urldate = {2024-03-28},
	date = {2009-01-01},
	langid = {english},
	keywords = {Electrodes, Epilepsy, Electroencephalogaphy, Implanted, Postoperative complication, Risk factors},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\UH8Y9SGW\\Wong et al. - 2009 - Risk factors for complications during intracranial.pdf:application/pdf},
}

@article{behrens_surgical_1997,
	title = {Surgical and Neurological Complications in a Series of 708 Epilepsy Surgery Procedures},
	volume = {41},
	issn = {0148-396X},
	url = {https://journals.lww.com/neurosurgery/fulltext/1997/07000/surgical_and_neurological_complications_in_a.4.aspx},
	abstract = {{OBJECTIVE}: 
          There are few modern data on the complications of surgery for epilepsy from the neurosurgeon's point of view. A survey of complications observed in a large current epilepsy surgery series is presented to facilitate the assessment of a risk:benefit ratio, which must be known when planning for epilepsy surgery and counseling patients.
          {METHODS}: 
          A series of 429 consecutive patients operated on during 6.5 years in the newly established University of Bonn epilepsy surgery program was, in part, retrospectively, and, in larger part, prospectively analyzed for complications originating from 279 invasive diagnostic procedures and 429 therapeutic procedures. Neuropsychological and psychiatric complications as well as the rate of failure to control seizures are not addressed in this article.
          {RESULTS}: 
          Two hundred and seventy-nine temporal operations, 59 frontal operations, 22 other extratemporal operations, 33 callosotomies, 3 multilobectomies, and 33 hemispherectomies were performed. Complications were grouped into general surgical and neurological complications. No mortality resulted from 708 invasive procedures. Two hundred and seventy-nine invasive diagnostic procedures (various combinations of strip, grid, and depth electrode insertions) resulted in 3.6\% transient morbidity (2.9\% surgical complications, 0.7\% neurological complications) and 0.7\% permanent morbidity (dysphasia). During 429 therapeutic procedures, 33 surgical complications were encountered. None of these resulted in permanent morbidity, except for the necessity for permanent shunt insertion in three patients. Wound infection was the most frequent surgical complication, but we were able to demonstrate a steady decrease during the 6.5-year observation period. The total rate of neurological complications in 429 therapeutic procedures was 5.4\%, with 3.03\% causing transient morbidity and 2.33\% causing permanent morbidity.
          {CONCLUSION}: 
          Our data indicate that epilepsy surgery can be performed with an acceptable rate of resultant morbidity. The indications for epilepsy surgery, the learning curve determined, and the results from other series are discussed in the light of these figures.},
	pages = {1},
	number = {1},
	journaltitle = {Neurosurgery},
	author = {Behrens, Elga and Schramm, Johannes and Zentner, Josef and König, Roy},
	urldate = {2024-03-28},
	date = {1997-07},
	langid = {american},
	file = {Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\X2S934EW\\surgical_and_neurological_complications_in_a.4.html:text/html},
}

@article{mitchell_assessment_2023,
	title = {Assessment of Safety of a Fully Implanted Endovascular Brain-Computer Interface for Severe Paralysis in 4 Patients: The Stentrode With Thought-Controlled Digital Switch ({SWITCH}) Study},
	volume = {80},
	issn = {2168-6149},
	url = {https://doi.org/10.1001/jamaneurol.2022.4847},
	doi = {10.1001/jamaneurol.2022.4847},
	shorttitle = {Assessment of Safety of a Fully Implanted Endovascular Brain-Computer Interface for Severe Paralysis in 4 Patients},
	abstract = {Brain-computer interface ({BCI}) implants have previously required craniotomy to deliver penetrating or surface electrodes to the brain. Whether a minimally invasive endovascular technique to deliver recording electrodes through the jugular vein to superior sagittal sinus is safe and feasible is unknown.To assess the safety of an endovascular {BCI} and feasibility of using the system to control a computer by thought.The Stentrode With Thought-Controlled Digital Switch ({SWITCH}) study, a single-center, prospective, first in-human study, evaluated 5 patients with severe bilateral upper-limb paralysis, with a follow-up of 12 months. From a referred sample, 4 patients with amyotrophic lateral sclerosis and 1 with primary lateral sclerosis met inclusion criteria and were enrolled in the study. Surgical procedures and follow-up visits were performed at the Royal Melbourne Hospital, Parkville, Australia. Training sessions were performed at patients’ homes and at a university clinic. The study start date was May 27, 2019, and final follow-up was completed January 9, 2022.Recording devices were delivered via catheter and connected to subcutaneous electronic units. Devices communicated wirelessly to an external device for personal computer control.The primary safety end point was device-related serious adverse events resulting in death or permanent increased disability. Secondary end points were blood vessel occlusion and device migration. Exploratory end points were signal fidelity and stability over 12 months, number of distinct commands created by neuronal activity, and use of system for digital device control.Of 4 patients included in analyses, all were male, and the mean ({SD}) age was 61 (17) years. Patients with preserved motor cortex activity and suitable venous anatomy were implanted. Each completed 12-month follow-up with no serious adverse events and no vessel occlusion or device migration. Mean ({SD}) signal bandwidth was 233 (16) Hz and was stable throughout study in all 4 patients ({SD} range across all sessions, 7-32 Hz). At least 5 attempted movement types were decoded offline, and each patient successfully controlled a computer with the {BCI}.Endovascular access to the sensorimotor cortex is an alternative to placing {BCI} electrodes in or on the dura by open-brain surgery. These final safety and feasibility data from the first in-human {SWITCH} study indicate that it is possible to record neural signals from a blood vessel. The favorable safety profile could promote wider and more rapid translation of {BCI} to people with paralysis.{ClinicalTrials}.gov Identifier: {NCT}03834857},
	pages = {270--278},
	number = {3},
	journaltitle = {{JAMA} Neurology},
	shortjournal = {{JAMA} Neurology},
	author = {Mitchell, Peter and Lee, Sarah C. M. and Yoo, Peter E. and Morokoff, Andrew and Sharma, Rahul P. and Williams, Daryl L. and {MacIsaac}, Christopher and Howard, Mark E. and Irving, Lou and Vrljic, Ivan and Williams, Cameron and Bush, Steven and Balabanski, Anna H. and Drummond, Katharine J. and Desmond, Patricia and Weber, Douglas and Denison, Timothy and Mathers, Susan and O’Brien, Terence J. and Mocco, J. and Grayden, David B. and Liebeskind, David S. and Opie, Nicholas L. and Oxley, Thomas J. and Campbell, Bruce C. V.},
	urldate = {2024-03-28},
	date = {2023-03-01},
	file = {Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\PCY3KFYQ\\2799839.html:text/html},
}

@article{brandman_rapid_2018,
	title = {Rapid calibration of an intracortical brain–computer interface for people with tetraplegia},
	volume = {15},
	issn = {1741-2552},
	url = {https://dx.doi.org/10.1088/1741-2552/aa9ee7},
	doi = {10.1088/1741-2552/aa9ee7},
	abstract = {Objective. Brain–computer interfaces ({BCIs}) can enable individuals with tetraplegia to communicate and control external devices. Though much progress has been made in improving the speed and robustness of neural control provided by intracortical {BCIs}, little research has been devoted to minimizing the amount of time spent on decoder calibration. Approach. We investigated the amount of time users needed to calibrate decoders and achieve performance saturation using two markedly different decoding algorithms: the steady-state Kalman filter, and a novel technique using Gaussian process regression ({GP}-{DKF}). Main results. Three people with tetraplegia gained rapid closed-loop neural cursor control and peak, plateaued decoder performance within 3 min of initializing calibration. We also show that a {BCI}-naïve user (T5) was able to rapidly attain closed-loop neural cursor control with the {GP}-{DKF} using self-selected movement imagery on his first-ever day of closed-loop {BCI} use, acquiring a target 37 s after initiating calibration. Significance. These results demonstrate the potential for an intracortical {BCI} to be used immediately after deployment by people with paralysis, without the need for user learning or extensive system calibration.},
	pages = {026007},
	number = {2},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Brandman, David M. and Hosman, Tommy and Saab, Jad and Burkhart, Michael C. and Shanahan, Benjamin E. and Ciancibello, John G. and Sarma, Anish A. and Milstein, Daniel J. and Vargas-Irwin, Carlos E. and Franco, Brian and Kelemen, Jessica and Blabe, Christine and Murphy, Brian A. and Young, Daniel R. and Willett, Francis R. and Pandarinath, Chethan and Stavisky, Sergey D. and Kirsch, Robert F. and Walter, Benjamin L. and Ajiboye, A. Bolu and Cash, Sydney S. and Eskandar, Emad N. and Miller, Jonathan P. and Sweet, Jennifer A. and Shenoy, Krishna V. and Henderson, Jaimie M. and Jarosiewicz, Beata and Harrison, Matthew T. and Simeral, John D. and Hochberg, Leigh R.},
	urldate = {2024-03-28},
	date = {2018-01},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\Z5FCMLLA\\Brandman et al. - 2018 - Rapid calibration of an intracortical brain–comput.pdf:application/pdf},
}

@misc{pratap_massively_2020,
	title = {Massively Multilingual {ASR}: 50 Languages, 1 Model, 1 Billion Parameters},
	url = {http://arxiv.org/abs/2007.03001},
	shorttitle = {Massively Multilingual {ASR}},
	abstract = {We study training a single acoustic model for multiple languages with the aim of improving automatic speech recognition ({ASR}) performance on low-resource languages, and over-all simplifying deployment of {ASR} systems that support diverse languages. We perform an extensive benchmark on 51 languages, with varying amount of training data by language(from 100 hours to 1100 hours). We compare three variants of multilingual training from a single joint model without knowing the input language, to using this information, to multiple heads (one per language cluster). We show that multilingual training of {ASR} models on several languages can improve recognition performance, in particular, on low resource languages. We see 20.9\%, 23\% and 28.8\% average {WER} relative reduction compared to monolingual baselines on joint model, joint model with language input and multi head model respectively. To our knowledge, this is the first work studying multilingual {ASR} at massive scale, with more than 50 languages and more than 16,000 hours of audio across them.},
	number = {{arXiv}:2007.03001},
	publisher = {{arXiv}},
	author = {Pratap, Vineel and Sriram, Anuroop and Tomasello, Paden and Hannun, Awni and Liptchinsky, Vitaliy and Synnaeve, Gabriel and Collobert, Ronan},
	urldate = {2024-04-04},
	date = {2020-07-07},
	eprinttype = {arxiv},
	eprint = {2007.03001 [cs, eess]},
	keywords = {Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing, Computer Science - Computation and Language},
	file = {arXiv.org Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\GSCXZKPI\\2007.html:text/html;Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\95RRZVCJ\\Pratap et al. - 2020 - Massively Multilingual ASR 50 Languages, 1 Model,.pdf:application/pdf},
}

@book{green_automatic_2021,
	title = {Automatic Speech Recognition of Disordered Speech: Personalized Models Outperforming Human Listeners on Short Phrases},
	shorttitle = {Automatic Speech Recognition of Disordered Speech},
	abstract = {This study evaluated the accuracy of personalized automatic speech recognition ({ASR}) for recognizing disordered speech from a large cohort of individuals with a wide range of underlying etiologies using an open vocabulary. The performance of these models was benchmarked relative to that of expert human transcribers and two different speaker-independent {ASR} models trained on typical speech. 432 individuals with self-reported disordered speech recorded at least 300 short phrases using a web-based application. Word error rates ({WERs}) were estimated for three different {ASR} models and for human transcribers. Metadata were collected to evaluate the potential impact of participants, atypical speech characteristics, and technical factors on recognition accuracy. Personalized models outperformed human transcribers with median and max recognition accuracy gains of 9\% and 80\%, respectively. The accuracies of personalized models were high (median {WER}: 4.6\%) and better than those of speaker-independent models (median {WER}: 31\%). The most significant improvements were for the most severely affected speakers. Low signal-to-noise ratio and fewer training utterances were associated with poor word recognition, even for speakers with mild speech impairments. Our results demonstrate the efficacy of personalized {ASR} models in recognizing a wide range of speech impairments and severities and using an open vocabulary.},
	pagetotal = {4778},
	author = {Green, Jordan and {MacDonald}, Robert and Jiang, Pan-Pan and Cattiau, Julie and Heywood, Rus and Cave, Richard and Seaver, Katie and Ladewig, Marilyn and Tobin, Jimmy and Brenner, Michael and Nelson, Philip and Tomanek, Katrin},
	date = {2021-08-30},
	doi = {10.21437/Interspeech.2021-1384},
	note = {Pages: 4782},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\DRATWQQZ\\Green et al. - 2021 - Automatic Speech Recognition of Disordered Speech.pdf:application/pdf},
}

@article{chen_neural_2024,
	title = {A neural speech decoding framework leveraging deep learning and speech synthesis},
	rights = {2024 The Author(s)},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-024-00824-8},
	doi = {10.1038/s42256-024-00824-8},
	abstract = {Decoding human speech from neural signals is essential for brain–computer interface ({BCI}) technologies that aim to restore speech in populations with neurological deficits. However, it remains a highly challenging task, compounded by the scarce availability of neural signals with corresponding speech, data complexity and high dimensionality. Here we present a novel deep learning-based neural speech decoding framework that includes an {ECoG} decoder that translates electrocorticographic ({ECoG}) signals from the cortex into interpretable speech parameters and a novel differentiable speech synthesizer that maps speech parameters to spectrograms. We have developed a companion speech-to-speech auto-encoder consisting of a speech encoder and the same speech synthesizer to generate reference speech parameters to facilitate the {ECoG} decoder training. This framework generates natural-sounding speech and is highly reproducible across a cohort of 48 participants. Our experimental results show that our models can decode speech with high correlation, even when limited to only causal operations, which is necessary for adoption by real-time neural prostheses. Finally, we successfully decode speech in participants with either left or right hemisphere coverage, which could lead to speech prostheses in patients with deficits resulting from left hemisphere damage.},
	pages = {1--14},
	journaltitle = {Nature Machine Intelligence},
	shortjournal = {Nat Mach Intell},
	author = {Chen, Xupeng and Wang, Ran and Khalilian-Gourtani, Amirhossein and Yu, Leyao and Dugan, Patricia and Friedman, Daniel and Doyle, Werner and Devinsky, Orrin and Wang, Yao and Flinker, Adeen},
	urldate = {2024-04-11},
	date = {2024-04-08},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Neural decoding, Cortex},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\VYDTKDQB\\Chen et al. - 2024 - A neural speech decoding framework leveraging deep.pdf:application/pdf},
}

@article{guan_stability_2022,
	title = {Stability of motor representations after paralysis},
	volume = {11},
	issn = {2050-084X},
	url = {https://doi.org/10.7554/eLife.74478},
	doi = {10.7554/eLife.74478},
	abstract = {Neural plasticity allows us to learn skills and incorporate new experiences. What happens when our lived experiences fundamentally change, such as after a severe injury? To address this question, we analyzed intracortical population activity in the posterior parietal cortex ({PPC}) of a tetraplegic adult as she controlled a virtual hand through a brain–computer interface ({BCI}). By attempting to move her fingers, she could accurately drive the corresponding virtual fingers. Neural activity during finger movements exhibited robust representational structure similar to {fMRI} recordings of able-bodied individuals’ motor cortex, which is known to reflect able-bodied usage patterns. The finger representational structure was consistent throughout multiple sessions, even though the structure contributed to {BCI} decoding errors. Within individual {BCI} movements, the representational structure was dynamic, first resembling muscle activation patterns and then resembling the anticipated sensory consequences. Our results reveal that motor representations in {PPC} reflect able-bodied motor usage patterns even after paralysis, and {BCIs} can re-engage these stable representations to restore lost motor functions.},
	pages = {e74478},
	journaltitle = {{eLife}},
	author = {Guan, Charles and Aflalo, Tyson and Zhang, Carey Y and Amoruso, Elena and Rosario, Emily R and Pouratian, Nader and Andersen, Richard A},
	editor = {Diedrichsen, Jörn and Baker, Chris I and Diedrichsen, Jörn},
	urldate = {2024-04-16},
	date = {2022-09-20},
	note = {Publisher: {eLife} Sciences Publications, Ltd},
	keywords = {plasticity, brain-machine interface, brain–computer interface, fingers, hand, paralysis, posterior parietal cortex},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\SLCIKGG4\\Guan et al. - 2022 - Stability of motor representations after paralysis.pdf:application/pdf},
}

@article{chen_chronic_2023,
	title = {Chronic stability of a neuroprosthesis comprising multiple adjacent Utah arrays in monkeys},
	volume = {20},
	issn = {1741-2552},
	url = {https://dx.doi.org/10.1088/1741-2552/ace07e},
	doi = {10.1088/1741-2552/ace07e},
	abstract = {Objective. Electrical stimulation of visual cortex via a neuroprosthesis induces the perception of dots of light (‘phosphenes’), potentially allowing recognition of simple shapes even after decades of blindness. However, restoration of functional vision requires large numbers of electrodes, and chronic, clinical implantation of intracortical electrodes in the visual cortex has only been achieved using devices of up to 96 channels. We evaluated the efficacy and stability of a 1024-channel neuroprosthesis system in non-human primates ({NHPs}) over more than 3 years to assess its suitability for long-term vision restoration. Approach. We implanted 16 microelectrode arrays (Utah arrays) consisting of 8 × 8 electrodes with iridium oxide tips in the primary visual cortex (V1) and visual area 4 (V4) of two sighted macaques. We monitored the animals’ health and measured electrode impedances and neuronal signal quality by calculating signal-to-noise ratios of visually driven neuronal activity, peak-to-peak voltages of the waveforms of action potentials, and the number of channels with high-amplitude signals. We delivered cortical microstimulation and determined the minimum current that could be perceived, monitoring the number of channels that successfully yielded phosphenes. We also examined the influence of the implant on a visual task after 2–3 years of implantation and determined the integrity of the brain tissue with a histological analysis 3–3.5 years post-implantation. Main results. The monkeys remained healthy throughout the implantation period and the device retained its mechanical integrity and electrical conductivity. However, we observed decreasing signal quality with time, declining numbers of phosphene-evoking electrodes, decreases in electrode impedances, and impaired performance on a visual task at visual field locations corresponding to implanted cortical regions. Current thresholds increased with time in one of the two animals. The histological analysis revealed encapsulation of arrays and cortical degeneration. Scanning electron microscopy on one array revealed degradation of {IrOx} coating and higher impedances for electrodes with broken tips. Significance. Long-term implantation of a high-channel-count device in {NHP} visual cortex was accompanied by deformation of cortical tissue and decreased stimulation efficacy and signal quality over time. We conclude that improvements in device biocompatibility and/or refinement of implantation techniques are needed before future clinical use is feasible.},
	pages = {036039},
	number = {3},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Chen, Xing and Wang, Feng and Kooijmans, Roxana and Klink, Peter Christiaan and Boehler, Christian and Asplund, Maria and Roelfsema, Pieter Roelf},
	urldate = {2024-04-16},
	date = {2023-06},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\93WS5YIQ\\Chen et al. - 2023 - Chronic stability of a neuroprosthesis comprising .pdf:application/pdf},
}

@article{dickey_single-unit_2009,
	title = {Single-Unit Stability Using Chronically Implanted Multielectrode Arrays},
	volume = {102},
	issn = {0022-3077},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2724357/},
	doi = {10.1152/jn.90920.2008},
	abstract = {The use of chronic intracortical multielectrode arrays has become increasingly prevalent in neurophysiological experiments. However, it is not obvious whether neuronal signals obtained over multiple recording sessions come from the same or different neurons. Here, we develop a criterion to assess single-unit stability by measuring the similarity of 1) average spike waveforms and 2) interspike interval histograms ({ISIHs}). Neuronal activity was recorded from four Utah arrays implanted in primary motor and premotor cortices in three rhesus macaque monkeys during 10 recording sessions over a 15- to 17-day period. A unit was defined as stable through a given day if the stability criterion was satisfied on all recordings leading up to that day. We found that 57\% of the original units were stable through 7 days, 43\% were stable through 10 days, and 39\% were stable through 15 days. Moreover, stable units were more likely to remain stable in subsequent recording sessions (i.e., 89\% of the neurons that were stable through four sessions remained stable on the fifth). Using both waveform and {ISIH} data instead of just waveforms improved performance by reducing the number of false positives. We also demonstrate that this method can be used to track neurons across days, even during adaptation to a visuomotor rotation. Identifying a stable subset of neurons should allow the study of long-term learning effects across days and has practical implications for pooling of behavioral data across days and for increasing the effectiveness of brain–machine interfaces.},
	pages = {1331--1339},
	number = {2},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {J Neurophysiol},
	author = {Dickey, Adam S. and Suminski, Aaron and Amit, Yali and Hatsopoulos, Nicholas G.},
	urldate = {2024-04-16},
	date = {2009-08},
	pmid = {19535480},
	pmcid = {PMC2724357},
}

@article{larzabal_long-term_2021,
	title = {Long-term stability of the chronic epidural wireless recorder {WIMAGINE} in tetraplegic patients},
	volume = {18},
	issn = {1741-2552},
	doi = {10.1088/1741-2552/ac2003},
	abstract = {Objective.The evaluation of the long-term stability of {ElectroCorticoGram} ({ECoG}) signals is an important scientific question as new implantable recording devices can be used for medical purposes such as Brain-Computer Interface ({BCI}) or brain monitoring.Approach.The long-term clinical validation of wireless implantable multi-channel acquisition system for generic interface with neurons ({WIMAGINE}), a wireless 64-channel epidural {ECoG} recorder was investigated. The {WIMAGINE} device was implanted in two quadriplegic patients within the context of a {BCI} protocol. This study focused on the {ECoG} signal stability in two patients bilaterally implanted in June 2017 (P1) and in November 2019 (P2).Methods. The {ECoG} signal was recorded at rest prior to each {BCI} session resulting in a 32 month and in a 14 month follow-up for P1 and P2 respectively. State-of-the-art signal evaluation metrics such as root mean square ({RMS}), the band power ({BP}), the signal to noise ratio ({SNR}), the effective bandwidth ({EBW}) and the spectral edge frequency ({SEF}) were used to evaluate stability of signal over the implantation time course. The time-frequency maps obtained from task-related motor activations were also studied to investigate the long-term selectivity of the electrodes.Mainresults.Based on temporal linear regressions, we report a limited decrease of the signal average level ({RMS}), spectral distribution ({BP}) and {SNR}, and a remarkable steadiness of the {EBW} and {SEF}. Time-frequency maps obtained during motor imagery, showed a high level of discrimination 1 month after surgery and also after 2 years.Conclusions.The {WIMAGINE} epidural device showed high stability over time. The signal evaluation metrics of two quadriplegic patients during 32 months and 14 months respectively provide strong evidence that this wireless implant is well-suited for long-term {ECoG} recording.Significance.These findings are relevant for the future of implantable {BCIs}, and could benefit other patients with spinal cord injury, amyotrophic lateral sclerosis, neuromuscular diseases or drug-resistant epilepsy.},
	number = {5},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J Neural Eng},
	author = {Larzabal, Christelle and Bonnet, Stéphane and Costecalde, Thomas and Auboiroux, Vincent and Charvet, Guillaume and Chabardes, Stéphan and Aksenova, Tetiana and Sauter-Starace, Fabien},
	date = {2021-09-09},
	pmid = {34425566},
	keywords = {{ECoG}, Humans, Electrocorticography, Electroencephalography, Brain, Brain-Computer Interfaces, clinical trial, Electrodes, Implanted, Epidural Space, long-term, signal quality, wireless, Wireless Technology},
}

@article{turella_beta_2016,
	title = {Beta band modulations underlie action representations for movement planning},
	volume = {136},
	issn = {1053-8119},
	url = {https://www.sciencedirect.com/science/article/pii/S1053811916301471},
	doi = {10.1016/j.neuroimage.2016.05.027},
	abstract = {To be able to interact with our environment, we need to transform incoming sensory information into goal-directed motor outputs. Whereas our ability to plan an appropriate movement based on sensory information appears effortless and simple, the underlying brain dynamics are still largely unknown. Here we used magnetoencephalography ({MEG}) to investigate this issue by recording brain activity during the planning of non-visually guided reaching and grasping actions, performed with either the left or right hand. Adopting a combination of univariate and multivariate analyses, we revealed specific patterns of beta power modulations underlying varying levels of neural representations during movement planning. (1) Effector-specific modulations were evident as a decrease in power in the beta band. Within both hemispheres, this decrease was stronger while planning a movement with the contralateral hand. (2) The comparison of planned grasping and reaching led to a relative increase in power in the beta band. These power changes were localized within temporal, premotor and posterior parietal cortices. Action-related modulations overlapped with effector-related beta power changes within widespread frontal and parietal regions, suggesting the possible integration of these two types of neural representations. (3) Multivariate analyses of action-specific power changes revealed that part of this broadband beta modulation also contributed to the encoding of an effector-independent neural representation of a planned action within fronto-parietal and temporal regions. Our results suggest that beta band power modulations play a central role in movement planning, within both the dorsal and ventral stream, by coding and integrating different levels of neural representations, ranging from the simple representation of the to-be-moved effector up to an abstract, effector-independent representation of the upcoming action.},
	pages = {197--207},
	journaltitle = {{NeuroImage}},
	shortjournal = {{NeuroImage}},
	author = {Turella, Luca and Tucciarelli, Raffaele and Oosterhof, Nikolaas N. and Weisz, Nathan and Rumiati, Raffaella and Lingnau, Angelika},
	urldate = {2024-04-19},
	date = {2016-08-01},
	keywords = {{MVPA}, Action, Beta band, Grasping, {MEG}, Motor system},
	file = {ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\ZAP96JCI\\S1053811916301471.html:text/html},
}

@article{klein_informed_2016,
	title = {Informed consent in implantable {BCI} research: identification of research risks and recommendations for development of best practices},
	volume = {13},
	issn = {1741-2552},
	url = {https://dx.doi.org/10.1088/1741-2560/13/4/043001},
	doi = {10.1088/1741-2560/13/4/043001},
	shorttitle = {Informed consent in implantable {BCI} research},
	abstract = {Objective. Implantable brain–computer interface ({BCI}) research promises improvements in human health and enhancements in quality of life. Informed consent of subjects is a central tenet of this research. Rapid advances in neuroscience, and the intimate connection between functioning of the brain and conceptions of the self, make informed consent particularly challenging in {BCI} research. Identification of safety and research-related risks associated with {BCI} devices is an important step in ensuring meaningful informed consent. Approach. This paper highlights a number of {BCI} research risks, including safety concerns, cognitive and communicative impairments, inappropriate subject expectations, group vulnerabilities, privacy and security, and disruptions of identity. Main results. Based on identified {BCI} research risks, best practices are needed for understanding and incorporating {BCI}-related risks into informed consent protocols. Significance. Development of best practices should be guided by processes that are: multidisciplinary, systematic and transparent, iterative, relational and exploratory.},
	pages = {043001},
	number = {4},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Klein, Eran and Ojemann, Jeffrey},
	urldate = {2024-05-10},
	date = {2016-06},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\BZYG34MM\\Klein and Ojemann - 2016 - Informed consent in implantable BCI research iden.pdf:application/pdf},
}

@article{flint_long_2013,
	title = {Long term, stable brain machine interface performance using local field potentials and multiunit spikes},
	volume = {10},
	issn = {1741-2552},
	url = {https://dx.doi.org/10.1088/1741-2560/10/5/056005},
	doi = {10.1088/1741-2560/10/5/056005},
	abstract = {Objective. Brain machine interfaces ({BMIs}) have the potential to restore movement to people with paralysis. However, a clinically-viable {BMI} must enable consistently accurate control over time spans ranging from years to decades, which has not yet been demonstrated. Most {BMIs} that use single-unit spikes as inputs will experience degraded performance over time without frequent decoder re-training. Two other signals, local field potentials ({LFPs}) and multi-unit spikes ({MSPs}), may offer greater reliability over long periods and better performance stability than single-unit spikes. Here, we demonstrate that {LFPs} can be used in a biomimetic {BMI} to control a computer cursor. Approach. We implanted two rhesus macaques with intracortical microelectrodes in primary motor cortex. We recorded {LFP} and {MSP} signals from the monkeys while they performed a continuous reaching task, moving a cursor to randomly-placed targets on a computer screen. We then used the {LFP} and {MSP} signals to construct biomimetic decoders for control of the cursor. Main results. Both monkeys achieved high-performance, continuous control that remained stable or improved over nearly 12 months using an {LFP} decoder that was not retrained or adapted. In parallel, the monkeys used {MSPs} to control a {BMI} without retraining or adaptation and had similar or better performance, and that predominantly remained stable over more than six months. In contrast to their stable online control, both {LFP} and {MSP} signals showed substantial variability when used offline to predict hand movements. Significance. Our results suggest that the monkeys were able to stabilize the relationship between neural activity and cursor movement during online {BMI} control, despite variability in the relationship between neural activity and hand movements.},
	pages = {056005},
	number = {5},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Flint, Robert D. and Wright, Zachary A. and Scheid, Michael R. and Slutzky, Marc W.},
	urldate = {2024-05-10},
	date = {2013-08},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\7FNBXWH4\\Flint et al. - 2013 - Long term, stable brain machine interface performa.pdf:application/pdf},
}

@article{flint_continuous_2016,
	title = {Continuous decoding of human grasp kinematics using epidural and subdural signals},
	volume = {14},
	issn = {1741-2552},
	url = {https://dx.doi.org/10.1088/1741-2560/14/1/016005},
	doi = {10.1088/1741-2560/14/1/016005},
	abstract = {Objective. Restoring or replacing function in paralyzed individuals will one day be achieved through the use of brain–machine interfaces. Regaining hand function is a major goal for paralyzed patients. Two competing prerequisites for the widespread adoption of any hand neuroprosthesis are accurate control over the fine details of movement, and minimized invasiveness. Here, we explore the interplay between these two goals by comparing our ability to decode hand movements with subdural and epidural field potentials ({EFPs}). Approach. We measured the accuracy of decoding continuous hand and finger kinematics during naturalistic grasping motions in five human subjects. We recorded subdural surface potentials (electrocorticography; {ECoG}) as well as with {EFPs}, with both standard- and high-resolution electrode arrays. Main results. In all five subjects, decoding of continuous kinematics significantly exceeded chance, using either {EGoG} or {EFPs}. {ECoG} decoding accuracy compared favorably with prior investigations of grasp kinematics (mean ± {SD} grasp aperture variance accounted for was 0.54 ± 0.05 across all subjects, 0.75 ± 0.09 for the best subject). In general, {EFP} decoding performed comparably to {ECoG} decoding. The 7–20 Hz and 70–115 Hz spectral bands contained the most information about grasp kinematics, with the 70–115 Hz band containing greater information about more subtle movements. Higher-resolution recording arrays provided clearly superior performance compared to standard-resolution arrays. Significance. To approach the fine motor control achieved by an intact brain-body system, it will be necessary to execute motor intent on a continuous basis with high accuracy. The current results demonstrate that this level of accuracy might be achievable not just with {ECoG}, but with {EFPs} as well. Epidural placement of electrodes is less invasive, and therefore may incur less risk of encephalitis or stroke than subdural placement of electrodes. Accurately decoding motor commands at the epidural level may be an important step towards a clinically viable brain–machine interface.},
	pages = {016005},
	number = {1},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Flint, Robert D. and Rosenow, Joshua M. and Tate, Matthew C. and Slutzky, Marc W.},
	urldate = {2024-05-10},
	date = {2016-11},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\UZXLU3TF\\Flint et al. - 2016 - Continuous decoding of human grasp kinematics usin.pdf:application/pdf},
}

@article{nuyujukian_performance_2014,
	title = {Performance sustaining intracortical neural prostheses},
	volume = {11},
	issn = {1741-2552},
	url = {https://dx.doi.org/10.1088/1741-2560/11/6/066003},
	doi = {10.1088/1741-2560/11/6/066003},
	abstract = {Objective. Neural prostheses, or brain–machine interfaces, aim to restore efficient communication and movement ability to those suffering from paralysis. A major challenge these systems face is robust performance, particularly with aging signal sources. The aim in this study was to develop a neural prosthesis that could sustain high performance in spite of signal instability while still minimizing retraining time. Approach. We trained two rhesus macaques implanted with intracortical microelectrode arrays 1–4 years prior to this study to acquire targets with a neurally-controlled cursor. We measured their performance via achieved bitrate (bits per second, bps). This task was repeated over contiguous days to evaluate the sustained performance across time. Main results. We found that in the monkey with a younger (i.e., two year old) implant and better signal quality, a fixed decoder could sustain performance for a month at a rate of 4 bps, the highest achieved communication rate reported to date. This fixed decoder was evaluated across 22 months and experienced a performance decline at a rate of 0.24 bps yr-1. In the monkey with the older (i.e., 3.5 year old) implant and poorer signal quality, a fixed decoder could not sustain performance for more than a few days. Nevertheless, performance in this monkey was maintained for two weeks without requiring additional online retraining time by utilizing prior days’ experimental data. Upon analysis of the changes in channel tuning, we found that this stability appeared partially attributable to the cancelling-out of neural tuning fluctuations when projected to two-dimensional cursor movements. Significance. The findings in this study (1) document the highest-performing communication neural prosthesis in monkeys, (2) confirm and extend prior reports of the stability of fixed decoders, and (3) demonstrate a protocol for system stability under conditions where fixed decoders would otherwise fail. These improvements to decoder stability are important for minimizing training time and should make neural prostheses more practical to use.},
	pages = {066003},
	number = {6},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Nuyujukian, Paul and Kao, Jonathan C. and Fan, Joline M. and Stavisky, Sergey D. and Ryu, Stephen I. and Shenoy, Krishna V.},
	urldate = {2024-05-10},
	date = {2014-10},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\HIII79QK\\Nuyujukian et al. - 2014 - Performance sustaining intracortical neural prosth.pdf:application/pdf},
}

@article{silva_speech_2024,
	title = {The speech neuroprosthesis},
	rights = {2024 Springer Nature Limited},
	issn = {1471-0048},
	url = {https://www.nature.com/articles/s41583-024-00819-9},
	doi = {10.1038/s41583-024-00819-9},
	abstract = {Loss of speech after paralysis is devastating, but circumventing motor-pathway injury by directly decoding speech from intact cortical activity has the potential to restore natural communication and self-expression. Recent discoveries have defined how key features of speech production are facilitated by the coordinated activity of vocal-tract articulatory and motor-planning cortical representations. In this Review, we highlight such progress and how it has led to successful speech decoding, first in individuals implanted with intracranial electrodes for clinical epilepsy monitoring and subsequently in individuals with paralysis as part of early feasibility clinical trials to restore speech. We discuss high-spatiotemporal-resolution neural interfaces and the adaptation of state-of-the-art speech computational algorithms that have driven rapid and substantial progress in decoding neural activity into text, audible speech, and facial movements. Although restoring natural speech is a long-term goal, speech neuroprostheses already have performance levels that surpass communication rates offered by current assistive-communication technology. Given this accelerated rate of progress in the field, we propose key evaluation metrics for speed and accuracy, among others, to help standardize across studies. We finish by highlighting several directions to more fully explore the multidimensional feature space of speech and language, which will continue to accelerate progress towards a clinically viable speech neuroprosthesis.},
	pages = {1--20},
	journaltitle = {Nature Reviews Neuroscience},
	shortjournal = {Nat. Rev. Neurosci.},
	author = {Silva, Alexander B. and Littlejohn, Kaylo T. and Liu, Jessie R. and Moses, David A. and Chang, Edward F.},
	urldate = {2024-05-15},
	date = {2024-05-14},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Neuroscience, Cognitive neuroscience},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\9YXEBNMM\\Silva et al. - 2024 - The speech neuroprosthesis.pdf:application/pdf},
}

@article{silva_bilingual_2024,
	title = {A bilingual speech neuroprosthesis driven by cortical articulatory representations shared between languages},
	rights = {2024 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {2157-846X},
	url = {https://www.nature.com/articles/s41551-024-01207-5},
	doi = {10.1038/s41551-024-01207-5},
	abstract = {Advancements in decoding speech from brain activity have focused on decoding a single language. Hence, the extent to which bilingual speech production relies on unique or shared cortical activity across languages has remained unclear. Here, we leveraged electrocorticography, along with deep-learning and statistical natural-language models of English and Spanish, to record and decode activity from speech-motor cortex of a Spanish–English bilingual with vocal-tract and limb paralysis into sentences in either language. This was achieved without requiring the participant to manually specify the target language. Decoding models relied on shared vocal-tract articulatory representations across languages, which allowed us to build a syllable classifier that generalized across a shared set of English and Spanish syllables. Transfer learning expedited training of the bilingual decoder by enabling neural data recorded in one language to improve decoding in the other language. Overall, our findings suggest shared cortical articulatory representations that persist after paralysis and enable the decoding of multiple languages without the need to train separate language-specific decoders.},
	pages = {1--15},
	journaltitle = {Nature Biomedical Engineering},
	shortjournal = {Nat. Biomed. Eng},
	author = {Silva, Alexander B. and Liu, Jessie R. and Metzger, Sean L. and Bhaya-Grossman, Ilina and Dougherty, Maximilian E. and Seaton, Margaret P. and Littlejohn, Kaylo T. and Tu-Chan, Adelyn and Ganguly, Karunesh and Moses, David A. and Chang, Edward F.},
	urldate = {2024-05-21},
	date = {2024-05-20},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Brain–machine interface, Amyotrophic lateral sclerosis, Biomedical engineering},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\ZSQCA7YX\\Silva et al. - 2024 - A bilingual speech neuroprosthesis driven by corti.pdf:application/pdf},
}

@article{schalk_translation_2024,
	title = {Translation of neurotechnologies},
	rights = {2024  Springer Nature Limited},
	issn = {2731-6092},
	url = {https://www.nature.com/articles/s44222-024-00185-2},
	doi = {10.1038/s44222-024-00185-2},
	abstract = {Neurotechnologies combine engineering methods and neuroscientific knowledge to design devices that interface the brain with the outside world. Since the early 2000s, inspiring and encouraging neurotechnology examples have been the subject of high-profile scientific articles and made headlines in popular media. However, although neurotechnologies have the potential to improve people’s lives in ways that cannot be achieved by other solutions such as pharmaceuticals, only a few of them have established themselves as clinical solutions. In this Review, we provide a systematic, state-of-the-art assessment of the opportunities and shortcomings of neurotechnology’s engineering and scientific components, and highlight the requirements to overcome translational barriers. Finally, we present a comprehensive framework to aid the clinical and commercial translation of neurotechnologies.},
	pages = {1--16},
	journaltitle = {Nature Reviews Bioengineering},
	shortjournal = {Nat Rev Bioeng},
	author = {Schalk, Gerwin and Brunner, Peter and Allison, Brendan Z. and Soekadar, Surjo R. and Guan, Cuntai and Denison, Tim and Rickert, Jörn and Miller, Kai J.},
	urldate = {2024-06-03},
	date = {2024-05-31},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Biomedical engineering, Diseases of the nervous system},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\X9YBU2S5\\Schalk et al. - 2024 - Translation of neurotechnologies.pdf:application/pdf},
}

@article{slutzky_physiological_2017,
	title = {Physiological properties of brain-machine interface input signals},
	volume = {118},
	issn = {0022-3077},
	url = {https://journals.physiology.org/doi/full/10.1152/jn.00070.2017},
	doi = {10.1152/jn.00070.2017},
	abstract = {Brain-machine interfaces ({BMIs}), also called brain-computer interfaces ({BCIs}), decode neural signals and use them to control some type of external device. Despite many experimental successes and terrific demonstrations in animals and humans, a high-performance, clinically viable device has not yet been developed for widespread usage. There are many factors that impact clinical viability and {BMI} performance. Arguably, the first of these is the selection of brain signals used to control {BMIs}. In this review, we summarize the physiological characteristics and performance—including movement-related information, longevity, and stability—of multiple types of input signals that have been used in invasive {BMIs} to date. These include intracortical spikes as well as field potentials obtained inside the cortex, at the surface of the cortex (electrocorticography), and at the surface of the dura mater (epidural signals). We also discuss the potential for future enhancements in input signal performance, both by improving hardware and by leveraging the knowledge of the physiological characteristics of these signals to improve decoding and stability.},
	pages = {1329--1343},
	number = {2},
	journaltitle = {Journal of Neurophysiology},
	author = {Slutzky, Marc W. and Flint, Robert D.},
	urldate = {2024-06-20},
	date = {2017-08},
	note = {Publisher: American Physiological Society},
	keywords = {{ECoG}, brain-machine interface, epidural signals, {LFP}, longevity, spikes, stability},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\ZQP83L2U\\Slutzky and Flint - 2017 - Physiological properties of brain-machine interfac.pdf:application/pdf},
}

@article{fan_plug-and-play_2023,
	title = {Plug-and-Play Stability for Intracortical Brain-Computer Interfaces: A One-Year Demonstration of Seamless Brain-to-Text Communication},
	volume = {36},
	url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/83a14a36de4502bac5b580db36e81858-Abstract-Conference.html},
	shorttitle = {Plug-and-Play Stability for Intracortical Brain-Computer Interfaces},
	pages = {42258--42270},
	journaltitle = {Advances in Neural Information Processing Systems},
	author = {Fan, Chaofei and Hahn, Nick and Kamdar, Foram and Avansino, Donald and Wilson, Guy and Hochberg, Leigh and Shenoy, Krishna V. and Henderson, Jaimie and Willett, Francis},
	urldate = {2024-06-20},
	date = {2023-12-15},
	langid = {english},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\LC7EJAKK\\Fan et al. - 2023 - Plug-and-Play Stability for Intracortical Brain-Co.pdf:application/pdf},
}

@article{morris_striving_2022,
	title = {Striving Toward Equity in Health Care for People With Communication Disabilities},
	volume = {65},
	url = {https://pubs.asha.org/doi/10.1044/2022_JSLHR-22-00057},
	doi = {10.1044/2022_JSLHR-22-00057},
	abstract = {Purpose:
      Approximately 10\% of the U.S. adult population has a speech, language, and/or voice
         disability, collectively referred to as communication disabilities. An increasing
         number of studies demonstrate that persons with communication disabilities have worse
         health and health care outcomes as compared to those without communication disabilities.
         Understanding the state of the science, including potential contributing factors is
         critical to begin to address the disparities.
      
      Method:
      Applying a historical lens and integrating multiple models of disability provide a
         comprehensive perspective of the health and health care outcomes of persons with communication
         disabilities.
      
      Results:
      Three phases for addressing health care disparities exist: detecting, understanding,
         and reducing. Results from a 2012 National Health Interview Survey provide compelling
         population-level results of the health and health care disparities experienced by
         persons with communication disabilities. To understand the disparities, factors within
         the health care system, such as availability of communication aids and services, as
         well as provider and staff biases, assumptions, and lack of knowledge need to be considered.
         To date, few interventions exist to address disparities in care for persons with communication
         disabilities. Consequently, researchers need to engage with stakeholders in innovative
         study designs and methods to facilitate the rapid development, implementation, and
         dissemination of interventions that address the disparities.
      
      Conclusion:
      To ensure equity for the large and growing population of persons with communication
         disabilities, researchers, policy makers, patients, and health care systems need to
         collaborate in identifying and addressing the factors contributing to health and health
         care disparities.
      
      Presentation Video:
      https://doi.org/10.23641/asha.21215804},
	pages = {3623--3632},
	number = {10},
	journaltitle = {Journal of Speech, Language, and Hearing Research},
	author = {Morris, Megan A.},
	urldate = {2024-06-20},
	date = {2022-10-17},
	note = {Publisher: American Speech-Language-Hearing Association},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\TZHWQUZ9\\Morris - 2022 - Striving Toward Equity in Health Care for People W.pdf:application/pdf},
}

@article{morris_prevalence_2016,
	title = {Prevalence and etiologies of adult communication disabilities in the United States: Results from the 2012 National Health Interview Survey},
	volume = {9},
	issn = {1936-6574},
	url = {https://www.sciencedirect.com/science/article/pii/S1936657415001016},
	doi = {10.1016/j.dhjo.2015.07.004},
	shorttitle = {Prevalence and etiologies of adult communication disabilities in the United States},
	abstract = {Background
Communication disabilities, including speech, language and voice disabilities, can significantly impact a person's quality of life, employment and health status. Despite this, little is known about the prevalence and etiology of communication disabilities in the general adult population.
Objectives
To assess the prevalence and etiology of communication disabilities in a nationally representative adult sample.
Methods
We conducted a cross-sectional study and analyzed the responses of non-institutionalized adults to the Sample Adult Core questionnaire within the 2012 National Health Interview Survey. We used respondents' self-report of having a speech, language or voice disability within the past year and receiving a diagnosis for one of these communication disabilities, as well as the etiology of their communication disability. We additionally examined the responses by subgroups, including sex, age, race and ethnicity, and geographical area.
Results
In 2012 approximately 10\% of the {US} adult population reported a communication disability, while only 2\% of adults reported receiving a diagnosis. The rates of speech, language and voice disabilities and diagnoses varied across gender, race/ethnicity and geographic groups. The most common response for the etiology of a communication disability was “something else.”
Conclusions
Improved understanding of population prevalence and etiologies of communication disabilities will assist in appropriately directing rehabilitation and medical services; potentially reducing the burden of communication disabilities.},
	pages = {140--144},
	number = {1},
	journaltitle = {Disability and Health Journal},
	shortjournal = {Disability and Health Journal},
	author = {Morris, Megan A. and Meier, Sarah K. and Griffin, Joan M. and Branda, Megan E. and Phelan, Sean M.},
	urldate = {2024-06-20},
	date = {2016-01-01},
	keywords = {Communication disability, Epidemiology, Etiology},
	file = {ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\W8ZQGNRC\\S1936657415001016.html:text/html},
}

@article{stransky_adults_2018,
	title = {Adults with Communication Disabilities Experience Poorer Health and Healthcare Outcomes Compared to Persons Without Communication Disabilities},
	volume = {33},
	issn = {1525-1497},
	doi = {10.1007/s11606-018-4625-1},
	abstract = {{BACKGROUND}: Persons with speech, language, and/or voice disabilities (collectively referred to as communication disabilities ({CD})) represent 10\% of the {US} population, yet their healthcare outcomes have not been described. Generally, research shows that persons with disabilities have poorer health and healthcare outcomes than their non-disabled peers.
{OBJECTIVES}: To examine the health and healthcare outcomes of persons with {CD} compared to persons without {CD}.
{DESIGN}: Retrospective cohort study of the 2012 National Health Interview Survey, which contained the first supplemental questions on {CD}. We compared proportional differences in outcomes; logistic and ordered logistic regression assessed the outcome measures across {CD} categories, controlling for demographics, non-communication disabilities, and chronic conditions. Findings are weighted to permit national inferences.
{PARTICIPANTS}: Adults (≥ 18 years old) were divided into 4 mutually exclusive groups: people with voice disabilities only; speech/language disabilities only; speech/language and voice disabilities; and people without {CD}.
{MAIN} {MEASURES}: Chronic health conditions; self-rated health; access to care; unmet needs for care; healthcare utilization.
{KEY} {RESULTS}: Adults with {CD} more frequently had ≥ 1 chronic condition (voice 67.9\%, speech/language 68.6\%, speech/language and voice 79.9\%, no {CD} 50.1\%, p {\textless} 0.001) and reported fair/poor health (voice 19.5\%, speech/language 32.5\%, speech/language and voice 48.3\%, no {CD} 11.2\%, p {\textless} 0.001) compared to those without {CD}. Adults with {CD} more frequently utilized healthcare compared to those without {CD}. However, persons with {CD} endorsed greater difficulties accessing care than those without {CD}, including identifying a usual source of care, trouble finding a physician, and delaying or foregoing care (e.g., delayed due to availability of care: voice 26.1\%, speech/language 37.2\%, speech/language and voice 30.8\% no {CD} 16.1\%, p {\textless} 0.001).
{CONCLUSIONS}: Persons with {CD} are medically complex and experience greater challenges accessing healthcare than persons without {CD}. Healthcare providers need support and tools to provide equitable care that addresses the medical needs of persons with {CD}.},
	pages = {2147--2155},
	number = {12},
	journaltitle = {Journal of General Internal Medicine},
	shortjournal = {J Gen Intern Med},
	author = {Stransky, Michelle L. and Jensen, Kristin M. and Morris, Megan A.},
	date = {2018-12},
	pmid = {30143977},
	pmcid = {PMC6258615},
	keywords = {Adolescent, Adult, Female, Humans, Male, Middle Aged, Aged, access to care, chronic conditions, Cohort Studies, communication disabilities, Communication Disorders, Cross-Sectional Studies, Delivery of Health Care, health care utilization, Health Services Needs and Demand, Health Status, Health Surveys, Patient Acceptance of Health Care, Retrospective Studies, Treatment Outcome, unmet needs for care, Young Adult},
	file = {Full Text:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\9ZF4VTUL\\Stransky et al. - 2018 - Adults with Communication Disabilities Experience .pdf:application/pdf},
}

@misc{hanson_sewing_2019,
	title = {The “sewing machine” for minimally invasive neural recording},
	rights = {© 2019, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-{NonCommercial} 4.0 International), {CC} {BY}-{NC} 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/578542v1},
	doi = {10.1101/578542},
	abstract = {We present a system for scalable and customizable recording and stimulation of neural activity. In large animals and humans, the current benchmark for high spatial and temporal resolution neural interfaces are fixed arrays of wire or silicon electrodes inserted into the parenchyma of the brain. However, probes that are large and stiff enough to penetrate the brain have been shown to cause acute and chronic damage and inflammation, which limits their longevity, stability, and yield. One approach to this problem is to separate the requirements of the insertion device, which should to be as stiff as possible, with the implanted device, which should be as small and flexible as possible. Here, we demonstrate the feasibility and scalability of this approach with a system incorporating fine and flexible thin-film polymer probes, a fine and stiff insertion needle, and a robotic insertion machine. Together the system permits rapid and precise implantation of probes, each individually targeted to avoid observable vasculature and to attain diverse anatomical targets. As an initial demonstration of this system, we implanted arrays of electrodes in rat somatosensory cortex, recorded extracellular action potentials from them, and obtained histological images of the tissue response. This approach points the way toward a new generation of scaleable, stable, and safe neural interfaces, both for the basic scientific study of brain function and for clinical applications.},
	publisher = {{bioRxiv}},
	author = {Hanson, Timothy L. and Diaz-Botia, Camilo A. and Kharazia, Viktor and Maharbiz, Michel M. and Sabes, Philip N.},
	urldate = {2024-06-20},
	date = {2019-03-14},
	langid = {english},
	note = {Pages: 578542
Section: New Results},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\IFTDGF6C\\Hanson et al. - 2019 - The “sewing machine” for minimally invasive neural.pdf:application/pdf},
}

@article{khodagholy_neurogrid_2015,
	title = {{NeuroGrid}: recording action potentials from the surface of the brain},
	volume = {18},
	rights = {2015 Springer Nature America, Inc.},
	issn = {1546-1726},
	url = {https://www.nature.com/articles/nn.3905},
	doi = {10.1038/nn.3905},
	shorttitle = {{NeuroGrid}},
	abstract = {In this technical report, Khodagholy and colleagues find that {NeuroGrid}, a planar, scalable and highly conformable electrode array, allows recordings of local-field potentials and stable single-unit activity from the surface of the rat cortex or hippocampus. The authors also validate {NeuroGrid} across species by showing that that it can capture {LFP}-modulated spiking activity intraoperatively in surgical patients, thus demonstrating its utility as tool for fundamental research on the human brain and in the clinic.},
	pages = {310--315},
	number = {2},
	journaltitle = {Nature Neuroscience},
	shortjournal = {Nat Neurosci},
	author = {Khodagholy, Dion and Gelinas, Jennifer N. and Thesen, Thomas and Doyle, Werner and Devinsky, Orrin and Malliaras, George G. and Buzsáki, György},
	urldate = {2024-06-20},
	date = {2015-02},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Extracellular recording, Neuroscience, Epilepsy},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\52H222SI\\Khodagholy et al. - 2015 - NeuroGrid recording action potentials from the su.pdf:application/pdf},
}

@article{duraivel_high-resolution_2023,
	title = {High-resolution neural recordings improve the accuracy of speech decoding},
	volume = {14},
	rights = {2023 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-023-42555-1},
	doi = {10.1038/s41467-023-42555-1},
	abstract = {Patients suffering from debilitating neurodegenerative diseases often lose the ability to communicate, detrimentally affecting their quality of life. One solution to restore communication is to decode signals directly from the brain to enable neural speech prostheses. However, decoding has been limited by coarse neural recordings which inadequately capture the rich spatio-temporal structure of human brain signals. To resolve this limitation, we performed high-resolution, micro-electrocorticographic (µ{ECoG}) neural recordings during intra-operative speech production. We obtained neural signals with 57× higher spatial resolution and 48\% higher signal-to-noise ratio compared to macro-{ECoG} and {SEEG}. This increased signal quality improved decoding by 35\% compared to standard intracranial signals. Accurate decoding was dependent on the high-spatial resolution of the neural interface. Non-linear decoding models designed to utilize enhanced spatio-temporal neural information produced better results than linear techniques. We show that high-density µ{ECoG} can enable high-quality speech decoding for future neural speech prostheses.},
	pages = {6938},
	number = {1},
	journaltitle = {Nature Communications},
	shortjournal = {Nat Commun},
	author = {Duraivel, Suseendrakumar and Rahimpour, Shervin and Chiang, Chia-Han and Trumpis, Michael and Wang, Charles and Barth, Katrina and Harward, Stephen C. and Lad, Shivanand P. and Friedman, Allan H. and Southwell, Derek G. and Sinha, Saurabh R. and Viventi, Jonathan and Cogan, Gregory B.},
	urldate = {2024-06-20},
	date = {2023-11-06},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Brain–machine interface, Motor cortex},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\4HK7EBJB\\Duraivel et al. - 2023 - High-resolution neural recordings improve the accu.pdf:application/pdf},
}

@article{tchoe_human_2022,
	title = {Human brain mapping with multithousand-channel {PtNRGrids} resolves spatiotemporal dynamics},
	volume = {14},
	url = {https://www.science.org/doi/full/10.1126/scitranslmed.abj1441},
	doi = {10.1126/scitranslmed.abj1441},
	abstract = {Electrophysiological devices are critical for mapping eloquent and diseased brain regions and for therapeutic neuromodulation in clinical settings and are extensively used for research in brain-machine interfaces. However, the existing clinical and experimental devices are often limited in either spatial resolution or cortical coverage. Here, we developed scalable manufacturing processes with a dense electrical connection scheme to achieve reconfigurable thin-film, multithousand-channel neurophysiological recording grids using platinum nanorods ({PtNRGrids}). With {PtNRGrids}, we have achieved a multithousand-channel array of small (30 μm) contacts with low impedance, providing high spatial and temporal resolution over a large cortical area. We demonstrated that {PtNRGrids} can resolve submillimeter functional organization of the barrel cortex in anesthetized rats that captured the tissue structure. In the clinical setting, {PtNRGrids} resolved fine, complex temporal dynamics from the cortical surface in an awake human patient performing grasping tasks. In addition, the {PtNRGrids} identified the spatial spread and dynamics of epileptic discharges in a patient undergoing epilepsy surgery at 1-mm spatial resolution, including activity induced by direct electrical stimulation. Collectively, these findings demonstrated the power of the {PtNRGrids} to transform clinical mapping and research with brain-machine interfaces.},
	pages = {eabj1441},
	number = {628},
	journaltitle = {Science Translational Medicine},
	author = {Tchoe, Youngbin and Bourhis, Andrew M. and Cleary, Daniel R. and Stedelin, Brittany and Lee, Jihwan and Tonsfeldt, Karen J. and Brown, Erik C. and Siler, Dominic A. and Paulk, Angelique C. and Yang, Jimmy C. and Oh, Hongseok and Ro, Yun Goo and Lee, Keundong and Russman, Samantha M. and Ganji, Mehran and Galton, Ian and Ben-Haim, Sharona and Raslan, Ahmed M. and Dayeh, Shadi A.},
	urldate = {2024-06-20},
	date = {2022-01-19},
	note = {Publisher: American Association for the Advancement of Science},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\W74TW9WS\\Tchoe et al. - 2022 - Human brain mapping with multithousand-channel PtN.pdf:application/pdf},
}

@article{leuthardt_using_2011,
	title = {Using the electrocorticographic speech network to control a brain–computer interface in humans},
	volume = {8},
	issn = {1741-2552},
	url = {https://dx.doi.org/10.1088/1741-2560/8/3/036004},
	doi = {10.1088/1741-2560/8/3/036004},
	abstract = {Electrocorticography ({ECoG}) has emerged as a new signal platform for brain–computer interface ({BCI}) systems. Classically, the cortical physiology that has been commonly investigated and utilized for device control in humans has been brain signals from the sensorimotor cortex. Hence, it was unknown whether other neurophysiological substrates, such as the speech network, could be used to further improve on or complement existing motor-based control paradigms. We demonstrate here for the first time that {ECoG} signals associated with different overt and imagined phoneme articulation can enable invasively monitored human patients to control a one-dimensional computer cursor rapidly and accurately. This phonetic content was distinguishable within higher gamma frequency oscillations and enabled users to achieve final target accuracies between 68\% and 91\% within 15 min. Additionally, one of the patients achieved robust control using recordings from a microarray consisting of 1 mm spaced microwires. These findings suggest that the cortical network associated with speech could provide an additional cognitive and physiologic substrate for {BCI} operation and that these signals can be acquired from a cortical array that is small and minimally invasive.},
	pages = {036004},
	number = {3},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Leuthardt, Eric C. and Gaona, Charles and Sharma, Mohit and Szrama, Nicholas and Roland, Jarod and Freudenberg, Zac and Solis, Jamie and Breshears, Jonathan and Schalk, Gerwin},
	urldate = {2024-06-20},
	date = {2011-04},
	langid = {english},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\GPDPHL6N\\Leuthardt et al. - 2011 - Using the electrocorticographic speech network to .pdf:application/pdf},
}

@article{rastogi_neural_2020,
	title = {Neural Representation of Observed, Imagined, and Attempted Grasping Force in Motor Cortex of Individuals with Chronic Tetraplegia},
	volume = {10},
	rights = {2020 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-020-58097-1},
	doi = {10.1038/s41598-020-58097-1},
	abstract = {Hybrid kinetic and kinematic intracortical brain-computer interfaces ({iBCIs}) have the potential to restore functional grasping and object interaction capabilities in individuals with tetraplegia. This requires an understanding of how kinetic information is represented in neural activity, and how this representation is affected by non-motor parameters such as volitional state ({VoS}), namely, whether one observes, imagines, or attempts an action. To this end, this work investigates how motor cortical neural activity changes when three human participants with tetraplegia observe, imagine, and attempt to produce three discrete hand grasping forces with the dominant hand. We show that force representation follows the same {VoS}-related trends as previously shown for directional arm movements; namely, that attempted force production recruits more neural activity compared to observed or imagined force production. Additionally, {VoS}-modulated neural activity to a greater extent than grasping force. Neural representation of forces was lower than expected, possibly due to compromised somatosensory pathways in individuals with tetraplegia, which have been shown to influence motor cortical activity. Nevertheless, attempted forces (but not always observed or imagined forces) could be decoded significantly above chance, thereby potentially providing relevant information towards the development of a hybrid kinetic and kinematic {iBCI}.},
	pages = {1429},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Rastogi, Anisha and Vargas-Irwin, Carlos E. and Willett, Francis R. and Abreu, Jessica and Crowder, Douglas C. and Murphy, Brian A. and Memberg, William D. and Miller, Jonathan P. and Sweet, Jennifer A. and Walter, Benjamin L. and Cash, Sydney S. and Rezaii, Paymon G. and Franco, Brian and Saab, Jad and Stavisky, Sergey D. and Shenoy, Krishna V. and Henderson, Jaimie M. and Hochberg, Leigh R. and Kirsch, Robert F. and Ajiboye, A. Bolu},
	urldate = {2024-06-20},
	date = {2020-01-29},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Brain–machine interface, Biomedical engineering, Neurology},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\2I8UJQLI\\Rastogi et al. - 2020 - Neural Representation of Observed, Imagined, and A.pdf:application/pdf},
}

@article{miller_spectral_2007,
	title = {Spectral Changes in Cortical Surface Potentials during Motor Movement},
	volume = {27},
	rights = {Copyright © 2007 Society for Neuroscience 0270-6474/07/272424-09\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/27/9/2424},
	doi = {10.1523/JNEUROSCI.3886-06.2007},
	abstract = {In the first large study of its kind, we quantified changes in electrocorticographic signals associated with motor movement across 22 subjects with subdural electrode arrays placed for identification of seizure foci. Patients underwent a 5–7 d monitoring period with array placement, before seizure focus resection, and during this time they participated in the study. An interval-based motor-repetition task produced consistent and quantifiable spectral shifts that were mapped on a Talairach-standardized template cortex. Maps were created independently for a high-frequency band ({HFB}) (76–100 Hz) and a low-frequency band ({LFB}) (8–32 Hz) for several different movement modalities in each subject. The power in relevant electrodes consistently decreased in the {LFB} with movement, whereas the power in the {HFB} consistently increased. In addition, the {HFB} changes were more focal than the {LFB} changes. Sites of power changes corresponded to stereotactic locations in sensorimotor cortex and to the results of individual clinical electrical cortical mapping. Sensorimotor representation was found to be somatotopic, localized in stereotactic space to rolandic cortex, and typically followed the classic homunculus with limited extrarolandic representation.},
	pages = {2424--2432},
	number = {9},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Miller, Kai J. and Leuthardt, Eric C. and Schalk, Gerwin and Rao, Rajesh P. N. and Anderson, Nicholas R. and Moran, Daniel W. and Miller, John W. and Ojemann, Jeffrey G.},
	urldate = {2024-06-20},
	date = {2007-02-28},
	langid = {english},
	pmid = {17329441},
	note = {Publisher: Society for Neuroscience
Section: Articles},
	keywords = {electrocorticography ({ECoG}), motor, cortical spectra, homunculus, mapping, somatotopy},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\5SRCZP8R\\Miller et al. - 2007 - Spectral Changes in Cortical Surface Potentials du.pdf:application/pdf},
}

@article{miller_decoupling_2009,
	title = {Decoupling the Cortical Power Spectrum Reveals Real-Time Representation of Individual Finger Movements in Humans},
	volume = {29},
	rights = {Copyright © 2009 Society for Neuroscience 0270-6474/09/293132-06\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/29/10/3132},
	doi = {10.1523/JNEUROSCI.5506-08.2009},
	abstract = {During active movement the electric potentials measured from the surface of the motor cortex exhibit consistent modulation, revealing two distinguishable processes in the power spectrum. At frequencies {\textless}40 Hz, narrow-band power decreases occur with movement over widely distributed cortical areas, while at higher frequencies there are spatially more focal power increases. These high-frequency changes have commonly been assumed to reflect synchronous rhythms, analogous to lower-frequency phenomena, but it has recently been proposed that they reflect a broad-band spectral change across the entire spectrum, which could be obscured by synchronous rhythms at low frequencies. In 10 human subjects performing a finger movement task, we demonstrate that a principal component type of decomposition can naively separate low-frequency narrow-band rhythms from an asynchronous, broad-spectral, change at all frequencies between 5 and 200 Hz. This broad-spectral change exhibited spatially discrete representation for individual fingers and reproduced the temporal movement trajectories of different individual fingers.},
	pages = {3132--3137},
	number = {10},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Miller, K. J. and Zanos, S. and Fetz, E. E. and Nijs, M. den and Ojemann, J. G.},
	urldate = {2024-06-20},
	date = {2009-03-11},
	langid = {english},
	pmid = {19279250},
	note = {Publisher: Society for Neuroscience
Section: Brief Communications},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\UF2SPBVC\\Miller et al. - 2009 - Decoupling the Cortical Power Spectrum Reveals Rea.pdf:application/pdf},
}

@article{manning_broadband_2009,
	title = {Broadband Shifts in Local Field Potential Power Spectra Are Correlated with Single-Neuron Spiking in Humans},
	volume = {29},
	rights = {Copyright © 2009 Society for Neuroscience 0270-6474/09/2913613-08\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/29/43/13613},
	doi = {10.1523/JNEUROSCI.2041-09.2009},
	abstract = {A fundamental question in neuroscience concerns the relation between the spiking of individual neurons and the aggregate electrical activity of neuronal ensembles as seen in local field potentials ({LFPs}). Because {LFPs} reflect both spiking activity and subthreshold events, this question is not simply one of data aggregation. Recording from 20 neurosurgical patients, we directly examined the relation between {LFPs} and neuronal spiking. Examining 2030 neurons in widespread brain regions, we found that firing rates were positively correlated with broadband (2–150 Hz) shifts in the {LFP} power spectrum. In contrast, narrowband oscillations correlated both positively and negatively with firing rates at different recording sites. Broadband power shifts were a more reliable predictor of neuronal spiking than narrowband power shifts. These findings suggest that broadband {LFP} power provides valuable information concerning neuronal activity beyond that contained in narrowband oscillations.},
	pages = {13613--13620},
	number = {43},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Manning, Jeremy R. and Jacobs, Joshua and Fried, Itzhak and Kahana, Michael J.},
	urldate = {2024-06-20},
	date = {2009-10-28},
	langid = {english},
	pmid = {19864573},
	note = {Publisher: Society for Neuroscience
Section: Articles},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\YWMDLYS7\\Manning et al. - 2009 - Broadband Shifts in Local Field Potential Power Sp.pdf:application/pdf},
}

@article{flint_accurate_2012,
	title = {Accurate decoding of reaching movements from field potentials in the absence of spikes},
	volume = {9},
	issn = {1741-2552},
	url = {https://dx.doi.org/10.1088/1741-2560/9/4/046006},
	doi = {10.1088/1741-2560/9/4/046006},
	abstract = {The recent explosion of interest in brain–machine interfaces ({BMIs}) has spurred research into choosing the optimal input signal source for a desired application. The signals with highest bandwidth—single neuron action potentials or spikes—typically are difficult to record for more than a few years after implantation of intracortical electrodes. Fortunately, field potentials recorded within the cortex (local field potentials, {LFPs}), at its surface (electrocorticograms, {ECoG}) and at the dural surface (epidural, {EFPs}) have also been shown to contain significant information about movement. However, the relative performance of these signals has not yet been directly compared. Furthermore, while it is widely postulated, it has not yet been demonstrated that these field potential signals are more durable than spike recordings. The aim of this study was to address both of these questions. We assessed the offline decoding performance of {EFPs}, {LFPs} and spikes, recorded sequentially, in primary motor cortex (M1) in terms of their ability to decode the target of reaching movements, as well as the endpoint trajectory. We also examined the decoding performance of {LFPs} on electrodes that are not recording spikes, compared with the performance when they did record spikes. Spikes were still present on some of the other electrodes throughout this study. We showed that {LFPs} performed nearly as well as spikes in decoding velocity, and slightly worse in decoding position and in target classification. {EFP} performance was slightly inferior to that reported for {ECoG} in humans. We also provided evidence demonstrating that movement-related information in the {LFP} remains high regardless of the ability to record spikes concurrently on the same electrodes. This is the first study to provide evidence that {LFPs} retain information about movement in the absence of spikes on the same electrodes. These results suggest that {LFPs} may indeed remain informative after spike recordings are lost, thereby providing a robust, accurate signal source for {BMIs}.},
	pages = {046006},
	number = {4},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Flint, Robert D. and Lindberg, Eric W. and Jordan, Luke R. and Miller, Lee E. and Slutzky, Marc W.},
	urldate = {2024-06-20},
	date = {2012-06},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\2CAJTNNE\\Flint et al. - 2012 - Accurate decoding of reaching movements from field.pdf:application/pdf},
}

@article{barbieri_stimulus_2014,
	title = {Stimulus Dependence of Local Field Potential Spectra: Experiment versus Theory},
	volume = {34},
	rights = {Copyright © 2014 the authors 0270-6474/14/3414589-17\$15.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/34/44/14589},
	doi = {10.1523/JNEUROSCI.5365-13.2014},
	shorttitle = {Stimulus Dependence of Local Field Potential Spectra},
	abstract = {The local field potential ({LFP}) captures different neural processes, including integrative synaptic dynamics that cannot be observed by measuring only the spiking activity of small populations. Therefore, investigating how {LFP} power is modulated by external stimuli can offer important insights into sensory neural representations. However, gaining such insight requires developing data-driven computational models that can identify and disambiguate the neural contributions to the {LFP}. Here, we investigated how networks of excitatory and inhibitory integrate-and-fire neurons responding to time-dependent inputs can be used to interpret sensory modulations of {LFP} spectra. We computed analytically from such models the {LFP} spectra and the information that they convey about input and used these analytical expressions to fit the model to {LFPs} recorded in V1 of anesthetized macaques (Macaca mulatta) during the presentation of color movies. Our expressions explain 60\%–98\% of the variance of the {LFP} spectrum shape and its dependency upon movie scenes and we achieved this with realistic values for the best-fit parameters. In particular, synaptic best-fit parameters were compatible with experimental measurements and the predictions of firing rates, based only on the fit of {LFP} data, correlated with the multiunit spike rate recorded from the same location. Moreover, the parameters characterizing the input to the network across different movie scenes correlated with cross-scene changes of several image features. Our findings suggest that analytical descriptions of spiking neuron networks may become a crucial tool for the interpretation of field recordings.},
	pages = {14589--14605},
	number = {44},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Barbieri, Francesca and Mazzoni, Alberto and Logothetis, Nikos K. and Panzeri, Stefano and Brunel, Nicolas},
	urldate = {2024-06-20},
	date = {2014-10-29},
	langid = {english},
	pmid = {25355213},
	note = {Publisher: Society for Neuroscience
Section: Articles},
	keywords = {data-driven models, gamma oscillations, neural coding, primary visual cortex, recurrent networks, slow oscillations},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\JZKAYEVC\\Barbieri et al. - 2014 - Stimulus Dependence of Local Field Potential Spect.pdf:application/pdf},
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	rights = {2015 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature14539},
	doi = {10.1038/nature14539},
	abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
	pages = {436--444},
	number = {7553},
	journaltitle = {Nature},
	author = {{LeCun}, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	urldate = {2024-06-20},
	date = {2015-05},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Computer science, Mathematics and computing},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\ECULM4RZ\\LeCun et al. - 2015 - Deep learning.pdf:application/pdf},
}

@article{song_continuous_2024,
	title = {Continuous neural control of a bionic limb restores biomimetic gait after amputation},
	rights = {2024 The Author(s)},
	issn = {1546-170X},
	url = {https://www.nature.com/articles/s41591-024-02994-9},
	doi = {10.1038/s41591-024-02994-9},
	abstract = {For centuries scientists and technologists have sought artificial leg replacements that fully capture the versatility of their intact biological counterparts. However, biological gait requires coordinated volitional and reflexive motor control by complex afferent and efferent neural interplay, making its neuroprosthetic emulation challenging after limb amputation. Here we hypothesize that continuous neural control of a bionic limb can restore biomimetic gait after below-knee amputation when residual muscle afferents are augmented. To test this hypothesis, we present a neuroprosthetic interface consisting of surgically connected, agonist–antagonist muscles including muscle-sensing electrodes. In a cohort of seven leg amputees, the interface is shown to augment residual muscle afferents by 18\% of biologically intact values. Compared with a matched amputee cohort without the afferent augmentation, the maximum neuroprosthetic walking speed is increased by 41\%, enabling equivalent peak speeds to persons without leg amputation. Further, this level of afferent augmentation enables biomimetic adaptation to various walking speeds and real-world environments, including slopes, stairs and obstructed pathways. Our results suggest that even a small augmentation of residual muscle afferents restores biomimetic gait under continuous neuromodulation in individuals with leg amputation.},
	pages = {1--10},
	journaltitle = {Nature Medicine},
	shortjournal = {Nat Med},
	author = {Song, Hyungeun and Hsieh, Tsung-Han and Yeon, Seong Ho and Shu, Tony and Nawrot, Michael and Landis, Christian F. and Friedman, Gabriel N. and Israel, Erica A. and Gutierrez-Arango, Samantha and Carty, Matthew J. and Freed, Lisa E. and Herr, Hugh M.},
	urldate = {2024-07-01},
	date = {2024-07-01},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Biomedical engineering, Motor control, Mechanical engineering, Medical research},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\UYLW3VXJ\\Song et al. - 2024 - Continuous neural control of a bionic limb restore.pdf:application/pdf},
}

@article{wandelt_representation_2024,
	title = {Representation of internal speech by single neurons in human supramarginal gyrus},
	volume = {8},
	rights = {2024 The Author(s)},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-024-01867-y},
	doi = {10.1038/s41562-024-01867-y},
	abstract = {Speech brain–machine interfaces ({BMIs}) translate brain signals into words or audio outputs, enabling communication for people having lost their speech abilities due to diseases or injury. While important advances in vocalized, attempted and mimed speech decoding have been achieved, results for internal speech decoding are sparse and have yet to achieve high functionality. Notably, it is still unclear from which brain areas internal speech can be decoded. Here two participants with tetraplegia with implanted microelectrode arrays located in the supramarginal gyrus ({SMG}) and primary somatosensory cortex (S1) performed internal and vocalized speech of six words and two pseudowords. In both participants, we found significant neural representation of internal and vocalized speech, at the single neuron and population level in the {SMG}. From recorded population activity in the {SMG}, the internally spoken and vocalized words were significantly decodable. In an offline analysis, we achieved average decoding accuracies of 55\% and 24\% for each participant, respectively (chance level 12.5\%), and during an online internal speech {BMI} task, we averaged 79\% and 23\% accuracy, respectively. Evidence of shared neural representations between internal speech, word reading and vocalized speech processes was found in participant 1. {SMG} represented words as well as pseudowords, providing evidence for phonetic encoding. Furthermore, our decoder achieved high classification with multiple internal speech strategies (auditory imagination/visual imagination). Activity in S1 was modulated by vocalized but not internal speech in both participants, suggesting no articulator movements of the vocal tract occurred during internal speech production. This work represents a proof-of-concept for a high-performance internal speech {BMI}.},
	pages = {1136--1149},
	number = {6},
	journaltitle = {Nature Human Behaviour},
	shortjournal = {Nat Hum Behav},
	author = {Wandelt, Sarah K. and Bjånes, David A. and Pejsa, Kelsie and Lee, Brian and Liu, Charles and Andersen, Richard A.},
	urldate = {2024-08-09},
	date = {2024-06},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Language, Neural decoding, Brain–machine interface},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\AM5LWBQB\\Wandelt et al. - 2024 - Representation of internal speech by single neuron.pdf:application/pdf},
}

@article{varbu_past_2022,
	title = {Past, Present, and Future of {EEG}-Based {BCI} Applications},
	volume = {22},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/22/9/3331},
	doi = {10.3390/s22093331},
	abstract = {An electroencephalography ({EEG})-based brain–computer interface ({BCI}) is a system that provides a pathway between the brain and external devices by interpreting {EEG}. {EEG}-based {BCI} applications have initially been developed for medical purposes, with the aim of facilitating the return of patients to normal life. In addition to the initial aim, {EEG}-based {BCI} applications have also gained increasing significance in the non-medical domain, improving the life of healthy people, for instance, by making it more efficient, collaborative and helping develop themselves. The objective of this review is to give a systematic overview of the literature on {EEG}-based {BCI} applications from the period of 2009 until 2019. The systematic literature review has been prepared based on three databases {PubMed}, Web of Science and Scopus. This review was conducted following the {PRISMA} model. In this review, 202 publications were selected based on specific eligibility criteria. The distribution of the research between the medical and non-medical domain has been analyzed and further categorized into fields of research within the reviewed domains. In this review, the equipment used for gathering {EEG} data and signal processing methods have also been reviewed. Additionally, current challenges in the field and possibilities for the future have been analyzed.},
	pages = {3331},
	number = {9},
	journaltitle = {Sensors},
	author = {Värbu, Kaido and Muhammad, Naveed and Muhammad, Yar},
	urldate = {2024-09-05},
	date = {2022-01},
	langid = {english},
	note = {Number: 9
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {brain–computer interface ({BCI}), electroencephalography ({EEG}), rehabilitation, systematic literature review},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\BRTDBUBF\\Värbu et al. - 2022 - Past, Present, and Future of EEG-Based BCI Applica.pdf:application/pdf},
}

@article{mcfarland_eeg-based_2017,
	title = {{EEG}-based brain–computer interfaces},
	volume = {4},
	issn = {2468-4511},
	url = {https://www.sciencedirect.com/science/article/pii/S246845111730082X},
	doi = {10.1016/j.cobme.2017.11.004},
	series = {Synthetic Biology and Biomedical Engineering / Neural Engineering},
	abstract = {Brain–Computer Interfaces ({BCIs}) are real-time computer-based systems that translate brain signals into useful commands. To date most applications have been demonstrations of proof-of-principle; widespread use by people who could benefit from this technology requires further development. Improvements in current {EEG} recording technology are needed. Better sensors would be easier to apply, more confortable for the user, and produce higher quality and more stable signals. Although considerable effort has been devoted to evaluating classifiers using public datasets, more attention to real-time signal processing issues and to optimizing the mutually adaptive interaction between the brain and the {BCI} are essential for improving {BCI} performance. Further development of applications is also needed, particularly applications of {BCI} technology to rehabilitation. The design of rehabilitation applications hinges on the nature of {BCI} control and how it might be used to induce and guide beneficial plasticity in the brain.},
	pages = {194--200},
	journaltitle = {Current Opinion in Biomedical Engineering},
	shortjournal = {Current Opinion in Biomedical Engineering},
	author = {{McFarland}, D. J. and Wolpaw, J. R.},
	urldate = {2024-09-05},
	date = {2017-12-01},
	keywords = {Brain-computer interface, Rehabilitation, Neurotechnology},
	file = {Accepted Version:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\GVTXRU8Y\\McFarland and Wolpaw - 2017 - EEG-based brain–computer interfaces.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\P5FTNM8Z\\S246845111730082X.html:text/html},
}

@article{abiri_comprehensive_2019,
	title = {A comprehensive review of {EEG}-based brain–computer interface paradigms},
	volume = {16},
	issn = {1741-2552},
	url = {https://dx.doi.org/10.1088/1741-2552/aaf12e},
	doi = {10.1088/1741-2552/aaf12e},
	abstract = {Advances in brain science and computer technology in the past decade have led to exciting developments in brain–computer interface ({BCI}), thereby making {BCI} a top research area in applied science. The renaissance of {BCI} opens new methods of neurorehabilitation for physically disabled people (e.g. paralyzed patients and amputees) and patients with brain injuries (e.g. stroke patients). Recent technological advances such as wireless recording, machine learning analysis, and real-time temporal resolution have increased interest in electroencephalographic ({EEG}) based {BCI} approaches. Many {BCI} studies have focused on decoding {EEG} signals associated with whole-body kinematics/kinetics, motor imagery, and various senses. Thus, there is a need to understand the various experimental paradigms used in {EEG}-based {BCI} systems. Moreover, given that there are many available options, it is essential to choose the most appropriate {BCI} application to properly manipulate a neuroprosthetic or neurorehabilitation device. The current review evaluates {EEG}-based {BCI} paradigms regarding their advantages and disadvantages from a variety of perspectives. For each paradigm, various {EEG} decoding algorithms and classification methods are evaluated. The applications of these paradigms with targeted patients are summarized. Finally, potential problems with {EEG}-based {BCI} systems are discussed, and possible solutions are proposed.},
	pages = {011001},
	number = {1},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Abiri, Reza and Borhani, Soheil and Sellers, Eric W. and Jiang, Yang and Zhao, Xiaopeng},
	urldate = {2024-09-05},
	date = {2019-01},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\VDLQNNV4\\Abiri et al. - 2019 - A comprehensive review of EEG-based brain–computer.pdf:application/pdf},
}

@article{lotte_review_2018,
	title = {A review of classification algorithms for {EEG}-based brain–computer interfaces: a 10 year update},
	volume = {15},
	issn = {1741-2552},
	url = {https://dx.doi.org/10.1088/1741-2552/aab2f2},
	doi = {10.1088/1741-2552/aab2f2},
	shorttitle = {A review of classification algorithms for {EEG}-based brain–computer interfaces},
	abstract = {Objective. Most current electroencephalography ({EEG})-based brain–computer interfaces ({BCIs}) are based on machine learning algorithms. There is a large diversity of classifier types that are used in this field, as described in our 2007 review paper. Now, approximately ten years after this review publication, many new algorithms have been developed and tested to classify {EEG} signals in {BCIs}. The time is therefore ripe for an updated review of {EEG} classification algorithms for {BCIs}. Approach. We surveyed the {BCI} and machine learning literature from 2007 to 2017 to identify the new classification approaches that have been investigated to design {BCIs}. We synthesize these studies in order to present such algorithms, to report how they were used for {BCIs}, what were the outcomes, and to identify their pros and cons. Main results. We found that the recently designed classification algorithms for {EEG}-based {BCIs} can be divided into four main categories: adaptive classifiers, matrix and tensor classifiers, transfer learning and deep learning, plus a few other miscellaneous classifiers. Among these, adaptive classifiers were demonstrated to be generally superior to static ones, even with unsupervised adaptation. Transfer learning can also prove useful although the benefits of transfer learning remain unpredictable. Riemannian geometry-based methods have reached state-of-the-art performances on multiple {BCI} problems and deserve to be explored more thoroughly, along with tensor-based methods. Shrinkage linear discriminant analysis and random forests also appear particularly useful for small training samples settings. On the other hand, deep learning methods have not yet shown convincing improvement over state-of-the-art {BCI} methods. Significance. This paper provides a comprehensive overview of the modern classification algorithms used in {EEG}-based {BCIs}, presents the principles of these methods and guidelines on when and how to use them. It also identifies a number of challenges to further advance {EEG} classification in {BCI}.},
	pages = {031005},
	number = {3},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Lotte, F. and Bougrain, L. and Cichocki, A. and Clerc, M. and Congedo, M. and Rakotomamonjy, A. and Yger, F.},
	urldate = {2024-09-05},
	date = {2018-04},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\S2TA89BC\\Lotte et al. - 2018 - A review of classification algorithms for EEG-base.pdf:application/pdf},
}

@article{wyse-sookoo_stability_2024,
	title = {Stability of {ECoG} high gamma signals during speech and implications for a speech {BCI} system in an individual with {ALS}: a year-long longitudinal study},
	volume = {21},
	rights = {All rights reserved},
	issn = {1741-2552},
	url = {https://dx.doi.org/10.1088/1741-2552/ad5c02},
	doi = {10.1088/1741-2552/ad5c02},
	shorttitle = {Stability of {ECoG} high gamma signals during speech and implications for a speech {BCI} system in an individual with {ALS}},
	abstract = {Objective. Speech brain–computer interfaces ({BCIs}) have the potential to augment communication in individuals with impaired speech due to muscle weakness, for example in amyotrophic lateral sclerosis ({ALS}) and other neurological disorders. However, to achieve long-term, reliable use of a speech {BCI}, it is essential for speech-related neural signal changes to be stable over long periods of time. Here we study, for the first time, the stability of speech-related electrocorticographic ({ECoG}) signals recorded from a chronically implanted {ECoG} {BCI} over a 12 month period. Approach. {ECoG} signals were recorded by an {ECoG} array implanted over the ventral sensorimotor cortex in a clinical trial participant with {ALS}. Because {ECoG}-based speech decoding has most often relied on broadband high gamma ({HG}) signal changes relative to baseline (non-speech) conditions, we studied longitudinal changes of {HG} band power at baseline and during speech, and we compared these with residual high frequency noise levels at baseline. Stability was further assessed by longitudinal measurements of signal-to-noise ratio, activation ratio, and peak speech-related {HG} response magnitude ({HG} response peaks). Lastly, we analyzed the stability of the event-related {HG} power changes ({HG} responses) for individual syllables at each electrode. Main Results. We found that speech-related {ECoG} signal responses were stable over a range of syllables activating different articulators for the first year after implantation. Significance. Together, our results indicate that {ECoG} can be a stable recording modality for long-term speech {BCI} systems for those living with severe paralysis. Clinical Trial Information. {ClinicalTrials}.gov, registration number {NCT}03567213.},
	pages = {046016},
	number = {4},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Wyse-Sookoo, Kimberley and Luo, Shiyu and Candrea, Daniel and Schippers, Anouck and Tippett, Donna C. and Wester, Brock and Fifer, Matthew and Vansteensel, Mariska J. and Ramsey, Nick F. and Crone, Nathan E.},
	urldate = {2024-09-05},
	date = {2024-07},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\BK6H84VX\\Wyse-Sookoo et al. - 2024 - Stability of ECoG high gamma signals during speech.pdf:application/pdf},
}

@incollection{jothilakshmi_chapter_2016,
	title = {Chapter 10 - Large Scale Data Enabled Evolution of Spoken Language Research and Applications},
	volume = {35},
	url = {https://www.sciencedirect.com/science/article/pii/S0169716116300463},
	series = {Cognitive Computing: Theory and Applications},
	abstract = {Natural Language Processing ({NLP}) is an interdisciplinary field whose goal is to analyze and understand human languages. Natural languages are used in two forms: written and spoken. Text and speech are the mediums for written and spoken languages, respectively. The synergistic confluence of advances in signal processing, machine learning, cognitive computing, and big data ushered in large scale data-driven approaches to speech research and applications. This chapter provides an introductory tutorial on the core tasks in speech processing, reviews recent large scale data-driven approaches to solving problems in spoken languages, describes current trends in speech research, and indicates future research directions.},
	pages = {301--340},
	booktitle = {Handbook of Statistics},
	publisher = {Elsevier},
	author = {Jothilakshmi, S. and Gudivada, V. N.},
	editor = {Gudivada, Venkat N. and Raghavan, Vijay V. and Govindaraju, Venu and Rao, C. R.},
	urldate = {2024-09-08},
	date = {2016-01-01},
	doi = {10.1016/bs.host.2016.07.005},
	keywords = {Big data, Large scale data, Natural language processing, Speech processing},
	file = {ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\SEARQDSL\\S0169716116300463.html:text/html},
}

@article{vansteensel_longevity_2024,
	title = {Longevity of a Brain–Computer Interface for Amyotrophic Lateral Sclerosis},
	volume = {391},
	issn = {0028-4793},
	url = {https://www.nejm.org/doi/full/10.1056/NEJMoa2314598},
	doi = {10.1056/NEJMoa2314598},
	abstract = {The durability of communication with the use of brain–computer interfaces in persons with progressive neurodegenerative disease has not been extensively examined. We report on 7 years of independent at-home use of an implanted brain–computer interface for communication by a person with advanced amyotrophic lateral sclerosis ({ALS}), the inception of which was reported in 2016. The frequency of at-home use increased over time to compensate for gradual loss of control of an eye-gaze–tracking device, followed by a progressive decrease in use starting 6 years after implantation. At-home use ended when control of the brain–computer interface became unreliable. No signs of technical malfunction were found. Instead, the amplitude of neural signals declined, and computed tomographic imaging revealed progressive atrophy, which suggested that {ALS}-related neurodegeneration ultimately rendered the brain–computer interface ineffective after years of successful use, although alternative explanations are plausible. (Funded by the National Institute on Deafness and Other Communication Disorders and others; {ClinicalTrials}.gov number, {NCT}02224469.) In a person with amyotrophic lateral sclerosis, an implanted brain–computer interface for assisted communication was effective for more than 7 years. {ALS}-related neurodegeneration ultimately rendered the device ineffective.},
	pages = {619--626},
	number = {7},
	journaltitle = {New England Journal of Medicine},
	author = {Vansteensel, Mariska J. and Leinders, Sacha and Branco, Mariana P. and Crone, Nathan E. and Denison, Timothy and Freudenburg, Zachary V. and Geukes, Simon H. and Gosselaar, Peter H. and Raemaekers, Mathijs and Schippers, Anouck and Verberne, Malinda and Aarnoutse, Erik J. and Ramsey, Nick F.},
	urldate = {2024-09-16},
	date = {2024-08-14},
	note = {Publisher: Massachusetts Medical Society
\_eprint: https://www.nejm.org/doi/pdf/10.1056/{NEJMoa}2314598},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\Y2BTSE7D\\Vansteensel et al. - 2024 - Longevity of a Brain–Computer Interface for Amyotr.pdf:application/pdf},
}

@article{hsieh_cortical_2024,
	title = {Cortical sites critical to language function act as connectors between language subnetworks},
	volume = {15},
	rights = {2024 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-024-51839-z},
	doi = {10.1038/s41467-024-51839-z},
	abstract = {Historically, eloquent functions have been viewed as localized to focal areas of human cerebral cortex, while more recent studies suggest they are encoded by distributed networks. We examined the network properties of cortical sites defined by stimulation to be critical for speech and language, using electrocorticography from sixteen participants during word-reading. We discovered distinct network signatures for sites where stimulation caused speech arrest and language errors. Both demonstrated lower local and global connectivity, whereas sites causing language errors exhibited higher inter-community connectivity, identifying them as connectors between modules in the language network. We used machine learning to classify these site types with reasonably high accuracy, even across participants, suggesting that a site’s pattern of connections within the task-activated language network helps determine its importance to function. These findings help to bridge the gap in our understanding of how focal cortical stimulation interacts with complex brain networks to elicit language deficits.},
	pages = {7897},
	number = {1},
	journaltitle = {Nature Communications},
	shortjournal = {Nat Commun},
	author = {Hsieh, Jason K. and Prakash, Prashanth R. and Flint, Robert D. and Fitzgerald, Zachary and Mugler, Emily and Wang, Yujing and Crone, Nathan E. and Templer, Jessica W. and Rosenow, Joshua M. and Tate, Matthew C. and Betzel, Richard and Slutzky, Marc W.},
	urldate = {2024-09-17},
	date = {2024-09-16},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Language, Network models},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\L78WM6R2\\Hsieh et al. - 2024 - Cortical sites critical to language function act a.pdf:application/pdf},
}

@article{patrick-krueger_state_2024,
	title = {The state of clinical trials of implantable brain–computer interfaces},
	rights = {2024  Springer Nature Limited},
	issn = {2731-6092},
	url = {https://www.nature.com/articles/s44222-024-00239-5},
	doi = {10.1038/s44222-024-00239-5},
	abstract = {Implanted brain–computer interfaces ({iBCIs}) translate brain activity recorded intracranially into commands for virtual or physical machines to restore or rehabilitate motor, sensory or speech functions. Currently, no {iBCIs} have been approved by regulatory agencies for the medical device market despite being in clinical trials since 1998, with little information available about their progress and outcomes. To address this gap, we conducted a review of all identified clinical trials of {iBCIs} for communication, motor control or restoration of tactile perception conducted between 1998 and 2023. We summarize findings from 21 research groups worldwide and their 67 participants who received implants to understand the challenges and opportunities in the {iBCI} field. This analysis highlights the importance of improving participant diversity, creating a participant registry to inform future research, regulatory and payer approvals, investor funding and new applications, adopting governed data sharing and standards, and boosting collaborative research.},
	pages = {1--18},
	journaltitle = {Nature Reviews Bioengineering},
	shortjournal = {Nat Rev Bioeng},
	author = {Patrick-Krueger, K. Michelle and Burkhart, Ian and Contreras-Vidal, Jose L.},
	urldate = {2024-09-23},
	date = {2024-09-20},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Brain–machine interface, Translational research},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\78YZXARE\\Patrick-Krueger et al. - 2024 - The state of clinical trials of implantable brain–.pdf:application/pdf},
}

@online{noauthor_neuropixels_nodate,
	title = {Neuropixels 2.0: A miniaturized high-density probe for stable, long-term brain recordings {\textbar} Science},
	url = {https://www.science.org/doi/10.1126/science.abf4588},
	urldate = {2024-09-28},
	file = {Neuropixels 2.0\: A miniaturized high-density probe for stable, long-term brain recordings | Science:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\2IT5UXDR\\science.html:text/html},
}

@article{willett_high-performance_2021,
	title = {High-performance brain-to-text communication via handwriting},
	volume = {593},
	rights = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-021-03506-2},
	doi = {10.1038/s41586-021-03506-2},
	abstract = {Brain–computer interfaces ({BCIs}) can restore communication to people who have lost the ability to move or speak. So far, a major focus of {BCI} research has been on restoring gross motor skills, such as reaching and grasping1–5 or point-and-click typing with a computer cursor6,7. However, rapid sequences of highly dexterous behaviours, such as handwriting or touch typing, might enable faster rates of communication. Here we developed an intracortical {BCI} that decodes attempted handwriting movements from neural activity in the motor cortex and translates it to text in real time, using a recurrent neural network decoding approach. With this {BCI}, our study participant, whose hand was paralysed from spinal cord injury, achieved typing speeds of 90 characters per minute with 94.1\% raw accuracy online, and greater than 99\% accuracy offline with a general-purpose autocorrect. To our knowledge, these typing speeds exceed those reported for any other {BCI}, and are comparable to typical smartphone typing speeds of individuals in the age group of our participant (115 characters per minute)8. Finally, theoretical considerations explain why temporally complex movements, such as handwriting, may be fundamentally easier to decode than point-to-point movements. Our results open a new approach for {BCIs} and demonstrate the feasibility of accurately decoding rapid, dexterous movements years after paralysis.},
	pages = {249--254},
	number = {7858},
	journaltitle = {Nature},
	author = {Willett, Francis R. and Avansino, Donald T. and Hochberg, Leigh R. and Henderson, Jaimie M. and Shenoy, Krishna V.},
	urldate = {2024-09-28},
	date = {2021-05},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Brain–machine interface, Motor cortex},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\VTEPE4Q6\\Willett et al. - 2020 - High-performance brain-to-text communication via i.pdf:application/pdf;Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\JZ83JZYQ\\Willett et al. - 2021 - High-performance brain-to-text communication via h.pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\HPNDKESX\\2020.07.01.html:text/html;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\HUQKP27H\\s41586-021-03506-2.html:text/html},
}

@article{thomas_decoding_2023,
	title = {Decoding articulatory and phonetic components of naturalistic continuous speech from the distributed language network},
	volume = {20},
	issn = {1741-2552},
	url = {https://dx.doi.org/10.1088/1741-2552/ace9fb},
	doi = {10.1088/1741-2552/ace9fb},
	abstract = {Objective. The speech production network relies on a widely distributed brain network. However, research and development of speech brain–computer interfaces (speech-{BCIs}) has typically focused on decoding speech only from superficial subregions readily accessible by subdural grid arrays—typically placed over the sensorimotor cortex. Alternatively, the technique of stereo-electroencephalography ({sEEG}) enables access to distributed brain regions using multiple depth electrodes with lower surgical risks, especially in patients with brain injuries resulting in aphasia and other speech disorders. Approach. To investigate the decoding potential of widespread electrode coverage in multiple cortical sites, we used a naturalistic continuous speech production task. We obtained neural recordings using {sEEG} from eight participants while they read aloud sentences. We trained linear classifiers to decode distinct speech components (articulatory components and phonemes) solely based on broadband gamma activity and evaluated the decoding performance using nested five-fold cross-validation. Main Results. We achieved an average classification accuracy of 18.7\% across 9 places of articulation (e.g. bilabials, palatals), 26.5\% across 5 manner of articulation ({MOA}) labels (e.g. affricates, fricatives), and 4.81\% across 38 phonemes. The highest classification accuracies achieved with a single large dataset were 26.3\% for place of articulation, 35.7\% for {MOA}, and 9.88\% for phonemes. Electrodes that contributed high decoding power were distributed across multiple sulcal and gyral sites in both dominant and non-dominant hemispheres, including ventral sensorimotor, inferior frontal, superior temporal, and fusiform cortices. Rather than finding a distinct cortical locus for each speech component, we observed neural correlates of both articulatory and phonetic components in multiple hubs of a widespread language production network. Significance. These results reveal the distributed cortical representations whose activity can enable decoding speech components during continuous speech through the use of this minimally invasive recording method, elucidating language neurobiology and neural targets for future speech-{BCIs}.},
	pages = {046030},
	number = {4},
	journaltitle = {Journal of Neural Engineering},
	shortjournal = {J. Neural Eng.},
	author = {Thomas, Tessy M. and Singh, Aditya and Bullock, Latané P. and Liang, Daniel and Morse, Cale W. and Scherschligt, Xavier and Seymour, John P. and Tandon, Nitin},
	urldate = {2024-10-03},
	date = {2023-08},
	langid = {english},
	note = {Publisher: {IOP} Publishing},
	file = {IOP Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\KGMVRNK6\\Thomas et al. - 2023 - Decoding articulatory and phonetic components of n.pdf:application/pdf},
}

@article{luo_review_2020,
	title = {A Review of Functional Electrical Stimulation Treatment in Spinal Cord Injury},
	volume = {22},
	rights = {All rights reserved},
	issn = {1559-1174},
	url = {https://doi.org/10.1007/s12017-019-08589-9},
	doi = {10.1007/s12017-019-08589-9},
	abstract = {Functional electrical stimulation ({FES}) has been widely adopted to elicit muscle contraction in rehabilitation training after spinal cord injury ({SCI}). Conventional {FES} modalities include stimulations coupled with rowing, cycling, assisted walking and other derivatives. In this review, we studied thirteen clinical reports from the past 5 years and evaluated the effects of various {FES} aided rehabilitation plans on the functional recovery after {SCI}, highlighting upper and lower extremity strength, cardiopulmonary function, and balder control. We further explored potential mechanisms of {FES} using the Hebbian theory and lumbar locomotor central pattern generators. Overall, {FES} can be used to improve respiration, circulation, hand strength, mobility, and metabolism after {SCI}.},
	pages = {447--463},
	number = {4},
	journaltitle = {{NeuroMolecular} Medicine},
	shortjournal = {Neuromol Med},
	author = {Luo, Shiyu and Xu, Haonan and Zuo, Yi and Liu, Xiaogang and All, Angelo H.},
	urldate = {2024-10-15},
	date = {2020-12-01},
	langid = {english},
	keywords = {Functional electrical stimulation, Neuroplasticity, Rehabilitation, Spinal cord injury},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\WDPWC4BA\\Luo et al. - 2020 - A Review of Functional Electrical Stimulation Trea.pdf:application/pdf},
}

@article{all_characterization_2020,
	title = {Characterization of transection spinal cord injuries by monitoring somatosensory evoked potentials and motor behavior},
	volume = {156},
	rights = {All rights reserved},
	issn = {0361-9230},
	url = {https://www.sciencedirect.com/science/article/pii/S0361923019306732},
	doi = {10.1016/j.brainresbull.2019.12.012},
	abstract = {Standardization of spinal cord injury ({SCI}) models is crucial for reproducible injury in research settings and their objective assessments. Basso, Beattie and Bresnahan ({BBB}) scoring, the traditional behavioral evaluation method, is subjective and susceptible to human error. On the other hand, neuro-electrophysiological monitoring, such as somatosensory evoked potential ({SSEP}), is an objective assessment method that can be performed continuously for longitudinal studies. We implemented both {SSEP} and {BBB} assessments on transection {SCI} model. Five experimental groups are designed as follows: left hemi-transection at T8, right hemi-transection at T10, double hemi-transection at left T8 and right T10, complete transection at T8 and control group which receives only laminectomy with intact dura and no injury on spinal cord parenchyma. On days 4, 7, 14 and 21 post-injury, first {BBB} scores in awake and then {SSEP} signals in anesthetized rats were obtained. Our results show {SSEP} signals and {BBB} scores are both closely associated with transection model and injury progression. However, the two assessment modalities demonstrate different sensitivity in measuring injury progression when it comes to late-stage double hemi-transection, complete transection and hemi-transection injury. Furthermore, {SSEP} amplitudes are found to be distinct in different injury groups and the progress of their attenuation is increasingly rapid with more severe transection injuries. It is evident from our findings that {SSEP} and {BBB} methods provide distinctive and valuable information and could be complementary of each other. We propose incorporating both {SSEP} monitoring and conventional {BBB} scoring in {SCI} research to more effectively standardize injury progression.},
	pages = {150--163},
	journaltitle = {Brain Research Bulletin},
	shortjournal = {Brain Research Bulletin},
	author = {All, Angelo H. and Al Nashash, Hasan and Mir, Hasan and Luo, Shiyu and liu, Xiaogang},
	urldate = {2024-10-15},
	date = {2020-03-01},
	keywords = {{BBB} score, Rat, Somatosensory evoked potential, Spinal cord injury, {SSEP}, Transection},
	file = {ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\QDCUVKYH\\S0361923019306732.html:text/html},
}

@article{li_processing_2018,
	title = {Processing Techniques for Bioresorbable Nanoparticles in Fabricating Flexible Conductive Interconnects},
	volume = {11},
	rights = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1996-1944},
	url = {https://www.mdpi.com/1996-1944/11/7/1102},
	doi = {10.3390/ma11071102},
	abstract = {Bioresorbable electronics (or transient electronics) devices can be potentially used to replace build-to-last devices in consumer electronics, implantable devices, and data security, leading to reduced electronic waste and surgical processes through controllable dissolution. Recent development of printing bioresorbable electronics leads to bioresorbable conductive pastes or inks that can be used to make interconnects, circuit traces, and sensors, offering alternative solutions for the predominant complementary metal oxide semiconductor ({CMOS}) processes in fabrication of bioresorbable electronics. However, the conductivities offered by current bioresorbable pastes and processing techniques are still much lower than those of the bulk metals, demanding further improvement in both paste composition and process optimization. This paper aims at exploring several influential factors such as paste compositions and processing techniques in determining conductivities of bioresorbable patterns. Experimental results reveal that an optimized paste constituent with a ratio of Zn:{PVP}:glycerol:methanol = 7:0.007:2:1 by weight can generate stable conductive pastes suitable for a screen printing process. In addition, a high conductivity of 60,213.6 S/m can be obtained by combining hot rolling and photonic sintering. The results demonstrate that large-scale transient electronics can be obtained by combining screen printing, hot rolling and photonic sintering approaches with optimized paste compositions, offering important experimental proofs and approaches for further improving the conductivity of bioresorbable pastes or inks that can accommodate the demands for mass fabrication and practical use in electronic industry.},
	pages = {1102},
	number = {7},
	journaltitle = {Materials},
	author = {Li, Jiameng and Luo, Shiyu and Liu, Jiaxuan and Xu, Hang and Huang, Xian},
	urldate = {2024-10-15},
	date = {2018-07},
	langid = {english},
	note = {Number: 7
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {bioresorbable electronics, conductive inks, printing electronics techniques},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\K232EWK6\\Li et al. - 2018 - Processing Techniques for Bioresorbable Nanopartic.pdf:application/pdf},
}

@article{angrick_online_2024,
	title = {Online speech synthesis using a chronically implanted brain–computer interface in an individual with {ALS}},
	volume = {14},
	rights = {2024 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-024-60277-2},
	doi = {10.1038/s41598-024-60277-2},
	abstract = {Brain–computer interfaces ({BCIs}) that reconstruct and synthesize speech using brain activity recorded with intracranial electrodes may pave the way toward novel communication interfaces for people who have lost their ability to speak, or who are at high risk of losing this ability, due to neurological disorders. Here, we report online synthesis of intelligible words using a chronically implanted brain-computer interface ({BCI}) in a man with impaired articulation due to {ALS}, participating in a clinical trial ({ClinicalTrials}.gov, {NCT}03567213) exploring different strategies for {BCI} communication. The 3-stage approach reported here relies on recurrent neural networks to identify, decode and synthesize speech from electrocorticographic ({ECoG}) signals acquired across motor, premotor and somatosensory cortices. We demonstrate a reliable {BCI} that synthesizes commands freely chosen and spoken by the participant from a vocabulary of 6 keywords previously used for decoding commands to control a communication board. Evaluation of the intelligibility of the synthesized speech indicates that 80\% of the words can be correctly recognized by human listeners. Our results show that a speech-impaired individual with {ALS} can use a chronically implanted {BCI} to reliably produce synthesized words while preserving the participant’s voice profile, and provide further evidence for the stability of {ECoG} for speech-based {BCIs}.},
	pages = {9617},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Angrick, Miguel and Luo, Shiyu and Rabbani, Qinwan and Candrea, Daniel N. and Shah, Samyak and Milsap, Griffin W. and Anderson, William S. and Gordon, Chad R. and Rosenblatt, Kathryn R. and Clawson, Lora and Tippett, Donna C. and Maragakis, Nicholas and Tenore, Francesco V. and Fifer, Matthew S. and Hermansky, Hynek and Ramsey, Nick F. and Crone, Nathan E.},
	urldate = {2024-10-15},
	date = {2024-04-26},
	langid = {english},
	note = {Publisher: Nature Publishing Group},
	keywords = {Amyotrophic lateral sclerosis, Neuroscience},
	file = {Available Version (via Google Scholar):C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\R5M8XEPA\\s41598-024-60277-2.html:text/html;Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\6DLVQMAX\\Angrick et al. - 2024 - Online speech synthesis using a chronically implan.pdf:application/pdf},
}

@article{all_effect_2021,
	title = {Effect of thoracic spinal cord injury on forelimb somatosensory evoked potential},
	volume = {173},
	rights = {All rights reserved},
	issn = {0361-9230},
	url = {https://www.sciencedirect.com/science/article/pii/S0361923021001362},
	doi = {10.1016/j.brainresbull.2021.05.005},
	abstract = {In this paper, we investigate the forelimbs somatosensory evoked potential ({SSEP}) signals, which are representative of the integrity of ascending sensory pathways and their stability as well as function, recorded from corresponding cortices, post thoracic spinal cord injury ({SCI}). We designed a series of distinctive transection {SCI} to investigate whether forelimbs {SSEPs} change after right T10 hemi-transection, T8 and T10 double hemi-transection and T8 complete transection in rat model of {SCI}. We used electrical stimuli to stimulate median nerves and recorded {SSEPs} from left and right somatosensory areas of both cortices. We monitored pre-injury baseline and verified changes in forelimbs {SSEP} signals on Days 4, 7, 14, and 21 post-injury. We previously characterized hindlimb {SSEP} changes for the abovementioned transection injuries. The focus of this article is to investigate the quality and quantity of changes that may occur in the forelimb somatosensory pathways post-thoracic transection {SCI}. It is important to test the stability of forelimb {SSEPs} following thoracic {SCI} because of their potential utility as a proxy baseline for the traumatic {SCIs} in clinical cases wherein there is no opportunity to gather baseline of the lower extremities. We observed that the forelimb {SSEP} amplitudes increased following thoracic {SCI} but gradually returned to the baseline. Despite changes found in the raw signals, statistical analysis found forelimb {SSEP} signals become stable relatively soon. In summary, though there are changes in value (with p {\textgreater}  0.05), they are not statistically significant. Therefore, the null hypothesis that the mean of the forelimb {SSEP} signals are the same across multiple days after injury onset cannot be rejected during the acute phase.},
	pages = {22--27},
	journaltitle = {Brain Research Bulletin},
	shortjournal = {Brain Research Bulletin},
	author = {All, Angelo H. and Luo, Shiyu and Liu, Xiaogang and Al-Nashash, Hasan},
	urldate = {2024-10-15},
	date = {2021-08-01},
	keywords = {Forelimb signals, Somatosensory evoked potential, Spinal cord injury, Transection},
	file = {ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\896LYXE6\\S0361923021001362.html:text/html},
}

@article{al-nashash_trading_2020,
	title = {Trading baseline with forelimbs somatosensory evoked potential for longitudinal analysis in thoracic transection spinal cord injury},
	volume = {343},
	rights = {All rights reserved},
	issn = {0165-0270},
	url = {https://www.sciencedirect.com/science/article/pii/S0165027020302818},
	doi = {10.1016/j.jneumeth.2020.108858},
	abstract = {Patients who suffered from spinal cord injury ({SCI}) that come to healthcare professionals for diagnosis and treatment do not have electrophysiology baseline of somatosensory evoked potential ({SSEP}). The {SSEP} has always been used in research for data comparison to detect onset and severity of the {SCI} as well as for assessing its progress, endogenous and therapeutic recovery. This unmet need has motivated us to develop a new tool to substitute the baseline data with forelimb {SSEP} data of the same day. In this study, we report the development and investigation of three distinctive thoracic transections (right T10 hemi-transection (Rxl), left T8 and right T10 double hemi-transection (Dxl) and T8 complete transection (Cxl)) spinal cord injuries in an adult rat model. We used our well-established monitoring methods to obtain {SSEP} baselines as well as post-injury signals from days 4, 7, 14 and 21. We observed that spectral coherences obtained from non-injured spinal cord pathways are always above 0.8. The spectral coherence is dimensionless measure with values between 0 and 1 and measures the correlation between two time signals in the frequency domain. Analysis of variance ({ANOVA}) results also showed that there is a significant difference between the spectral coherence componanet means before and after injury with reaching p = 0.05 for Rxl, p = 0.02 for {DxI}, and p = 0.00 for {CxI}. Our signal processing enables us to replicate comparable detection of the natural history of injuries longitudinally without the implication of baseline {SSEP} signals, highlighting the potential of this analysis method for clinical studies.},
	pages = {108858},
	journaltitle = {Journal of Neuroscience Methods},
	shortjournal = {Journal of Neuroscience Methods},
	author = {Al-Nashash, Hasan and Luo, Shiyu and Liu, Xiaogang and All, Angelo H.},
	urldate = {2024-10-15},
	date = {2020-09-01},
	keywords = {Longitudinal analysis, Rat, Somatosensory evoked potential, Spinal cord injury, Transection},
	file = {ScienceDirect Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\MAZ6ZNGA\\S0165027020302818.html:text/html},
}

@misc{candrea_click-based_2023,
	title = {A click-based electrocorticographic brain-computer interface enables long-term high-performance switch-scan spelling},
	rights = {All rights reserved},
	url = {https://www.researchsquare.com/article/rs-3158792/v1},
	doi = {10.21203/rs.3.rs-3158792/v1},
	abstract = {Background Brain-computer interfaces ({BCIs}) can restore communication in movement- and/or speech-impaired individuals by enabling neural control of computer typing applications. Single command \&amp;ldquo;click\&amp;rdquo; decoders provide a basic yet highly functional capability.Methods We sought to test the performance and long-term stability of click-decoding using a chronically implanted high density electrocorticographic ({ECoG}) {BCI} with coverage of the sensorimotor cortex in a human clinical trial participant ({ClinicalTrials}.gov, {NCT}03567213) with amyotrophic lateral sclerosis ({ALS}). We trained the participant\&amp;rsquo;s click decoder using a small amount of training data (\&amp;lt;\&amp;thinsp;44 minutes across four days) collected up to 21 days prior to {BCI} use, and then tested it over a period of 90 days without any retraining or updating.Results Using this click decoder to navigate a switch-scanning spelling interface, the study participant was able to maintain a median spelling rate of 10.2 characters per min. Though a transient reduction in signal power modulation interrupted testing with this fixed model, a new click decoder achieved comparable performance despite being trained with even less data (\&amp;lt;\&amp;thinsp;15 min, within one day).Conclusion These results demonstrate that a click decoder can be trained with a small {ECoG} dataset while retaining robust performance for extended periods, providing functional text-based communication to {BCI} users.},
	publisher = {Research Square},
	author = {Candrea, Daniel N. and Shah, Samyak and Luo, Shiyu and Angrick, Miguel and Rabbani, Qinwan and Coogan, Christopher and Milsap, Griffin W. and Nathan, Kevin C. and Wester, Brock A. and Anderson, William S. and Rosenblatt, Kathryn R. and Uchil, Alpa and Clawson, Lora and Maragakis, Nicholas J. and Vansteensel, Mariska J. and Tenore, Francesco V. and Ramsey, Nicolas F. and Fifer, Matthew S. and Crone, Nathan E.},
	urldate = {2024-10-15},
	date = {2023-09-25},
	note = {{ISSN}: 2693-5015},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\42CE4TMN\\Candrea et al. - 2023 - A click-based electrocorticographic brain-computer.pdf:application/pdf},
}

@article{peterson_supervised_2024,
	title = {A supervised data-driven spatial filter denoising method for speech artifacts in intracranial electrophysiological recordings},
	volume = {2},
	rights = {All rights reserved},
	issn = {2837-6056},
	url = {https://doi.org/10.1162/imag_a_00301},
	doi = {10.1162/imag_a_00301},
	abstract = {Neurosurgical procedures that enable direct brain recordings in awake patients offer unique opportunities to explore the neurophysiology of human speech. The scarcity of these opportunities and the altruism of participating patients compel us to apply the highest rigor to signal analysis. Intracranial electroencephalography ({iEEG}) signals recorded during overt speech can contain a speech artifact that tracks the fundamental frequency (F0) of the participant’s voice, involving the same high-gamma frequencies that are modulated during speech production and perception. To address this artifact, we developed a spatial-filtering approach to identify and remove acoustic-induced contaminations of the recorded signal. We found that traditional reference schemes jeopardized signal quality, whereas our data-driven method denoised the recordings while preserving underlying neural activity.},
	pages = {1--22},
	journaltitle = {Imaging Neuroscience},
	shortjournal = {Imaging Neuroscience},
	author = {Peterson, Victoria and Vissani, Matteo and Luo, Shiyu and Rabbani, Qinwan and Crone, Nathan E. and Bush, Alan and Richardson, R. Mark},
	urldate = {2024-10-15},
	date = {2024-10-01},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\633TJX7U\\Peterson et al. - 2024 - A supervised data-driven spatial filter denoising .pdf:application/pdf;Snapshot:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\P82V9F7L\\124344.html:text/html},
}

@misc{angrick_real-time_2024,
	title = {Real-time detection of spoken speech from unlabeled {ECoG} signals: A pilot study with an {ALS} participant},
	rights = {© 2024, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-{NonCommercial}-{NoDerivs} 4.0 International), {CC} {BY}-{NC}-{ND} 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.medrxiv.org/content/10.1101/2024.09.18.24313755v1},
	doi = {10.1101/2024.09.18.24313755},
	shorttitle = {Real-time detection of spoken speech from unlabeled {ECoG} signals},
	abstract = {Objective. Brain-Computer Interfaces ({BCIs}) hold significant promise for restoring communication in individuals with partial or complete loss of the ability to speak due to paralysis from amyotrophic lateral sclerosis ({ALS}), brainstem stroke, and other neurological disorders. Many of the approaches to speech decoding reported in the {BCI} literature have required time-aligned target representations to allow successful training – a major challenge when translating such approaches to people who have already lost their voice. Approach. In this pilot study, we made a first step toward scenarios in which no ground truth is available. We utilized a graph-based clustering approach to identify temporal segments of speech production from electrocorticographic ({ECoG}) signals alone. We then used the estimated speech segments to train a voice activity detection ({VAD}) model using only {ECoG} signals. We evaluated our approach using held-out open-loop recordings of a single dysarthric clinical trial participant living with {ALS}, and we compared the resulting performance to previous solutions trained with ground truth acoustic voice recordings. Main results. Our approach achieves a median error rate of around 0.5 seconds with respect to the actual spoken speech. Embedded into a real-time {BCI}, our approach is capable of providing {VAD} results with a latency of only 10 ms. Significance. To the best of our knowledge, our results show for the first time that speech activity can be predicted purely from unlabeled {ECoG} signals, a crucial step toward individuals who cannot provide this information anymore due to their neurological condition, such as patients with locked-in syndrome. Clinical Trial Information. {ClinicalTrials}.gov, registration number {NCT}03567213.},
	publisher = {{medRxiv}},
	author = {Angrick, Miguel and Luo, Shiyu and Rabbani, Qinwan and Joshi, Shreya and Candrea, Daniel N. and Milsap, Griffin W. and Gordon, Chad R. and Rosenblatt, Kathryn and Clawson, Lora and Maragakis, Nicholas and Tenore, Francesco V. and Fifer, Matthew S. and Ramsey, Nick F. and Crone, Nathan E.},
	urldate = {2024-10-15},
	date = {2024-09-22},
	langid = {english},
	note = {Pages: 2024.09.18.24313755},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\D9DCPIC2\\Angrick et al. - 2024 - Real-time detection of spoken speech from unlabele.pdf:application/pdf},
}
