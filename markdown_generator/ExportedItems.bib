
@misc{candrea_click-based_2023,
	title = {A click-based electrocorticographic brain-computer interface enables long-term high-performance switch-scan spelling},
	rights = {All rights reserved},
	url = {https://www.researchsquare.com/article/rs-3158792/v1},
	doi = {10.21203/rs.3.rs-3158792/v1},
	abstract = {Background Brain-computer interfaces ({BCIs}) can restore communication in movement- and/or speech-impaired individuals by enabling neural control of computer typing applications. Single command \&amp;ldquo;click\&amp;rdquo; decoders provide a basic yet highly functional capability.Methods We sought to test the performance and long-term stability of click-decoding using a chronically implanted high density electrocorticographic ({ECoG}) {BCI} with coverage of the sensorimotor cortex in a human clinical trial participant ({ClinicalTrials}.gov, {NCT}03567213) with amyotrophic lateral sclerosis ({ALS}). We trained the participant\&amp;rsquo;s click decoder using a small amount of training data (\&amp;lt;\&amp;thinsp;44 minutes across four days) collected up to 21 days prior to {BCI} use, and then tested it over a period of 90 days without any retraining or updating.Results Using this click decoder to navigate a switch-scanning spelling interface, the study participant was able to maintain a median spelling rate of 10.2 characters per min. Though a transient reduction in signal power modulation interrupted testing with this fixed model, a new click decoder achieved comparable performance despite being trained with even less data (\&amp;lt;\&amp;thinsp;15 min, within one day).Conclusion These results demonstrate that a click decoder can be trained with a small {ECoG} dataset while retaining robust performance for extended periods, providing functional text-based communication to {BCI} users.},
	publisher = {Research Square},
	author = {Candrea, Daniel N. and Shah, Samyak and Luo, Shiyu and Angrick, Miguel and Rabbani, Qinwan and Coogan, Christopher and Milsap, Griffin W. and Nathan, Kevin C. and Wester, Brock A. and Anderson, William S. and Rosenblatt, Kathryn R. and Uchil, Alpa and Clawson, Lora and Maragakis, Nicholas J. and Vansteensel, Mariska J. and Tenore, Francesco V. and Ramsey, Nicolas F. and Fifer, Matthew S. and Crone, Nathan E.},
	urldate = {2024-10-15},
	date = {2023-09-25},
	note = {{ISSN}: 2693-5015},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\42CE4TMN\\Candrea et al. - 2023 - A click-based electrocorticographic brain-computer.pdf:application/pdf},
}

@misc{angrick_real-time_2024,
	title = {Real-time detection of spoken speech from unlabeled {ECoG} signals: A pilot study with an {ALS} participant},
	rights = {© 2024, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-{NonCommercial}-{NoDerivs} 4.0 International), {CC} {BY}-{NC}-{ND} 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.medrxiv.org/content/10.1101/2024.09.18.24313755v1},
	doi = {10.1101/2024.09.18.24313755},
	shorttitle = {Real-time detection of spoken speech from unlabeled {ECoG} signals},
	abstract = {Objective. Brain-Computer Interfaces ({BCIs}) hold significant promise for restoring communication in individuals with partial or complete loss of the ability to speak due to paralysis from amyotrophic lateral sclerosis ({ALS}), brainstem stroke, and other neurological disorders. Many of the approaches to speech decoding reported in the {BCI} literature have required time-aligned target representations to allow successful training – a major challenge when translating such approaches to people who have already lost their voice. Approach. In this pilot study, we made a first step toward scenarios in which no ground truth is available. We utilized a graph-based clustering approach to identify temporal segments of speech production from electrocorticographic ({ECoG}) signals alone. We then used the estimated speech segments to train a voice activity detection ({VAD}) model using only {ECoG} signals. We evaluated our approach using held-out open-loop recordings of a single dysarthric clinical trial participant living with {ALS}, and we compared the resulting performance to previous solutions trained with ground truth acoustic voice recordings. Main results. Our approach achieves a median error rate of around 0.5 seconds with respect to the actual spoken speech. Embedded into a real-time {BCI}, our approach is capable of providing {VAD} results with a latency of only 10 ms. Significance. To the best of our knowledge, our results show for the first time that speech activity can be predicted purely from unlabeled {ECoG} signals, a crucial step toward individuals who cannot provide this information anymore due to their neurological condition, such as patients with locked-in syndrome. Clinical Trial Information. {ClinicalTrials}.gov, registration number {NCT}03567213.},
	publisher = {{medRxiv}},
	author = {Angrick, Miguel and Luo, Shiyu and Rabbani, Qinwan and Joshi, Shreya and Candrea, Daniel N. and Milsap, Griffin W. and Gordon, Chad R. and Rosenblatt, Kathryn and Clawson, Lora and Maragakis, Nicholas and Tenore, Francesco V. and Fifer, Matthew S. and Ramsey, Nick F. and Crone, Nathan E.},
	urldate = {2024-10-15},
	date = {2024-09-22},
	langid = {english},
	note = {Pages: 2024.09.18.24313755},
	file = {Full Text PDF:C\:\\Users\\Steve Luo\\OneDrive\\Documents\\Research\\Zotero\\storage\\D9DCPIC2\\Angrick et al. - 2024 - Real-time detection of spoken speech from unlabele.pdf:application/pdf},
}
